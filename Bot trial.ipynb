{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c259c2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (1.23.5)\n",
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\user\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.23)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.25.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.59.2)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.11.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: tflearn in c:\\users\\user\\anaconda3\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from tflearn) (1.23.5)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from tflearn) (1.16.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\anaconda3\\lib\\site-packages (from tflearn) (9.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install nltk\n",
    "!pip install tensorflow\n",
    "!pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb9b4825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer=LancasterStemmer()\n",
    "import numpy\n",
    "import tflearn\n",
    "import tensorflow\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "with open('intents_ZH-TW.json') as file:\n",
    "    data=json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7155741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "try:\n",
    "    with open(\"data.pickle\", \"rb\") as f:\n",
    "        words, labels, training, output = pickle.load(f)\n",
    "except:\n",
    "'''\n",
    "words=[]\n",
    "labels=[]\n",
    "docs_x=[]\n",
    "docs_y=[]\n",
    "for intent in data[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        wrds=nltk.word_tokenize(pattern)\n",
    "        words.extend(wrds)\n",
    "        docs_x.append(wrds)\n",
    "        docs_y.append(intent[\"tag\"])\n",
    "        \n",
    "    if intent['tag'] not in labels:\n",
    "        labels.append (intent[\"tag\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3309bd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[stemmer.stem(w.lower()) for w in words if w !=\"?\"]\n",
    "words=sorted(list(set(words)))\n",
    "labels=sorted(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b386c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training=[]\n",
    "output=[]\n",
    "out_empty=[0 for _ in range(len(labels))]\n",
    "for x,doc in enumerate(docs_x):\n",
    "    bag=[]\n",
    "    wrds=[stemmer.stem(w.lower()) for w in doc]\n",
    "    for w in words:\n",
    "        if w in wrds:\n",
    "            bag.append(1)\n",
    "        else:\n",
    "            bag.append(0)\n",
    "    output_row=out_empty[:]\n",
    "    output_row[labels.index(docs_y[x])]=1\n",
    "\n",
    "    training.append(bag)\n",
    "    output.append(output_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ace03c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "training=numpy.array(training)\n",
    "output=numpy.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0137a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import tflearn\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "net = tflearn.input_data(shape=[None, len(training[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\")\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa21117f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: CTDYHF\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name Accuracy/ (raw) is illegal; using Accuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 8\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.101s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.98872\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 002 | loss: 0.98872 - acc: 0.5625 -- iter: 8/8\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m1.07826\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 003 | loss: 1.07826 - acc: 0.5114 -- iter: 8/8\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m1.09284\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 004 | loss: 1.09284 - acc: 0.5028 -- iter: 8/8\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m1.09589\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 005 | loss: 1.09589 - acc: 0.5009 -- iter: 8/8\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m1.09646\u001b[0m\u001b[0m | time: 0.015s\n",
      "| Adam | epoch: 006 | loss: 1.09646 - acc: 0.5003 -- iter: 8/8\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m1.09636\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 007 | loss: 1.09636 - acc: 0.5751 -- iter: 8/8\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m1.09606\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 008 | loss: 1.09606 - acc: 0.6735 -- iter: 8/8\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m1.09567\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 009 | loss: 1.09567 - acc: 0.7140 -- iter: 8/8\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m1.09525\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 010 | loss: 1.09525 - acc: 0.7320 -- iter: 8/8\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m1.09481\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 011 | loss: 1.09481 - acc: 0.7405 -- iter: 8/8\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m1.09445\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 012 | loss: 1.09445 - acc: 0.5198 -- iter: 8/8\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m1.09395\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 013 | loss: 1.09395 - acc: 0.6185 -- iter: 8/8\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m1.09345\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 014 | loss: 1.09345 - acc: 0.6723 -- iter: 8/8\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m1.09296\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 015 | loss: 1.09296 - acc: 0.7027 -- iter: 8/8\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m1.09246\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 016 | loss: 1.09246 - acc: 0.6736 -- iter: 8/8\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m1.09196\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 017 | loss: 1.09196 - acc: 0.6111 -- iter: 8/8\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m1.09144\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 018 | loss: 1.09144 - acc: 0.5726 -- iter: 8/8\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m1.09092\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 019 | loss: 1.09092 - acc: 0.5484 -- iter: 8/8\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m1.09038\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 020 | loss: 1.09038 - acc: 0.5329 -- iter: 8/8\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m1.08983\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 021 | loss: 1.08983 - acc: 0.5227 -- iter: 8/8\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m1.08927\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 022 | loss: 1.08927 - acc: 0.5159 -- iter: 8/8\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m1.08869\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 023 | loss: 1.08869 - acc: 0.5113 -- iter: 8/8\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m1.08823\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 024 | loss: 1.08823 - acc: 0.5081 -- iter: 8/8\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m1.08759\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 025 | loss: 1.08759 - acc: 0.5059 -- iter: 8/8\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m1.08694\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 026 | loss: 1.08694 - acc: 0.5043 -- iter: 8/8\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m1.08629\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 027 | loss: 1.08629 - acc: 0.5032 -- iter: 8/8\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m1.08562\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 028 | loss: 1.08562 - acc: 0.5024 -- iter: 8/8\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m1.08494\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 029 | loss: 1.08494 - acc: 0.5018 -- iter: 8/8\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m1.08425\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 030 | loss: 1.08425 - acc: 0.5014 -- iter: 8/8\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m1.08353\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 031 | loss: 1.08353 - acc: 0.5011 -- iter: 8/8\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m1.08280\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 032 | loss: 1.08280 - acc: 0.5008 -- iter: 8/8\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m1.08204\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 033 | loss: 1.08204 - acc: 0.5006 -- iter: 8/8\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m1.08126\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 034 | loss: 1.08126 - acc: 0.5005 -- iter: 8/8\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m1.08046\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 035 | loss: 1.08046 - acc: 0.5004 -- iter: 8/8\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m1.07964\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 036 | loss: 1.07964 - acc: 0.5003 -- iter: 8/8\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m1.07879\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 037 | loss: 1.07879 - acc: 0.5003 -- iter: 8/8\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m1.07791\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 038 | loss: 1.07791 - acc: 0.5002 -- iter: 8/8\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m1.07701\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 039 | loss: 1.07701 - acc: 0.5002 -- iter: 8/8\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m1.07607\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 040 | loss: 1.07607 - acc: 0.5001 -- iter: 8/8\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m1.07511\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 041 | loss: 1.07511 - acc: 0.5001 -- iter: 8/8\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m1.07412\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 042 | loss: 1.07412 - acc: 0.5001 -- iter: 8/8\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m1.07310\u001b[0m\u001b[0m | time: 0.014s\n",
      "| Adam | epoch: 043 | loss: 1.07310 - acc: 0.5001 -- iter: 8/8\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m1.07205\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 044 | loss: 1.07205 - acc: 0.5001 -- iter: 8/8\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m1.07096\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 045 | loss: 1.07096 - acc: 0.5001 -- iter: 8/8\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m1.06984\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 046 | loss: 1.06984 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m1.06868\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 047 | loss: 1.06868 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m1.06749\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 048 | loss: 1.06749 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m1.06626\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 049 | loss: 1.06626 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m1.06499\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 050 | loss: 1.06499 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m1.06369\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 051 | loss: 1.06369 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m1.06234\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 052 | loss: 1.06234 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m1.06096\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 053 | loss: 1.06096 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m1.05953\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 054 | loss: 1.05953 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m1.05806\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 055 | loss: 1.05806 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m1.05655\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 056 | loss: 1.05655 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m1.05499\u001b[0m\u001b[0m | time: 0.015s\n",
      "| Adam | epoch: 057 | loss: 1.05499 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m1.05339\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 058 | loss: 1.05339 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m1.05174\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 059 | loss: 1.05174 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m1.05005\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 060 | loss: 1.05005 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m1.04831\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 061 | loss: 1.04831 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m1.04652\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 062 | loss: 1.04652 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m1.04469\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 063 | loss: 1.04469 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m1.04281\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 064 | loss: 1.04281 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m1.04088\u001b[0m\u001b[0m | time: 0.014s\n",
      "| Adam | epoch: 065 | loss: 1.04088 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m1.03890\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 066 | loss: 1.03890 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m1.03687\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 067 | loss: 1.03687 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m1.03480\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 068 | loss: 1.03480 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m1.03267\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 069 | loss: 1.03267 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m1.03426\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 070 | loss: 1.03426 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m1.03163\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 071 | loss: 1.03163 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m1.02903\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 072 | loss: 1.02903 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m1.02643\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 073 | loss: 1.02643 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m1.02384\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 074 | loss: 1.02384 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m1.02125\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 075 | loss: 1.02125 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m1.01864\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 076 | loss: 1.01864 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m1.01602\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 077 | loss: 1.01602 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m1.01338\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 078 | loss: 1.01338 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m1.01071\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 079 | loss: 1.01071 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m1.00802\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 080 | loss: 1.00802 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m1.00530\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 081 | loss: 1.00530 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m1.00255\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 082 | loss: 1.00255 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m0.99974\u001b[0m\u001b[0m | time: 0.023s\n",
      "| Adam | epoch: 083 | loss: 0.99974 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 84  | total loss: \u001b[1m\u001b[32m0.99687\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 084 | loss: 0.99687 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 85  | total loss: \u001b[1m\u001b[32m0.99395\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 085 | loss: 0.99395 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m0.99096\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 086 | loss: 0.99096 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 87  | total loss: \u001b[1m\u001b[32m0.98793\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 087 | loss: 0.98793 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 88  | total loss: \u001b[1m\u001b[32m0.98484\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 088 | loss: 0.98484 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 89  | total loss: \u001b[1m\u001b[32m0.98170\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 089 | loss: 0.98170 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 90  | total loss: \u001b[1m\u001b[32m0.97852\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 090 | loss: 0.97852 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 91  | total loss: \u001b[1m\u001b[32m0.97528\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 091 | loss: 0.97528 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 92  | total loss: \u001b[1m\u001b[32m0.97201\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 092 | loss: 0.97201 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 93  | total loss: \u001b[1m\u001b[32m0.96870\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 093 | loss: 0.96870 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 94  | total loss: \u001b[1m\u001b[32m0.96534\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 094 | loss: 0.96534 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 95  | total loss: \u001b[1m\u001b[32m0.96195\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 095 | loss: 0.96195 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 96  | total loss: \u001b[1m\u001b[32m0.95853\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 096 | loss: 0.95853 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 97  | total loss: \u001b[1m\u001b[32m0.95507\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 097 | loss: 0.95507 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 98  | total loss: \u001b[1m\u001b[32m0.95158\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 098 | loss: 0.95158 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m0.94807\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 099 | loss: 0.94807 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m0.94453\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 100 | loss: 0.94453 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 101  | total loss: \u001b[1m\u001b[32m0.94096\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 101 | loss: 0.94096 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 102  | total loss: \u001b[1m\u001b[32m0.93738\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 102 | loss: 0.93738 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 103  | total loss: \u001b[1m\u001b[32m0.93377\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 103 | loss: 0.93377 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 104  | total loss: \u001b[1m\u001b[32m0.93014\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 104 | loss: 0.93014 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 105  | total loss: \u001b[1m\u001b[32m0.92650\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 105 | loss: 0.92650 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 106  | total loss: \u001b[1m\u001b[32m0.92284\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 106 | loss: 0.92284 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 107  | total loss: \u001b[1m\u001b[32m0.91917\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 107 | loss: 0.91917 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 108  | total loss: \u001b[1m\u001b[32m0.91549\u001b[0m\u001b[0m | time: 0.013s\n",
      "| Adam | epoch: 108 | loss: 0.91549 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m0.91179\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 109 | loss: 0.91179 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m0.90809\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 110 | loss: 0.90809 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 111  | total loss: \u001b[1m\u001b[32m0.90437\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 111 | loss: 0.90437 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 112  | total loss: \u001b[1m\u001b[32m0.90064\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 112 | loss: 0.90064 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 113  | total loss: \u001b[1m\u001b[32m0.89691\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 113 | loss: 0.89691 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 114  | total loss: \u001b[1m\u001b[32m0.89317\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 114 | loss: 0.89317 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 115  | total loss: \u001b[1m\u001b[32m0.88942\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 115 | loss: 0.88942 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 116  | total loss: \u001b[1m\u001b[32m0.88566\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 116 | loss: 0.88566 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 117  | total loss: \u001b[1m\u001b[32m0.88189\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 117 | loss: 0.88189 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 118  | total loss: \u001b[1m\u001b[32m0.87812\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 118 | loss: 0.87812 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 119  | total loss: \u001b[1m\u001b[32m0.87434\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 119 | loss: 0.87434 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 120  | total loss: \u001b[1m\u001b[32m0.87055\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 120 | loss: 0.87055 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 121  | total loss: \u001b[1m\u001b[32m0.86675\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 121 | loss: 0.86675 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 122  | total loss: \u001b[1m\u001b[32m0.86294\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 122 | loss: 0.86294 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 123  | total loss: \u001b[1m\u001b[32m0.85911\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 123 | loss: 0.85911 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 124  | total loss: \u001b[1m\u001b[32m0.85528\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 124 | loss: 0.85528 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 125  | total loss: \u001b[1m\u001b[32m0.85144\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 125 | loss: 0.85144 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 126  | total loss: \u001b[1m\u001b[32m0.84757\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 126 | loss: 0.84757 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 127  | total loss: \u001b[1m\u001b[32m0.84370\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 127 | loss: 0.84370 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 128  | total loss: \u001b[1m\u001b[32m0.83980\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 128 | loss: 0.83980 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 129  | total loss: \u001b[1m\u001b[32m0.83589\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 129 | loss: 0.83589 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 130  | total loss: \u001b[1m\u001b[32m0.83196\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 130 | loss: 0.83196 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m0.82800\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 131 | loss: 0.82800 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m0.82402\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 132 | loss: 0.82402 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 133  | total loss: \u001b[1m\u001b[32m0.82001\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 133 | loss: 0.82001 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 134  | total loss: \u001b[1m\u001b[32m0.81598\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 134 | loss: 0.81598 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 135  | total loss: \u001b[1m\u001b[32m0.81191\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 135 | loss: 0.81191 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 136  | total loss: \u001b[1m\u001b[32m0.80781\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 136 | loss: 0.80781 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 137  | total loss: \u001b[1m\u001b[32m0.80368\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 137 | loss: 0.80368 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 138  | total loss: \u001b[1m\u001b[32m0.79951\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 138 | loss: 0.79951 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m0.79531\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 139 | loss: 0.79531 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m0.79106\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 140 | loss: 0.79106 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 141  | total loss: \u001b[1m\u001b[32m0.78677\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 141 | loss: 0.78677 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 142  | total loss: \u001b[1m\u001b[32m0.78244\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 142 | loss: 0.78244 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 143  | total loss: \u001b[1m\u001b[32m0.77806\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 143 | loss: 0.77806 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 144  | total loss: \u001b[1m\u001b[32m0.77363\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 144 | loss: 0.77363 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 145  | total loss: \u001b[1m\u001b[32m0.76916\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 145 | loss: 0.76916 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 146  | total loss: \u001b[1m\u001b[32m0.76463\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 146 | loss: 0.76463 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 147  | total loss: \u001b[1m\u001b[32m0.76005\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 147 | loss: 0.76005 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 148  | total loss: \u001b[1m\u001b[32m0.75542\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 148 | loss: 0.75542 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 149  | total loss: \u001b[1m\u001b[32m0.75074\u001b[0m\u001b[0m | time: 0.022s\n",
      "| Adam | epoch: 149 | loss: 0.75074 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 150  | total loss: \u001b[1m\u001b[32m0.74120\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 150 | loss: 0.74120 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 151  | total loss: \u001b[1m\u001b[32m0.73635\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 151 | loss: 0.73635 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 152  | total loss: \u001b[1m\u001b[32m0.73144\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 152 | loss: 0.73144 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m0.73144\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 153 | loss: 0.73144 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m0.72647\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 154 | loss: 0.72647 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m0.72144\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 155 | loss: 0.72144 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m0.71636\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 156 | loss: 0.71636 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m0.71121\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 157 | loss: 0.71121 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m0.70601\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 158 | loss: 0.70601 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m0.70075\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 159 | loss: 0.70075 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m0.69543\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 160 | loss: 0.69543 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m0.69005\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 161 | loss: 0.69005 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m0.68462\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 162 | loss: 0.68462 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m0.67913\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 163 | loss: 0.67913 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m0.67359\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 164 | loss: 0.67359 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m0.66799\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 165 | loss: 0.66799 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 166  | total loss: \u001b[1m\u001b[32m0.66234\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 166 | loss: 0.66234 - acc: 0.5000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 167  | total loss: \u001b[1m\u001b[32m0.65664\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 167 | loss: 0.65664 - acc: 0.5250 -- iter: 8/8\n",
      "--\n",
      "Training Step: 168  | total loss: \u001b[1m\u001b[32m0.65089\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 168 | loss: 0.65089 - acc: 0.5725 -- iter: 8/8\n",
      "--\n",
      "Training Step: 169  | total loss: \u001b[1m\u001b[32m0.64509\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 169 | loss: 0.64509 - acc: 0.6153 -- iter: 8/8\n",
      "--\n",
      "Training Step: 170  | total loss: \u001b[1m\u001b[32m0.63925\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 170 | loss: 0.63925 - acc: 0.6537 -- iter: 8/8\n",
      "--\n",
      "Training Step: 171  | total loss: \u001b[1m\u001b[32m0.63336\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 171 | loss: 0.63336 - acc: 0.6884 -- iter: 8/8\n",
      "--\n",
      "Training Step: 172  | total loss: \u001b[1m\u001b[32m0.62743\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 172 | loss: 0.62743 - acc: 0.7195 -- iter: 8/8\n",
      "--\n",
      "Training Step: 173  | total loss: \u001b[1m\u001b[32m0.62146\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 173 | loss: 0.62146 - acc: 0.7476 -- iter: 8/8\n",
      "--\n",
      "Training Step: 174  | total loss: \u001b[1m\u001b[32m0.61545\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 174 | loss: 0.61545 - acc: 0.7728 -- iter: 8/8\n",
      "--\n",
      "Training Step: 175  | total loss: \u001b[1m\u001b[32m0.60941\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 175 | loss: 0.60941 - acc: 0.7955 -- iter: 8/8\n",
      "--\n",
      "Training Step: 176  | total loss: \u001b[1m\u001b[32m0.64117\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 176 | loss: 0.64117 - acc: 0.7785 -- iter: 8/8\n",
      "--\n",
      "Training Step: 177  | total loss: \u001b[1m\u001b[32m0.62195\u001b[0m\u001b[0m | time: 0.013s\n",
      "| Adam | epoch: 177 | loss: 0.62195 - acc: 0.8006 -- iter: 8/8\n",
      "--\n",
      "Training Step: 178  | total loss: \u001b[1m\u001b[32m0.62195\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 178 | loss: 0.62195 - acc: 0.8206 -- iter: 8/8\n",
      "--\n",
      "Training Step: 179  | total loss: \u001b[1m\u001b[32m0.61292\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 179 | loss: 0.61292 - acc: 0.8385 -- iter: 8/8\n",
      "--\n",
      "Training Step: 180  | total loss: \u001b[1m\u001b[32m0.60421\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 180 | loss: 0.60421 - acc: 0.8547 -- iter: 8/8\n",
      "--\n",
      "Training Step: 181  | total loss: \u001b[1m\u001b[32m0.59578\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 181 | loss: 0.59578 - acc: 0.8692 -- iter: 8/8\n",
      "--\n",
      "Training Step: 182  | total loss: \u001b[1m\u001b[32m0.58761\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 182 | loss: 0.58761 - acc: 0.8823 -- iter: 8/8\n",
      "--\n",
      "Training Step: 183  | total loss: \u001b[1m\u001b[32m0.57966\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 183 | loss: 0.57966 - acc: 0.8940 -- iter: 8/8\n",
      "--\n",
      "Training Step: 184  | total loss: \u001b[1m\u001b[32m0.57191\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 184 | loss: 0.57191 - acc: 0.9046 -- iter: 8/8\n",
      "--\n",
      "Training Step: 185  | total loss: \u001b[1m\u001b[32m0.56435\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 185 | loss: 0.56435 - acc: 0.9142 -- iter: 8/8\n",
      "--\n",
      "Training Step: 186  | total loss: \u001b[1m\u001b[32m0.55694\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 186 | loss: 0.55694 - acc: 0.9228 -- iter: 8/8\n",
      "--\n",
      "Training Step: 187  | total loss: \u001b[1m\u001b[32m0.54967\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 187 | loss: 0.54967 - acc: 0.9305 -- iter: 8/8\n",
      "--\n",
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m0.54254\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 188 | loss: 0.54254 - acc: 0.9374 -- iter: 8/8\n",
      "--\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m0.53552\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 189 | loss: 0.53552 - acc: 0.9437 -- iter: 8/8\n",
      "--\n",
      "Training Step: 190  | total loss: \u001b[1m\u001b[32m0.52860\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 190 | loss: 0.52860 - acc: 0.9493 -- iter: 8/8\n",
      "--\n",
      "Training Step: 191  | total loss: \u001b[1m\u001b[32m0.52178\u001b[0m\u001b[0m | time: 0.014s\n",
      "| Adam | epoch: 191 | loss: 0.52178 - acc: 0.9544 -- iter: 8/8\n",
      "--\n",
      "Training Step: 192  | total loss: \u001b[1m\u001b[32m0.51505\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 192 | loss: 0.51505 - acc: 0.9590 -- iter: 8/8\n",
      "--\n",
      "Training Step: 193  | total loss: \u001b[1m\u001b[32m0.50840\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 193 | loss: 0.50840 - acc: 0.9631 -- iter: 8/8\n",
      "--\n",
      "Training Step: 194  | total loss: \u001b[1m\u001b[32m0.50184\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 194 | loss: 0.50184 - acc: 0.9668 -- iter: 8/8\n",
      "--\n",
      "Training Step: 195  | total loss: \u001b[1m\u001b[32m0.49534\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 195 | loss: 0.49534 - acc: 0.9701 -- iter: 8/8\n",
      "--\n",
      "Training Step: 196  | total loss: \u001b[1m\u001b[32m0.48891\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 196 | loss: 0.48891 - acc: 0.9731 -- iter: 8/8\n",
      "--\n",
      "Training Step: 197  | total loss: \u001b[1m\u001b[32m0.48255\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 197 | loss: 0.48255 - acc: 0.9758 -- iter: 8/8\n",
      "--\n",
      "Training Step: 198  | total loss: \u001b[1m\u001b[32m0.47625\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 198 | loss: 0.47625 - acc: 0.9782 -- iter: 8/8\n",
      "--\n",
      "Training Step: 199  | total loss: \u001b[1m\u001b[32m0.47001\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 199 | loss: 0.47001 - acc: 0.9804 -- iter: 8/8\n",
      "--\n",
      "Training Step: 200  | total loss: \u001b[1m\u001b[32m0.46384\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 200 | loss: 0.46384 - acc: 0.9823 -- iter: 8/8\n",
      "--\n",
      "Training Step: 201  | total loss: \u001b[1m\u001b[32m0.45772\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 201 | loss: 0.45772 - acc: 0.9841 -- iter: 8/8\n",
      "--\n",
      "Training Step: 202  | total loss: \u001b[1m\u001b[32m0.45167\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 202 | loss: 0.45167 - acc: 0.9857 -- iter: 8/8\n",
      "--\n",
      "Training Step: 203  | total loss: \u001b[1m\u001b[32m0.44567\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 203 | loss: 0.44567 - acc: 0.9871 -- iter: 8/8\n",
      "--\n",
      "Training Step: 204  | total loss: \u001b[1m\u001b[32m0.43972\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 204 | loss: 0.43972 - acc: 0.9884 -- iter: 8/8\n",
      "--\n",
      "Training Step: 205  | total loss: \u001b[1m\u001b[32m0.43384\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 205 | loss: 0.43384 - acc: 0.9896 -- iter: 8/8\n",
      "--\n",
      "Training Step: 206  | total loss: \u001b[1m\u001b[32m0.42801\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 206 | loss: 0.42801 - acc: 0.9906 -- iter: 8/8\n",
      "--\n",
      "Training Step: 207  | total loss: \u001b[1m\u001b[32m0.42224\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 207 | loss: 0.42224 - acc: 0.9915 -- iter: 8/8\n",
      "--\n",
      "Training Step: 208  | total loss: \u001b[1m\u001b[32m0.41653\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 208 | loss: 0.41653 - acc: 0.9924 -- iter: 8/8\n",
      "--\n",
      "Training Step: 209  | total loss: \u001b[1m\u001b[32m0.41088\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 209 | loss: 0.41088 - acc: 0.9932 -- iter: 8/8\n",
      "--\n",
      "Training Step: 210  | total loss: \u001b[1m\u001b[32m0.40528\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 210 | loss: 0.40528 - acc: 0.9938 -- iter: 8/8\n",
      "--\n",
      "Training Step: 211  | total loss: \u001b[1m\u001b[32m0.39974\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 211 | loss: 0.39974 - acc: 0.9945 -- iter: 8/8\n",
      "--\n",
      "Training Step: 212  | total loss: \u001b[1m\u001b[32m0.39426\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 212 | loss: 0.39426 - acc: 0.9950 -- iter: 8/8\n",
      "--\n",
      "Training Step: 213  | total loss: \u001b[1m\u001b[32m0.38884\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 213 | loss: 0.38884 - acc: 0.9955 -- iter: 8/8\n",
      "--\n",
      "Training Step: 214  | total loss: \u001b[1m\u001b[32m0.38348\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 214 | loss: 0.38348 - acc: 0.9960 -- iter: 8/8\n",
      "--\n",
      "Training Step: 215  | total loss: \u001b[1m\u001b[32m0.37817\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 215 | loss: 0.37817 - acc: 0.9964 -- iter: 8/8\n",
      "--\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m0.37293\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 216 | loss: 0.37293 - acc: 0.9967 -- iter: 8/8\n",
      "--\n",
      "Training Step: 217  | total loss: \u001b[1m\u001b[32m0.36774\u001b[0m\u001b[0m | time: 0.033s\n",
      "| Adam | epoch: 217 | loss: 0.36774 - acc: 0.9971 -- iter: 8/8\n",
      "--\n",
      "Training Step: 218  | total loss: \u001b[1m\u001b[32m0.36262\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 218 | loss: 0.36262 - acc: 0.9973 -- iter: 8/8\n",
      "--\n",
      "Training Step: 219  | total loss: \u001b[1m\u001b[32m0.35755\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 219 | loss: 0.35755 - acc: 0.9976 -- iter: 8/8\n",
      "--\n",
      "Training Step: 220  | total loss: \u001b[1m\u001b[32m0.35254\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 220 | loss: 0.35254 - acc: 0.9979 -- iter: 8/8\n",
      "--\n",
      "Training Step: 221  | total loss: \u001b[1m\u001b[32m0.34759\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 221 | loss: 0.34759 - acc: 0.9981 -- iter: 8/8\n",
      "--\n",
      "Training Step: 222  | total loss: \u001b[1m\u001b[32m0.34270\u001b[0m\u001b[0m | time: 0.014s\n",
      "| Adam | epoch: 222 | loss: 0.34270 - acc: 0.9983 -- iter: 8/8\n",
      "--\n",
      "Training Step: 223  | total loss: \u001b[1m\u001b[32m0.33787\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 223 | loss: 0.33787 - acc: 0.9984 -- iter: 8/8\n",
      "--\n",
      "Training Step: 224  | total loss: \u001b[1m\u001b[32m0.33310\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 224 | loss: 0.33310 - acc: 0.9986 -- iter: 8/8\n",
      "--\n",
      "Training Step: 225  | total loss: \u001b[1m\u001b[32m0.32839\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 225 | loss: 0.32839 - acc: 0.9987 -- iter: 8/8\n",
      "--\n",
      "Training Step: 226  | total loss: \u001b[1m\u001b[32m0.32373\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 226 | loss: 0.32373 - acc: 0.9989 -- iter: 8/8\n",
      "--\n",
      "Training Step: 227  | total loss: \u001b[1m\u001b[32m0.31913\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 227 | loss: 0.31913 - acc: 0.9990 -- iter: 8/8\n",
      "--\n",
      "Training Step: 228  | total loss: \u001b[1m\u001b[32m0.31459\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 228 | loss: 0.31459 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 229  | total loss: \u001b[1m\u001b[32m0.31011\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 229 | loss: 0.31011 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 230  | total loss: \u001b[1m\u001b[32m0.30568\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 230 | loss: 0.30568 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 231  | total loss: \u001b[1m\u001b[32m0.30131\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 231 | loss: 0.30131 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 232  | total loss: \u001b[1m\u001b[32m0.29700\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 232 | loss: 0.29700 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 233  | total loss: \u001b[1m\u001b[32m0.29274\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 233 | loss: 0.29274 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 234  | total loss: \u001b[1m\u001b[32m0.28854\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 234 | loss: 0.28854 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 235  | total loss: \u001b[1m\u001b[32m0.28439\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 235 | loss: 0.28439 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 236  | total loss: \u001b[1m\u001b[32m0.28030\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 236 | loss: 0.28030 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 237  | total loss: \u001b[1m\u001b[32m0.27626\u001b[0m\u001b[0m | time: 0.014s\n",
      "| Adam | epoch: 237 | loss: 0.27626 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 238  | total loss: \u001b[1m\u001b[32m0.27227\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 238 | loss: 0.27227 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m0.26834\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 239 | loss: 0.26834 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m0.26446\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 240 | loss: 0.26446 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 241  | total loss: \u001b[1m\u001b[32m0.26063\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 241 | loss: 0.26063 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 242  | total loss: \u001b[1m\u001b[32m0.25685\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 242 | loss: 0.25685 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 243  | total loss: \u001b[1m\u001b[32m0.25313\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 243 | loss: 0.25313 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 244  | total loss: \u001b[1m\u001b[32m0.24945\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 244 | loss: 0.24945 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 245  | total loss: \u001b[1m\u001b[32m0.24583\u001b[0m\u001b[0m | time: 0.014s\n",
      "| Adam | epoch: 245 | loss: 0.24583 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 246  | total loss: \u001b[1m\u001b[32m0.24225\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 246 | loss: 0.24225 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 247  | total loss: \u001b[1m\u001b[32m0.23873\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 247 | loss: 0.23873 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 248  | total loss: \u001b[1m\u001b[32m0.23525\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 248 | loss: 0.23525 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 249  | total loss: \u001b[1m\u001b[32m0.23182\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 249 | loss: 0.23182 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 250  | total loss: \u001b[1m\u001b[32m0.22844\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 250 | loss: 0.22844 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 251  | total loss: \u001b[1m\u001b[32m0.22511\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 251 | loss: 0.22511 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 252  | total loss: \u001b[1m\u001b[32m0.22182\u001b[0m\u001b[0m | time: 0.013s\n",
      "| Adam | epoch: 252 | loss: 0.22182 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 253  | total loss: \u001b[1m\u001b[32m0.21858\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 253 | loss: 0.21858 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 254  | total loss: \u001b[1m\u001b[32m0.21539\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 254 | loss: 0.21539 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 255  | total loss: \u001b[1m\u001b[32m0.21224\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 255 | loss: 0.21224 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 256  | total loss: \u001b[1m\u001b[32m0.20914\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 256 | loss: 0.20914 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m0.20608\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 257 | loss: 0.20608 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m0.20307\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 258 | loss: 0.20307 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m0.20010\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 259 | loss: 0.20010 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m0.34961\u001b[0m\u001b[0m | time: 0.015s\n",
      "| Adam | epoch: 260 | loss: 0.34961 - acc: 0.9250 -- iter: 8/8\n",
      "--\n",
      "Training Step: 261  | total loss: \u001b[1m\u001b[32m0.33160\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 261 | loss: 0.33160 - acc: 0.9325 -- iter: 8/8\n",
      "--\n",
      "Training Step: 262  | total loss: \u001b[1m\u001b[32m0.31525\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 262 | loss: 0.31525 - acc: 0.9392 -- iter: 8/8\n",
      "--\n",
      "Training Step: 263  | total loss: \u001b[1m\u001b[32m0.30038\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 263 | loss: 0.30038 - acc: 0.9453 -- iter: 8/8\n",
      "--\n",
      "Training Step: 264  | total loss: \u001b[1m\u001b[32m0.28684\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 264 | loss: 0.28684 - acc: 0.9508 -- iter: 8/8\n",
      "--\n",
      "Training Step: 265  | total loss: \u001b[1m\u001b[32m0.27450\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 265 | loss: 0.27450 - acc: 0.9557 -- iter: 8/8\n",
      "--\n",
      "Training Step: 266  | total loss: \u001b[1m\u001b[32m0.26323\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 266 | loss: 0.26323 - acc: 0.9601 -- iter: 8/8\n",
      "--\n",
      "Training Step: 267  | total loss: \u001b[1m\u001b[32m0.25292\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 267 | loss: 0.25292 - acc: 0.9641 -- iter: 8/8\n",
      "--\n",
      "Training Step: 268  | total loss: \u001b[1m\u001b[32m0.23480\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 268 | loss: 0.23480 - acc: 0.9677 -- iter: 8/8\n",
      "--\n",
      "Training Step: 269  | total loss: \u001b[1m\u001b[32m0.23480\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 269 | loss: 0.23480 - acc: 0.9709 -- iter: 8/8\n",
      "--\n",
      "Training Step: 270  | total loss: \u001b[1m\u001b[32m0.22682\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 270 | loss: 0.22682 - acc: 0.9738 -- iter: 8/8\n",
      "--\n",
      "Training Step: 271  | total loss: \u001b[1m\u001b[32m0.21946\u001b[0m\u001b[0m | time: 0.029s\n",
      "| Adam | epoch: 271 | loss: 0.21946 - acc: 0.9765 -- iter: 8/8\n",
      "--\n",
      "Training Step: 272  | total loss: \u001b[1m\u001b[32m0.21266\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 272 | loss: 0.21266 - acc: 0.9788 -- iter: 8/8\n",
      "--\n",
      "Training Step: 273  | total loss: \u001b[1m\u001b[32m0.20636\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 273 | loss: 0.20636 - acc: 0.9809 -- iter: 8/8\n",
      "--\n",
      "Training Step: 274  | total loss: \u001b[1m\u001b[32m0.20052\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 274 | loss: 0.20052 - acc: 0.9828 -- iter: 8/8\n",
      "--\n",
      "Training Step: 275  | total loss: \u001b[1m\u001b[32m0.19508\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 275 | loss: 0.19508 - acc: 0.9846 -- iter: 8/8\n",
      "--\n",
      "Training Step: 276  | total loss: \u001b[1m\u001b[32m0.19001\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 276 | loss: 0.19001 - acc: 0.9861 -- iter: 8/8\n",
      "--\n",
      "Training Step: 277  | total loss: \u001b[1m\u001b[32m0.18526\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 277 | loss: 0.18526 - acc: 0.9875 -- iter: 8/8\n",
      "--\n",
      "Training Step: 278  | total loss: \u001b[1m\u001b[32m0.18082\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 278 | loss: 0.18082 - acc: 0.9887 -- iter: 8/8\n",
      "--\n",
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m0.17664\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 279 | loss: 0.17664 - acc: 0.9899 -- iter: 8/8\n",
      "--\n",
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m0.17271\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 280 | loss: 0.17271 - acc: 0.9909 -- iter: 8/8\n",
      "--\n",
      "Training Step: 281  | total loss: \u001b[1m\u001b[32m0.16899\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 281 | loss: 0.16899 - acc: 0.9918 -- iter: 8/8\n",
      "--\n",
      "Training Step: 282  | total loss: \u001b[1m\u001b[32m0.16547\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 282 | loss: 0.16547 - acc: 0.9926 -- iter: 8/8\n",
      "--\n",
      "Training Step: 283  | total loss: \u001b[1m\u001b[32m0.16214\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 283 | loss: 0.16214 - acc: 0.9934 -- iter: 8/8\n",
      "--\n",
      "Training Step: 284  | total loss: \u001b[1m\u001b[32m0.15896\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 284 | loss: 0.15896 - acc: 0.9940 -- iter: 8/8\n",
      "--\n",
      "Training Step: 285  | total loss: \u001b[1m\u001b[32m0.15594\u001b[0m\u001b[0m | time: 0.013s\n",
      "| Adam | epoch: 285 | loss: 0.15594 - acc: 0.9946 -- iter: 8/8\n",
      "--\n",
      "Training Step: 286  | total loss: \u001b[1m\u001b[32m0.15305\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 286 | loss: 0.15305 - acc: 0.9952 -- iter: 8/8\n",
      "--\n",
      "Training Step: 287  | total loss: \u001b[1m\u001b[32m0.15029\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 287 | loss: 0.15029 - acc: 0.9956 -- iter: 8/8\n",
      "--\n",
      "Training Step: 288  | total loss: \u001b[1m\u001b[32m0.14764\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 288 | loss: 0.14764 - acc: 0.9961 -- iter: 8/8\n",
      "--\n",
      "Training Step: 289  | total loss: \u001b[1m\u001b[32m0.14509\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 289 | loss: 0.14509 - acc: 0.9965 -- iter: 8/8\n",
      "--\n",
      "Training Step: 290  | total loss: \u001b[1m\u001b[32m0.14264\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 290 | loss: 0.14264 - acc: 0.9968 -- iter: 8/8\n",
      "--\n",
      "Training Step: 291  | total loss: \u001b[1m\u001b[32m0.14028\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 291 | loss: 0.14028 - acc: 0.9971 -- iter: 8/8\n",
      "--\n",
      "Training Step: 292  | total loss: \u001b[1m\u001b[32m0.13800\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 292 | loss: 0.13800 - acc: 0.9974 -- iter: 8/8\n",
      "--\n",
      "Training Step: 293  | total loss: \u001b[1m\u001b[32m0.13579\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 293 | loss: 0.13579 - acc: 0.9977 -- iter: 8/8\n",
      "--\n",
      "Training Step: 294  | total loss: \u001b[1m\u001b[32m0.13365\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 294 | loss: 0.13365 - acc: 0.9979 -- iter: 8/8\n",
      "--\n",
      "Training Step: 295  | total loss: \u001b[1m\u001b[32m0.13158\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 295 | loss: 0.13158 - acc: 0.9981 -- iter: 8/8\n",
      "--\n",
      "Training Step: 296  | total loss: \u001b[1m\u001b[32m0.12956\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 296 | loss: 0.12956 - acc: 0.9983 -- iter: 8/8\n",
      "--\n",
      "Training Step: 297  | total loss: \u001b[1m\u001b[32m0.12760\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 297 | loss: 0.12760 - acc: 0.9985 -- iter: 8/8\n",
      "--\n",
      "Training Step: 298  | total loss: \u001b[1m\u001b[32m0.12570\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 298 | loss: 0.12570 - acc: 0.9986 -- iter: 8/8\n",
      "--\n",
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m0.12384\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 299 | loss: 0.12384 - acc: 0.9988 -- iter: 8/8\n",
      "--\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m0.12203\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 300 | loss: 0.12203 - acc: 0.9989 -- iter: 8/8\n",
      "--\n",
      "Training Step: 301  | total loss: \u001b[1m\u001b[32m0.12027\u001b[0m\u001b[0m | time: 0.013s\n",
      "| Adam | epoch: 301 | loss: 0.12027 - acc: 0.9990 -- iter: 8/8\n",
      "--\n",
      "Training Step: 302  | total loss: \u001b[1m\u001b[32m0.33680\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 302 | loss: 0.33680 - acc: 0.9491 -- iter: 8/8\n",
      "--\n",
      "Training Step: 303  | total loss: \u001b[1m\u001b[32m0.31338\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 303 | loss: 0.31338 - acc: 0.9542 -- iter: 8/8\n",
      "--\n",
      "Training Step: 304  | total loss: \u001b[1m\u001b[32m0.29226\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 304 | loss: 0.29226 - acc: 0.9588 -- iter: 8/8\n",
      "--\n",
      "Training Step: 305  | total loss: \u001b[1m\u001b[32m0.27320\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 305 | loss: 0.27320 - acc: 0.9629 -- iter: 8/8\n",
      "--\n",
      "Training Step: 306  | total loss: \u001b[1m\u001b[32m0.25599\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 306 | loss: 0.25599 - acc: 0.9666 -- iter: 8/8\n",
      "--\n",
      "Training Step: 307  | total loss: \u001b[1m\u001b[32m0.24044\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 307 | loss: 0.24044 - acc: 0.9699 -- iter: 8/8\n",
      "--\n",
      "Training Step: 308  | total loss: \u001b[1m\u001b[32m0.21365\u001b[0m\u001b[0m | time: 0.013s\n",
      "| Adam | epoch: 308 | loss: 0.21365 - acc: 0.9730 -- iter: 8/8\n",
      "--\n",
      "Training Step: 309  | total loss: \u001b[1m\u001b[32m0.20212\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 309 | loss: 0.20212 - acc: 0.9757 -- iter: 8/8\n",
      "--\n",
      "Training Step: 310  | total loss: \u001b[1m\u001b[32m0.20212\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 310 | loss: 0.20212 - acc: 0.9781 -- iter: 8/8\n",
      "--\n",
      "Training Step: 311  | total loss: \u001b[1m\u001b[32m0.19167\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 311 | loss: 0.19167 - acc: 0.9803 -- iter: 8/8\n",
      "--\n",
      "Training Step: 312  | total loss: \u001b[1m\u001b[32m0.18217\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 312 | loss: 0.18217 - acc: 0.9823 -- iter: 8/8\n",
      "--\n",
      "Training Step: 313  | total loss: \u001b[1m\u001b[32m0.17355\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 313 | loss: 0.17355 - acc: 0.9840 -- iter: 8/8\n",
      "--\n",
      "Training Step: 314  | total loss: \u001b[1m\u001b[32m0.16570\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 314 | loss: 0.16570 - acc: 0.9856 -- iter: 8/8\n",
      "--\n",
      "Training Step: 315  | total loss: \u001b[1m\u001b[32m0.15855\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 315 | loss: 0.15855 - acc: 0.9871 -- iter: 8/8\n",
      "--\n",
      "Training Step: 316  | total loss: \u001b[1m\u001b[32m0.15202\u001b[0m\u001b[0m | time: 0.014s\n",
      "| Adam | epoch: 316 | loss: 0.15202 - acc: 0.9884 -- iter: 8/8\n",
      "--\n",
      "Training Step: 317  | total loss: \u001b[1m\u001b[32m0.14606\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 317 | loss: 0.14606 - acc: 0.9895 -- iter: 8/8\n",
      "--\n",
      "Training Step: 318  | total loss: \u001b[1m\u001b[32m0.14060\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 318 | loss: 0.14060 - acc: 0.9906 -- iter: 8/8\n",
      "--\n",
      "Training Step: 319  | total loss: \u001b[1m\u001b[32m0.13560\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 319 | loss: 0.13560 - acc: 0.9915 -- iter: 8/8\n",
      "--\n",
      "Training Step: 320  | total loss: \u001b[1m\u001b[32m0.13100\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 320 | loss: 0.13100 - acc: 0.9924 -- iter: 8/8\n",
      "--\n",
      "Training Step: 321  | total loss: \u001b[1m\u001b[32m0.12677\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 321 | loss: 0.12677 - acc: 0.9931 -- iter: 8/8\n",
      "--\n",
      "Training Step: 322  | total loss: \u001b[1m\u001b[32m0.12287\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 322 | loss: 0.12287 - acc: 0.9938 -- iter: 8/8\n",
      "--\n",
      "Training Step: 323  | total loss: \u001b[1m\u001b[32m0.11926\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 323 | loss: 0.11926 - acc: 0.9944 -- iter: 8/8\n",
      "--\n",
      "Training Step: 324  | total loss: \u001b[1m\u001b[32m0.11593\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 324 | loss: 0.11593 - acc: 0.9950 -- iter: 8/8\n",
      "--\n",
      "Training Step: 325  | total loss: \u001b[1m\u001b[32m0.11283\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 325 | loss: 0.11283 - acc: 0.9955 -- iter: 8/8\n",
      "--\n",
      "Training Step: 326  | total loss: \u001b[1m\u001b[32m0.10995\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 326 | loss: 0.10995 - acc: 0.9959 -- iter: 8/8\n",
      "--\n",
      "Training Step: 327  | total loss: \u001b[1m\u001b[32m0.10727\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 327 | loss: 0.10727 - acc: 0.9963 -- iter: 8/8\n",
      "--\n",
      "Training Step: 328  | total loss: \u001b[1m\u001b[32m0.41343\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 328 | loss: 0.41343 - acc: 0.9217 -- iter: 8/8\n",
      "--\n",
      "Training Step: 329  | total loss: \u001b[1m\u001b[32m0.38033\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 329 | loss: 0.38033 - acc: 0.9295 -- iter: 8/8\n",
      "--\n",
      "Training Step: 330  | total loss: \u001b[1m\u001b[32m0.35055\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 330 | loss: 0.35055 - acc: 0.9366 -- iter: 8/8\n",
      "--\n",
      "Training Step: 331  | total loss: \u001b[1m\u001b[32m0.32375\u001b[0m\u001b[0m | time: 0.013s\n",
      "| Adam | epoch: 331 | loss: 0.32375 - acc: 0.9429 -- iter: 8/8\n",
      "--\n",
      "Training Step: 332  | total loss: \u001b[1m\u001b[32m0.29962\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 332 | loss: 0.29962 - acc: 0.9486 -- iter: 8/8\n",
      "--\n",
      "Training Step: 333  | total loss: \u001b[1m\u001b[32m0.25832\u001b[0m\u001b[0m | time: 0.021s\n",
      "| Adam | epoch: 333 | loss: 0.25832 - acc: 0.9538 -- iter: 8/8\n",
      "--\n",
      "Training Step: 334  | total loss: \u001b[1m\u001b[32m0.24068\u001b[0m\u001b[0m | time: 0.013s\n",
      "| Adam | epoch: 334 | loss: 0.24068 - acc: 0.9584 -- iter: 8/8\n",
      "--\n",
      "Training Step: 335  | total loss: \u001b[1m\u001b[32m0.24068\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 335 | loss: 0.24068 - acc: 0.9626 -- iter: 8/8\n",
      "--\n",
      "Training Step: 336  | total loss: \u001b[1m\u001b[32m0.22477\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 336 | loss: 0.22477 - acc: 0.9663 -- iter: 8/8\n",
      "--\n",
      "Training Step: 337  | total loss: \u001b[1m\u001b[32m0.21042\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 337 | loss: 0.21042 - acc: 0.9697 -- iter: 8/8\n",
      "--\n",
      "Training Step: 338  | total loss: \u001b[1m\u001b[32m0.19746\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 338 | loss: 0.19746 - acc: 0.9727 -- iter: 8/8\n",
      "--\n",
      "Training Step: 339  | total loss: \u001b[1m\u001b[32m0.18575\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 339 | loss: 0.18575 - acc: 0.9754 -- iter: 8/8\n",
      "--\n",
      "Training Step: 340  | total loss: \u001b[1m\u001b[32m0.17516\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 340 | loss: 0.17516 - acc: 0.9779 -- iter: 8/8\n",
      "--\n",
      "Training Step: 341  | total loss: \u001b[1m\u001b[32m0.16558\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 341 | loss: 0.16558 - acc: 0.9801 -- iter: 8/8\n",
      "--\n",
      "Training Step: 342  | total loss: \u001b[1m\u001b[32m0.15690\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 342 | loss: 0.15690 - acc: 0.9821 -- iter: 8/8\n",
      "--\n",
      "Training Step: 343  | total loss: \u001b[1m\u001b[32m0.14903\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 343 | loss: 0.14903 - acc: 0.9839 -- iter: 8/8\n",
      "--\n",
      "Training Step: 344  | total loss: \u001b[1m\u001b[32m0.14189\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 344 | loss: 0.14189 - acc: 0.9855 -- iter: 8/8\n",
      "--\n",
      "Training Step: 345  | total loss: \u001b[1m\u001b[32m0.13540\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 345 | loss: 0.13540 - acc: 0.9869 -- iter: 8/8\n",
      "--\n",
      "Training Step: 346  | total loss: \u001b[1m\u001b[32m0.12950\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 346 | loss: 0.12950 - acc: 0.9882 -- iter: 8/8\n",
      "--\n",
      "Training Step: 347  | total loss: \u001b[1m\u001b[32m0.12412\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 347 | loss: 0.12412 - acc: 0.9894 -- iter: 8/8\n",
      "--\n",
      "Training Step: 348  | total loss: \u001b[1m\u001b[32m0.11474\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 348 | loss: 0.11474 - acc: 0.9905 -- iter: 8/8\n",
      "--\n",
      "Training Step: 349  | total loss: \u001b[1m\u001b[32m0.11064\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 349 | loss: 0.11064 - acc: 0.9914 -- iter: 8/8\n",
      "--\n",
      "Training Step: 350  | total loss: \u001b[1m\u001b[32m0.11064\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 350 | loss: 0.11064 - acc: 0.9923 -- iter: 8/8\n",
      "--\n",
      "Training Step: 351  | total loss: \u001b[1m\u001b[32m0.10688\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 351 | loss: 0.10688 - acc: 0.9931 -- iter: 8/8\n",
      "--\n",
      "Training Step: 352  | total loss: \u001b[1m\u001b[32m0.10343\u001b[0m\u001b[0m | time: 0.015s\n",
      "| Adam | epoch: 352 | loss: 0.10343 - acc: 0.9938 -- iter: 8/8\n",
      "--\n",
      "Training Step: 353  | total loss: \u001b[1m\u001b[32m0.10026\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 353 | loss: 0.10026 - acc: 0.9944 -- iter: 8/8\n",
      "--\n",
      "Training Step: 354  | total loss: \u001b[1m\u001b[32m0.09734\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 354 | loss: 0.09734 - acc: 0.9949 -- iter: 8/8\n",
      "--\n",
      "Training Step: 355  | total loss: \u001b[1m\u001b[32m0.09465\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 355 | loss: 0.09465 - acc: 0.9954 -- iter: 8/8\n",
      "--\n",
      "Training Step: 356  | total loss: \u001b[1m\u001b[32m0.09216\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 356 | loss: 0.09216 - acc: 0.9959 -- iter: 8/8\n",
      "--\n",
      "Training Step: 357  | total loss: \u001b[1m\u001b[32m0.08984\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 357 | loss: 0.08984 - acc: 0.9963 -- iter: 8/8\n",
      "--\n",
      "Training Step: 358  | total loss: \u001b[1m\u001b[32m0.08770\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 358 | loss: 0.08770 - acc: 0.9967 -- iter: 8/8\n",
      "--\n",
      "Training Step: 359  | total loss: \u001b[1m\u001b[32m0.08570\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 359 | loss: 0.08570 - acc: 0.9970 -- iter: 8/8\n",
      "--\n",
      "Training Step: 360  | total loss: \u001b[1m\u001b[32m0.08384\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 360 | loss: 0.08384 - acc: 0.9973 -- iter: 8/8\n",
      "--\n",
      "Training Step: 361  | total loss: \u001b[1m\u001b[32m0.08210\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 361 | loss: 0.08210 - acc: 0.9976 -- iter: 8/8\n",
      "--\n",
      "Training Step: 362  | total loss: \u001b[1m\u001b[32m0.08046\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 362 | loss: 0.08046 - acc: 0.9978 -- iter: 8/8\n",
      "--\n",
      "Training Step: 363  | total loss: \u001b[1m\u001b[32m0.07893\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 363 | loss: 0.07893 - acc: 0.9980 -- iter: 8/8\n",
      "--\n",
      "Training Step: 364  | total loss: \u001b[1m\u001b[32m0.07749\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 364 | loss: 0.07749 - acc: 0.9982 -- iter: 8/8\n",
      "--\n",
      "Training Step: 365  | total loss: \u001b[1m\u001b[32m0.07612\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 365 | loss: 0.07612 - acc: 0.9984 -- iter: 8/8\n",
      "--\n",
      "Training Step: 366  | total loss: \u001b[1m\u001b[32m0.07484\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 366 | loss: 0.07484 - acc: 0.9986 -- iter: 8/8\n",
      "--\n",
      "Training Step: 367  | total loss: \u001b[1m\u001b[32m0.07362\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 367 | loss: 0.07362 - acc: 0.9987 -- iter: 8/8\n",
      "--\n",
      "Training Step: 368  | total loss: \u001b[1m\u001b[32m0.07246\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 368 | loss: 0.07246 - acc: 0.9988 -- iter: 8/8\n",
      "--\n",
      "Training Step: 369  | total loss: \u001b[1m\u001b[32m0.07135\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 369 | loss: 0.07135 - acc: 0.9990 -- iter: 8/8\n",
      "--\n",
      "Training Step: 370  | total loss: \u001b[1m\u001b[32m0.07030\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 370 | loss: 0.07030 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 371  | total loss: \u001b[1m\u001b[32m0.06930\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 371 | loss: 0.06930 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 372  | total loss: \u001b[1m\u001b[32m0.06833\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 372 | loss: 0.06833 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 373  | total loss: \u001b[1m\u001b[32m0.06741\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 373 | loss: 0.06741 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 374  | total loss: \u001b[1m\u001b[32m0.06652\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 374 | loss: 0.06652 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 375  | total loss: \u001b[1m\u001b[32m0.06566\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 375 | loss: 0.06566 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 376  | total loss: \u001b[1m\u001b[32m0.06484\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 376 | loss: 0.06484 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 377  | total loss: \u001b[1m\u001b[32m0.06404\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 377 | loss: 0.06404 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 378  | total loss: \u001b[1m\u001b[32m0.23569\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 378 | loss: 0.23569 - acc: 0.9746 -- iter: 8/8\n",
      "--\n",
      "Training Step: 379  | total loss: \u001b[1m\u001b[32m0.20157\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 379 | loss: 0.20157 - acc: 0.9771 -- iter: 8/8\n",
      "--\n",
      "Training Step: 380  | total loss: \u001b[1m\u001b[32m0.20157\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 380 | loss: 0.20157 - acc: 0.9794 -- iter: 8/8\n",
      "--\n",
      "Training Step: 381  | total loss: \u001b[1m\u001b[32m0.18699\u001b[0m\u001b[0m | time: 0.015s\n",
      "| Adam | epoch: 381 | loss: 0.18699 - acc: 0.9815 -- iter: 8/8\n",
      "--\n",
      "Training Step: 382  | total loss: \u001b[1m\u001b[32m0.17385\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 382 | loss: 0.17385 - acc: 0.9833 -- iter: 8/8\n",
      "--\n",
      "Training Step: 383  | total loss: \u001b[1m\u001b[32m0.16200\u001b[0m\u001b[0m | time: 0.032s\n",
      "| Adam | epoch: 383 | loss: 0.16200 - acc: 0.9850 -- iter: 8/8\n",
      "--\n",
      "Training Step: 384  | total loss: \u001b[1m\u001b[32m0.15131\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 384 | loss: 0.15131 - acc: 0.9865 -- iter: 8/8\n",
      "--\n",
      "Training Step: 385  | total loss: \u001b[1m\u001b[32m0.14165\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 385 | loss: 0.14165 - acc: 0.9878 -- iter: 8/8\n",
      "--\n",
      "Training Step: 386  | total loss: \u001b[1m\u001b[32m0.13294\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 386 | loss: 0.13294 - acc: 0.9891 -- iter: 8/8\n",
      "--\n",
      "Training Step: 387  | total loss: \u001b[1m\u001b[32m0.12506\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 387 | loss: 0.12506 - acc: 0.9902 -- iter: 8/8\n",
      "--\n",
      "Training Step: 388  | total loss: \u001b[1m\u001b[32m0.11793\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 388 | loss: 0.11793 - acc: 0.9920 -- iter: 8/8\n",
      "--\n",
      "Training Step: 389  | total loss: \u001b[1m\u001b[32m0.11148\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 389 | loss: 0.11148 - acc: 0.9920 -- iter: 8/8\n",
      "--\n",
      "Training Step: 390  | total loss: \u001b[1m\u001b[32m0.10564\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 390 | loss: 0.10564 - acc: 0.9928 -- iter: 8/8\n",
      "--\n",
      "Training Step: 391  | total loss: \u001b[1m\u001b[32m0.10035\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 391 | loss: 0.10035 - acc: 0.9935 -- iter: 8/8\n",
      "--\n",
      "Training Step: 392  | total loss: \u001b[1m\u001b[32m0.09555\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 392 | loss: 0.09555 - acc: 0.9942 -- iter: 8/8\n",
      "--\n",
      "Training Step: 393  | total loss: \u001b[1m\u001b[32m0.09119\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 393 | loss: 0.09119 - acc: 0.9948 -- iter: 8/8\n",
      "--\n",
      "Training Step: 394  | total loss: \u001b[1m\u001b[32m0.08723\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 394 | loss: 0.08723 - acc: 0.9953 -- iter: 8/8\n",
      "--\n",
      "Training Step: 395  | total loss: \u001b[1m\u001b[32m0.08362\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 395 | loss: 0.08362 - acc: 0.9958 -- iter: 8/8\n",
      "--\n",
      "Training Step: 396  | total loss: \u001b[1m\u001b[32m0.08033\u001b[0m\u001b[0m | time: 0.015s\n",
      "| Adam | epoch: 396 | loss: 0.08033 - acc: 0.9962 -- iter: 8/8\n",
      "--\n",
      "Training Step: 397  | total loss: \u001b[1m\u001b[32m0.07734\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 397 | loss: 0.07734 - acc: 0.9966 -- iter: 8/8\n",
      "--\n",
      "Training Step: 398  | total loss: \u001b[1m\u001b[32m0.07460\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 398 | loss: 0.07460 - acc: 0.9969 -- iter: 8/8\n",
      "--\n",
      "Training Step: 399  | total loss: \u001b[1m\u001b[32m0.07210\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 399 | loss: 0.07210 - acc: 0.9972 -- iter: 8/8\n",
      "--\n",
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m0.06980\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 400 | loss: 0.06980 - acc: 0.9975 -- iter: 8/8\n",
      "--\n",
      "Training Step: 401  | total loss: \u001b[1m\u001b[32m0.06770\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 401 | loss: 0.06770 - acc: 0.9977 -- iter: 8/8\n",
      "--\n",
      "Training Step: 402  | total loss: \u001b[1m\u001b[32m0.06576\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 402 | loss: 0.06576 - acc: 0.9980 -- iter: 8/8\n",
      "--\n",
      "Training Step: 403  | total loss: \u001b[1m\u001b[32m0.06398\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 403 | loss: 0.06398 - acc: 0.9982 -- iter: 8/8\n",
      "--\n",
      "Training Step: 404  | total loss: \u001b[1m\u001b[32m0.06234\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 404 | loss: 0.06234 - acc: 0.9984 -- iter: 8/8\n",
      "--\n",
      "Training Step: 405  | total loss: \u001b[1m\u001b[32m0.06082\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 405 | loss: 0.06082 - acc: 0.9985 -- iter: 8/8\n",
      "--\n",
      "Training Step: 406  | total loss: \u001b[1m\u001b[32m0.05942\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 406 | loss: 0.05942 - acc: 0.9987 -- iter: 8/8\n",
      "--\n",
      "Training Step: 407  | total loss: \u001b[1m\u001b[32m0.05811\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 407 | loss: 0.05811 - acc: 0.9988 -- iter: 8/8\n",
      "--\n",
      "Training Step: 408  | total loss: \u001b[1m\u001b[32m0.05690\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 408 | loss: 0.05690 - acc: 0.9989 -- iter: 8/8\n",
      "--\n",
      "Training Step: 409  | total loss: \u001b[1m\u001b[32m0.05577\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 409 | loss: 0.05577 - acc: 0.9990 -- iter: 8/8\n",
      "--\n",
      "Training Step: 410  | total loss: \u001b[1m\u001b[32m0.05471\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 410 | loss: 0.05471 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 411  | total loss: \u001b[1m\u001b[32m0.05372\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 411 | loss: 0.05372 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 412  | total loss: \u001b[1m\u001b[32m0.05279\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 412 | loss: 0.05279 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 413  | total loss: \u001b[1m\u001b[32m0.05192\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 413 | loss: 0.05192 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 414  | total loss: \u001b[1m\u001b[32m0.05110\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 414 | loss: 0.05110 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 415  | total loss: \u001b[1m\u001b[32m0.05032\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 415 | loss: 0.05032 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 416  | total loss: \u001b[1m\u001b[32m0.04959\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 416 | loss: 0.04959 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 417  | total loss: \u001b[1m\u001b[32m0.04889\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 417 | loss: 0.04889 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 418  | total loss: \u001b[1m\u001b[32m0.04822\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 418 | loss: 0.04822 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m0.04759\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 419 | loss: 0.04759 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m0.04698\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 420 | loss: 0.04698 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 421  | total loss: \u001b[1m\u001b[32m0.04641\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 421 | loss: 0.04641 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 422  | total loss: \u001b[1m\u001b[32m0.04585\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 422 | loss: 0.04585 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 423  | total loss: \u001b[1m\u001b[32m0.04532\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 423 | loss: 0.04532 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 424  | total loss: \u001b[1m\u001b[32m0.04480\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 424 | loss: 0.04480 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 425  | total loss: \u001b[1m\u001b[32m0.04431\u001b[0m\u001b[0m | time: 0.011s\n",
      "| Adam | epoch: 425 | loss: 0.04431 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 426  | total loss: \u001b[1m\u001b[32m0.04383\u001b[0m\u001b[0m | time: 0.021s\n",
      "| Adam | epoch: 426 | loss: 0.04383 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 427  | total loss: \u001b[1m\u001b[32m0.04336\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 427 | loss: 0.04336 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 428  | total loss: \u001b[1m\u001b[32m0.04291\u001b[0m\u001b[0m | time: 0.014s\n",
      "| Adam | epoch: 428 | loss: 0.04291 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m0.04248\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 429 | loss: 0.04248 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m0.04205\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 430 | loss: 0.04205 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 431  | total loss: \u001b[1m\u001b[32m0.04164\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 431 | loss: 0.04164 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 432  | total loss: \u001b[1m\u001b[32m0.04124\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 432 | loss: 0.04124 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 433  | total loss: \u001b[1m\u001b[32m0.04085\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 433 | loss: 0.04085 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 434  | total loss: \u001b[1m\u001b[32m0.04046\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 434 | loss: 0.04046 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 435  | total loss: \u001b[1m\u001b[32m0.04009\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 435 | loss: 0.04009 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 436  | total loss: \u001b[1m\u001b[32m0.03972\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 436 | loss: 0.03972 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 437  | total loss: \u001b[1m\u001b[32m0.03937\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 437 | loss: 0.03937 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 438  | total loss: \u001b[1m\u001b[32m0.03901\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 438 | loss: 0.03901 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m0.03867\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 439 | loss: 0.03867 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m0.03833\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 440 | loss: 0.03833 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 441  | total loss: \u001b[1m\u001b[32m0.03800\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 441 | loss: 0.03800 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 442  | total loss: \u001b[1m\u001b[32m0.31940\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 442 | loss: 0.31940 - acc: 0.9250 -- iter: 8/8\n",
      "--\n",
      "Training Step: 443  | total loss: \u001b[1m\u001b[32m0.29096\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 443 | loss: 0.29096 - acc: 0.9325 -- iter: 8/8\n",
      "--\n",
      "Training Step: 444  | total loss: \u001b[1m\u001b[32m0.26538\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 444 | loss: 0.26538 - acc: 0.9392 -- iter: 8/8\n",
      "--\n",
      "Training Step: 445  | total loss: \u001b[1m\u001b[32m0.24237\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 445 | loss: 0.24237 - acc: 0.9453 -- iter: 8/8\n",
      "--\n",
      "Training Step: 446  | total loss: \u001b[1m\u001b[32m0.20305\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 446 | loss: 0.20305 - acc: 0.9508 -- iter: 8/8\n",
      "--\n",
      "Training Step: 447  | total loss: \u001b[1m\u001b[32m0.18630\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 447 | loss: 0.18630 - acc: 0.9557 -- iter: 8/8\n",
      "--\n",
      "Training Step: 448  | total loss: \u001b[1m\u001b[32m0.18630\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 448 | loss: 0.18630 - acc: 0.9601 -- iter: 8/8\n",
      "--\n",
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m0.17123\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 449 | loss: 0.17123 - acc: 0.9641 -- iter: 8/8\n",
      "--\n",
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m0.15767\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 450 | loss: 0.15767 - acc: 0.9677 -- iter: 8/8\n",
      "--\n",
      "Training Step: 451  | total loss: \u001b[1m\u001b[32m0.14546\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 451 | loss: 0.14546 - acc: 0.9709 -- iter: 8/8\n",
      "--\n",
      "Training Step: 452  | total loss: \u001b[1m\u001b[32m0.12457\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 452 | loss: 0.12457 - acc: 0.9738 -- iter: 8/8\n",
      "--\n",
      "Training Step: 453  | total loss: \u001b[1m\u001b[32m0.12457\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 453 | loss: 0.12457 - acc: 0.9765 -- iter: 8/8\n",
      "--\n",
      "Training Step: 454  | total loss: \u001b[1m\u001b[32m0.11565\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 454 | loss: 0.11565 - acc: 0.9788 -- iter: 8/8\n",
      "--\n",
      "Training Step: 455  | total loss: \u001b[1m\u001b[32m0.10762\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 455 | loss: 0.10762 - acc: 0.9809 -- iter: 8/8\n",
      "--\n",
      "Training Step: 456  | total loss: \u001b[1m\u001b[32m0.09385\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 456 | loss: 0.09385 - acc: 0.9828 -- iter: 8/8\n",
      "--\n",
      "Training Step: 457  | total loss: \u001b[1m\u001b[32m0.08796\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 457 | loss: 0.08796 - acc: 0.9846 -- iter: 8/8\n",
      "--\n",
      "Training Step: 458  | total loss: \u001b[1m\u001b[32m0.08796\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 458 | loss: 0.08796 - acc: 0.9861 -- iter: 8/8\n",
      "--\n",
      "Training Step: 459  | total loss: \u001b[1m\u001b[32m0.08265\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 459 | loss: 0.08265 - acc: 0.9875 -- iter: 8/8\n",
      "--\n",
      "Training Step: 460  | total loss: \u001b[1m\u001b[32m0.07785\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 460 | loss: 0.07785 - acc: 0.9887 -- iter: 8/8\n",
      "--\n",
      "Training Step: 461  | total loss: \u001b[1m\u001b[32m0.07351\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 461 | loss: 0.07351 - acc: 0.9899 -- iter: 8/8\n",
      "--\n",
      "Training Step: 462  | total loss: \u001b[1m\u001b[32m0.06960\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 462 | loss: 0.06960 - acc: 0.9909 -- iter: 8/8\n",
      "--\n",
      "Training Step: 463  | total loss: \u001b[1m\u001b[32m0.06605\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 463 | loss: 0.06605 - acc: 0.9918 -- iter: 8/8\n",
      "--\n",
      "Training Step: 464  | total loss: \u001b[1m\u001b[32m0.06284\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 464 | loss: 0.06284 - acc: 0.9926 -- iter: 8/8\n",
      "--\n",
      "Training Step: 465  | total loss: \u001b[1m\u001b[32m0.05994\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 465 | loss: 0.05994 - acc: 0.9934 -- iter: 8/8\n",
      "--\n",
      "Training Step: 466  | total loss: \u001b[1m\u001b[32m0.05731\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 466 | loss: 0.05731 - acc: 0.9940 -- iter: 8/8\n",
      "--\n",
      "Training Step: 467  | total loss: \u001b[1m\u001b[32m0.05492\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 467 | loss: 0.05492 - acc: 0.9946 -- iter: 8/8\n",
      "--\n",
      "Training Step: 468  | total loss: \u001b[1m\u001b[32m0.05275\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 468 | loss: 0.05275 - acc: 0.9952 -- iter: 8/8\n",
      "--\n",
      "Training Step: 469  | total loss: \u001b[1m\u001b[32m0.05077\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 469 | loss: 0.05077 - acc: 0.9956 -- iter: 8/8\n",
      "--\n",
      "Training Step: 470  | total loss: \u001b[1m\u001b[32m0.04898\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 470 | loss: 0.04898 - acc: 0.9961 -- iter: 8/8\n",
      "--\n",
      "Training Step: 471  | total loss: \u001b[1m\u001b[32m0.04734\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 471 | loss: 0.04734 - acc: 0.9965 -- iter: 8/8\n",
      "--\n",
      "Training Step: 472  | total loss: \u001b[1m\u001b[32m0.04585\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 472 | loss: 0.04585 - acc: 0.9968 -- iter: 8/8\n",
      "--\n",
      "Training Step: 473  | total loss: \u001b[1m\u001b[32m0.04324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 473 | loss: 0.04324 - acc: 0.9971 -- iter: 8/8\n",
      "--\n",
      "Training Step: 474  | total loss: \u001b[1m\u001b[32m0.04210\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 474 | loss: 0.04210 - acc: 0.9974 -- iter: 8/8\n",
      "--\n",
      "Training Step: 475  | total loss: \u001b[1m\u001b[32m0.04210\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 475 | loss: 0.04210 - acc: 0.9977 -- iter: 8/8\n",
      "--\n",
      "Training Step: 476  | total loss: \u001b[1m\u001b[32m0.04105\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 476 | loss: 0.04105 - acc: 0.9979 -- iter: 8/8\n",
      "--\n",
      "Training Step: 477  | total loss: \u001b[1m\u001b[32m0.04008\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 477 | loss: 0.04008 - acc: 0.9981 -- iter: 8/8\n",
      "--\n",
      "Training Step: 478  | total loss: \u001b[1m\u001b[32m0.03919\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 478 | loss: 0.03919 - acc: 0.9983 -- iter: 8/8\n",
      "--\n",
      "Training Step: 479  | total loss: \u001b[1m\u001b[32m0.03761\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 479 | loss: 0.03761 - acc: 0.9985 -- iter: 8/8\n",
      "--\n",
      "Training Step: 480  | total loss: \u001b[1m\u001b[32m0.03761\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 480 | loss: 0.03761 - acc: 0.9986 -- iter: 8/8\n",
      "--\n",
      "Training Step: 481  | total loss: \u001b[1m\u001b[32m0.03691\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 481 | loss: 0.03691 - acc: 0.9988 -- iter: 8/8\n",
      "--\n",
      "Training Step: 482  | total loss: \u001b[1m\u001b[32m0.03626\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 482 | loss: 0.03626 - acc: 0.9989 -- iter: 8/8\n",
      "--\n",
      "Training Step: 483  | total loss: \u001b[1m\u001b[32m0.03565\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 483 | loss: 0.03565 - acc: 0.9990 -- iter: 8/8\n",
      "--\n",
      "Training Step: 484  | total loss: \u001b[1m\u001b[32m0.03509\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 484 | loss: 0.03509 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 485  | total loss: \u001b[1m\u001b[32m0.03456\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 485 | loss: 0.03456 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 486  | total loss: \u001b[1m\u001b[32m0.03406\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 486 | loss: 0.03406 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 487  | total loss: \u001b[1m\u001b[32m0.03360\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 487 | loss: 0.03360 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 488  | total loss: \u001b[1m\u001b[32m0.03316\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 488 | loss: 0.03316 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 489  | total loss: \u001b[1m\u001b[32m0.03274\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 489 | loss: 0.03274 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 490  | total loss: \u001b[1m\u001b[32m0.03235\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 490 | loss: 0.03235 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 491  | total loss: \u001b[1m\u001b[32m0.03163\u001b[0m\u001b[0m | time: 0.014s\n",
      "| Adam | epoch: 491 | loss: 0.03163 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 492  | total loss: \u001b[1m\u001b[32m0.03163\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 492 | loss: 0.03163 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 493  | total loss: \u001b[1m\u001b[32m0.03129\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 493 | loss: 0.03129 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 494  | total loss: \u001b[1m\u001b[32m0.03097\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 494 | loss: 0.03097 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 495  | total loss: \u001b[1m\u001b[32m0.03066\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 495 | loss: 0.03066 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 496  | total loss: \u001b[1m\u001b[32m0.03037\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 496 | loss: 0.03037 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 497  | total loss: \u001b[1m\u001b[32m0.03009\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 497 | loss: 0.03009 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 498  | total loss: \u001b[1m\u001b[32m0.02981\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 498 | loss: 0.02981 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 499  | total loss: \u001b[1m\u001b[32m0.02955\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 499 | loss: 0.02955 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 500  | total loss: \u001b[1m\u001b[32m0.02930\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 500 | loss: 0.02930 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 501  | total loss: \u001b[1m\u001b[32m0.02905\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 501 | loss: 0.02905 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 502  | total loss: \u001b[1m\u001b[32m0.02881\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 502 | loss: 0.02881 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 503  | total loss: \u001b[1m\u001b[32m0.02858\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 503 | loss: 0.02858 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 504  | total loss: \u001b[1m\u001b[32m0.02835\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 504 | loss: 0.02835 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 505  | total loss: \u001b[1m\u001b[32m0.02813\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 505 | loss: 0.02813 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 506  | total loss: \u001b[1m\u001b[32m0.02792\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 506 | loss: 0.02792 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 507  | total loss: \u001b[1m\u001b[32m0.02771\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 507 | loss: 0.02771 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 508  | total loss: \u001b[1m\u001b[32m0.02750\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 508 | loss: 0.02750 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 509  | total loss: \u001b[1m\u001b[32m0.02730\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 509 | loss: 0.02730 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 510  | total loss: \u001b[1m\u001b[32m0.02710\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 510 | loss: 0.02710 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 511  | total loss: \u001b[1m\u001b[32m0.02691\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 511 | loss: 0.02691 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 512  | total loss: \u001b[1m\u001b[32m0.02672\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 512 | loss: 0.02672 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 513  | total loss: \u001b[1m\u001b[32m0.02654\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 513 | loss: 0.02654 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 514  | total loss: \u001b[1m\u001b[32m0.02635\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 514 | loss: 0.02635 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 515  | total loss: \u001b[1m\u001b[32m0.02617\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 515 | loss: 0.02617 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 516  | total loss: \u001b[1m\u001b[32m0.02599\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 516 | loss: 0.02599 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 517  | total loss: \u001b[1m\u001b[32m0.02582\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 517 | loss: 0.02582 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 518  | total loss: \u001b[1m\u001b[32m0.02565\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 518 | loss: 0.02565 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 519  | total loss: \u001b[1m\u001b[32m0.02548\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 519 | loss: 0.02548 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 520  | total loss: \u001b[1m\u001b[32m0.02531\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 520 | loss: 0.02531 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 521  | total loss: \u001b[1m\u001b[32m0.02514\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 521 | loss: 0.02514 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 522  | total loss: \u001b[1m\u001b[32m0.02498\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 522 | loss: 0.02498 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 523  | total loss: \u001b[1m\u001b[32m0.02482\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 523 | loss: 0.02482 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 524  | total loss: \u001b[1m\u001b[32m0.02466\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 524 | loss: 0.02466 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 525  | total loss: \u001b[1m\u001b[32m0.02450\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 525 | loss: 0.02450 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 526  | total loss: \u001b[1m\u001b[32m0.02435\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 526 | loss: 0.02435 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 527  | total loss: \u001b[1m\u001b[32m0.02419\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 527 | loss: 0.02419 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 528  | total loss: \u001b[1m\u001b[32m0.02404\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 528 | loss: 0.02404 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 529  | total loss: \u001b[1m\u001b[32m0.02389\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 529 | loss: 0.02389 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 530  | total loss: \u001b[1m\u001b[32m0.02374\u001b[0m\u001b[0m | time: 0.013s\n",
      "| Adam | epoch: 530 | loss: 0.02374 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 531  | total loss: \u001b[1m\u001b[32m0.02359\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 531 | loss: 0.02359 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 532  | total loss: \u001b[1m\u001b[32m0.43577\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 532 | loss: 0.43577 - acc: 0.9250 -- iter: 8/8\n",
      "--\n",
      "Training Step: 533  | total loss: \u001b[1m\u001b[32m0.39444\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 533 | loss: 0.39444 - acc: 0.9325 -- iter: 8/8\n",
      "--\n",
      "Training Step: 534  | total loss: \u001b[1m\u001b[32m0.35727\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 534 | loss: 0.35727 - acc: 0.9392 -- iter: 8/8\n",
      "--\n",
      "Training Step: 535  | total loss: \u001b[1m\u001b[32m0.32384\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 535 | loss: 0.32384 - acc: 0.9453 -- iter: 8/8\n",
      "--\n",
      "Training Step: 536  | total loss: \u001b[1m\u001b[32m0.59482\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 536 | loss: 0.59482 - acc: 0.8883 -- iter: 8/8\n",
      "--\n",
      "Training Step: 537  | total loss: \u001b[1m\u001b[32m0.53771\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 537 | loss: 0.53771 - acc: 0.8995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 538  | total loss: \u001b[1m\u001b[32m0.48637\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 538 | loss: 0.48637 - acc: 0.9095 -- iter: 8/8\n",
      "--\n",
      "Training Step: 539  | total loss: \u001b[1m\u001b[32m0.44020\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 539 | loss: 0.44020 - acc: 0.9186 -- iter: 8/8\n",
      "--\n",
      "Training Step: 540  | total loss: \u001b[1m\u001b[32m0.39869\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 540 | loss: 0.39869 - acc: 0.9267 -- iter: 8/8\n",
      "--\n",
      "Training Step: 541  | total loss: \u001b[1m\u001b[32m0.36137\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 541 | loss: 0.36137 - acc: 0.9340 -- iter: 8/8\n",
      "--\n",
      "Training Step: 542  | total loss: \u001b[1m\u001b[32m0.32781\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 542 | loss: 0.32781 - acc: 0.9406 -- iter: 8/8\n",
      "--\n",
      "Training Step: 543  | total loss: \u001b[1m\u001b[32m0.29763\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 543 | loss: 0.29763 - acc: 0.9466 -- iter: 8/8\n",
      "--\n",
      "Training Step: 544  | total loss: \u001b[1m\u001b[32m0.56159\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 544 | loss: 0.56159 - acc: 0.9019 -- iter: 8/8\n",
      "--\n",
      "Training Step: 545  | total loss: \u001b[1m\u001b[32m0.50811\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 545 | loss: 0.50811 - acc: 0.9117 -- iter: 8/8\n",
      "--\n",
      "Training Step: 546  | total loss: \u001b[1m\u001b[32m0.46003\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 546 | loss: 0.46003 - acc: 0.9205 -- iter: 8/8\n",
      "--\n",
      "Training Step: 547  | total loss: \u001b[1m\u001b[32m0.41680\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 547 | loss: 0.41680 - acc: 0.9285 -- iter: 8/8\n",
      "--\n",
      "Training Step: 548  | total loss: \u001b[1m\u001b[32m0.34298\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 548 | loss: 0.34298 - acc: 0.9356 -- iter: 8/8\n",
      "--\n",
      "Training Step: 549  | total loss: \u001b[1m\u001b[32m0.34298\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 549 | loss: 0.34298 - acc: 0.9421 -- iter: 8/8\n",
      "--\n",
      "Training Step: 550  | total loss: \u001b[1m\u001b[32m0.31155\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 550 | loss: 0.31155 - acc: 0.9479 -- iter: 8/8\n",
      "--\n",
      "Training Step: 551  | total loss: \u001b[1m\u001b[32m0.28328\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 551 | loss: 0.28328 - acc: 0.9531 -- iter: 8/8\n",
      "--\n",
      "Training Step: 552  | total loss: \u001b[1m\u001b[32m0.25786\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 552 | loss: 0.25786 - acc: 0.9578 -- iter: 8/8\n",
      "--\n",
      "Training Step: 553  | total loss: \u001b[1m\u001b[32m0.23500\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 553 | loss: 0.23500 - acc: 0.9620 -- iter: 8/8\n",
      "--\n",
      "Training Step: 554  | total loss: \u001b[1m\u001b[32m0.21444\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 554 | loss: 0.21444 - acc: 0.9658 -- iter: 8/8\n",
      "--\n",
      "Training Step: 555  | total loss: \u001b[1m\u001b[32m0.19594\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 555 | loss: 0.19594 - acc: 0.9692 -- iter: 8/8\n",
      "--\n",
      "Training Step: 556  | total loss: \u001b[1m\u001b[32m0.17929\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 556 | loss: 0.17929 - acc: 0.9723 -- iter: 8/8\n",
      "--\n",
      "Training Step: 557  | total loss: \u001b[1m\u001b[32m0.16432\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 557 | loss: 0.16432 - acc: 0.9751 -- iter: 8/8\n",
      "--\n",
      "Training Step: 558  | total loss: \u001b[1m\u001b[32m0.15084\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 558 | loss: 0.15084 - acc: 0.9776 -- iter: 8/8\n",
      "--\n",
      "Training Step: 559  | total loss: \u001b[1m\u001b[32m0.13870\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 559 | loss: 0.13870 - acc: 0.9798 -- iter: 8/8\n",
      "--\n",
      "Training Step: 560  | total loss: \u001b[1m\u001b[32m0.12778\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 560 | loss: 0.12778 - acc: 0.9818 -- iter: 8/8\n",
      "--\n",
      "Training Step: 561  | total loss: \u001b[1m\u001b[32m0.11794\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 561 | loss: 0.11794 - acc: 0.9836 -- iter: 8/8\n",
      "--\n",
      "Training Step: 562  | total loss: \u001b[1m\u001b[32m0.10908\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 562 | loss: 0.10908 - acc: 0.9853 -- iter: 8/8\n",
      "--\n",
      "Training Step: 563  | total loss: \u001b[1m\u001b[32m0.10109\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 563 | loss: 0.10109 - acc: 0.9867 -- iter: 8/8\n",
      "--\n",
      "Training Step: 564  | total loss: \u001b[1m\u001b[32m0.09390\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 564 | loss: 0.09390 - acc: 0.9881 -- iter: 8/8\n",
      "--\n",
      "Training Step: 565  | total loss: \u001b[1m\u001b[32m0.08741\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 565 | loss: 0.08741 - acc: 0.9893 -- iter: 8/8\n",
      "--\n",
      "Training Step: 566  | total loss: \u001b[1m\u001b[32m0.45720\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 566 | loss: 0.45720 - acc: 0.9153 -- iter: 8/8\n",
      "--\n",
      "Training Step: 567  | total loss: \u001b[1m\u001b[32m0.41441\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 567 | loss: 0.41441 - acc: 0.9238 -- iter: 8/8\n",
      "--\n",
      "Training Step: 568  | total loss: \u001b[1m\u001b[32m0.37593\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 568 | loss: 0.37593 - acc: 0.9314 -- iter: 8/8\n",
      "--\n",
      "Training Step: 569  | total loss: \u001b[1m\u001b[32m0.34133\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 569 | loss: 0.34133 - acc: 0.9383 -- iter: 8/8\n",
      "--\n",
      "Training Step: 570  | total loss: \u001b[1m\u001b[32m0.31022\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 570 | loss: 0.31022 - acc: 0.9445 -- iter: 8/8\n",
      "--\n",
      "Training Step: 571  | total loss: \u001b[1m\u001b[32m0.28224\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 571 | loss: 0.28224 - acc: 0.9500 -- iter: 8/8\n",
      "--\n",
      "Training Step: 572  | total loss: \u001b[1m\u001b[32m0.25707\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 572 | loss: 0.25707 - acc: 0.9550 -- iter: 8/8\n",
      "--\n",
      "Training Step: 573  | total loss: \u001b[1m\u001b[32m0.23443\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 573 | loss: 0.23443 - acc: 0.9595 -- iter: 8/8\n",
      "--\n",
      "Training Step: 574  | total loss: \u001b[1m\u001b[32m0.21406\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 574 | loss: 0.21406 - acc: 0.9636 -- iter: 8/8\n",
      "--\n",
      "Training Step: 575  | total loss: \u001b[1m\u001b[32m0.19574\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 575 | loss: 0.19574 - acc: 0.9672 -- iter: 8/8\n",
      "--\n",
      "Training Step: 576  | total loss: \u001b[1m\u001b[32m0.17925\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 576 | loss: 0.17925 - acc: 0.9705 -- iter: 8/8\n",
      "--\n",
      "Training Step: 577  | total loss: \u001b[1m\u001b[32m0.16441\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 577 | loss: 0.16441 - acc: 0.9734 -- iter: 8/8\n",
      "--\n",
      "Training Step: 578  | total loss: \u001b[1m\u001b[32m0.15105\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 578 | loss: 0.15105 - acc: 0.9761 -- iter: 8/8\n",
      "--\n",
      "Training Step: 579  | total loss: \u001b[1m\u001b[32m0.12820\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 579 | loss: 0.12820 - acc: 0.9785 -- iter: 8/8\n",
      "--\n",
      "Training Step: 580  | total loss: \u001b[1m\u001b[32m0.12820\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 580 | loss: 0.12820 - acc: 0.9806 -- iter: 8/8\n",
      "--\n",
      "Training Step: 581  | total loss: \u001b[1m\u001b[32m0.11845\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 581 | loss: 0.11845 - acc: 0.9826 -- iter: 8/8\n",
      "--\n",
      "Training Step: 582  | total loss: \u001b[1m\u001b[32m0.10967\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 582 | loss: 0.10967 - acc: 0.9843 -- iter: 8/8\n",
      "--\n",
      "Training Step: 583  | total loss: \u001b[1m\u001b[32m0.10175\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 583 | loss: 0.10175 - acc: 0.9859 -- iter: 8/8\n",
      "--\n",
      "Training Step: 584  | total loss: \u001b[1m\u001b[32m0.09462\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 584 | loss: 0.09462 - acc: 0.9873 -- iter: 8/8\n",
      "--\n",
      "Training Step: 585  | total loss: \u001b[1m\u001b[32m0.08819\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 585 | loss: 0.08819 - acc: 0.9886 -- iter: 8/8\n",
      "--\n",
      "Training Step: 586  | total loss: \u001b[1m\u001b[32m0.08238\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 586 | loss: 0.08238 - acc: 0.9897 -- iter: 8/8\n",
      "--\n",
      "Training Step: 587  | total loss: \u001b[1m\u001b[32m0.07715\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 587 | loss: 0.07715 - acc: 0.9907 -- iter: 8/8\n",
      "--\n",
      "Training Step: 588  | total loss: \u001b[1m\u001b[32m0.07243\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 588 | loss: 0.07243 - acc: 0.9917 -- iter: 8/8\n",
      "--\n",
      "Training Step: 589  | total loss: \u001b[1m\u001b[32m0.06816\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 589 | loss: 0.06816 - acc: 0.9925 -- iter: 8/8\n",
      "--\n",
      "Training Step: 590  | total loss: \u001b[1m\u001b[32m0.06431\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 590 | loss: 0.06431 - acc: 0.9932 -- iter: 8/8\n",
      "--\n",
      "Training Step: 591  | total loss: \u001b[1m\u001b[32m0.06083\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 591 | loss: 0.06083 - acc: 0.9939 -- iter: 8/8\n",
      "--\n",
      "Training Step: 592  | total loss: \u001b[1m\u001b[32m0.05768\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 592 | loss: 0.05768 - acc: 0.9945 -- iter: 8/8\n",
      "--\n",
      "Training Step: 593  | total loss: \u001b[1m\u001b[32m0.05483\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 593 | loss: 0.05483 - acc: 0.9951 -- iter: 8/8\n",
      "--\n",
      "Training Step: 594  | total loss: \u001b[1m\u001b[32m0.05225\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 594 | loss: 0.05225 - acc: 0.9956 -- iter: 8/8\n",
      "--\n",
      "Training Step: 595  | total loss: \u001b[1m\u001b[32m0.04992\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 595 | loss: 0.04992 - acc: 0.9960 -- iter: 8/8\n",
      "--\n",
      "Training Step: 596  | total loss: \u001b[1m\u001b[32m0.04780\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 596 | loss: 0.04780 - acc: 0.9964 -- iter: 8/8\n",
      "--\n",
      "Training Step: 597  | total loss: \u001b[1m\u001b[32m0.04588\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 597 | loss: 0.04588 - acc: 0.9968 -- iter: 8/8\n",
      "--\n",
      "Training Step: 598  | total loss: \u001b[1m\u001b[32m0.04413\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 598 | loss: 0.04413 - acc: 0.9971 -- iter: 8/8\n",
      "--\n",
      "Training Step: 599  | total loss: \u001b[1m\u001b[32m0.04254\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 599 | loss: 0.04254 - acc: 0.9974 -- iter: 8/8\n",
      "--\n",
      "Training Step: 600  | total loss: \u001b[1m\u001b[32m0.04110\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 600 | loss: 0.04110 - acc: 0.9976 -- iter: 8/8\n",
      "--\n",
      "Training Step: 601  | total loss: \u001b[1m\u001b[32m0.03978\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 601 | loss: 0.03978 - acc: 0.9979 -- iter: 8/8\n",
      "--\n",
      "Training Step: 602  | total loss: \u001b[1m\u001b[32m0.03858\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 602 | loss: 0.03858 - acc: 0.9981 -- iter: 8/8\n",
      "--\n",
      "Training Step: 603  | total loss: \u001b[1m\u001b[32m0.03749\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 603 | loss: 0.03749 - acc: 0.9983 -- iter: 8/8\n",
      "--\n",
      "Training Step: 604  | total loss: \u001b[1m\u001b[32m0.32127\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 604 | loss: 0.32127 - acc: 0.9360 -- iter: 8/8\n",
      "--\n",
      "Training Step: 605  | total loss: \u001b[1m\u001b[32m0.29192\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 605 | loss: 0.29192 - acc: 0.9424 -- iter: 8/8\n",
      "--\n",
      "Training Step: 606  | total loss: \u001b[1m\u001b[32m0.26551\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 606 | loss: 0.26551 - acc: 0.9481 -- iter: 8/8\n",
      "--\n",
      "Training Step: 607  | total loss: \u001b[1m\u001b[32m0.24176\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 607 | loss: 0.24176 - acc: 0.9533 -- iter: 8/8\n",
      "--\n",
      "Training Step: 608  | total loss: \u001b[1m\u001b[32m0.22040\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 608 | loss: 0.22040 - acc: 0.9580 -- iter: 8/8\n",
      "--\n",
      "Training Step: 609  | total loss: \u001b[1m\u001b[32m0.20119\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 609 | loss: 0.20119 - acc: 0.9622 -- iter: 8/8\n",
      "--\n",
      "Training Step: 610  | total loss: \u001b[1m\u001b[32m0.18390\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 610 | loss: 0.18390 - acc: 0.9660 -- iter: 8/8\n",
      "--\n",
      "Training Step: 611  | total loss: \u001b[1m\u001b[32m0.16835\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 611 | loss: 0.16835 - acc: 0.9694 -- iter: 8/8\n",
      "--\n",
      "Training Step: 612  | total loss: \u001b[1m\u001b[32m0.15435\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 612 | loss: 0.15435 - acc: 0.9724 -- iter: 8/8\n",
      "--\n",
      "Training Step: 613  | total loss: \u001b[1m\u001b[32m0.14176\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 613 | loss: 0.14176 - acc: 0.9752 -- iter: 8/8\n",
      "--\n",
      "Training Step: 614  | total loss: \u001b[1m\u001b[32m0.13042\u001b[0m\u001b[0m | time: 0.015s\n",
      "| Adam | epoch: 614 | loss: 0.13042 - acc: 0.9777 -- iter: 8/8\n",
      "--\n",
      "Training Step: 615  | total loss: \u001b[1m\u001b[32m0.12022\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 615 | loss: 0.12022 - acc: 0.9799 -- iter: 8/8\n",
      "--\n",
      "Training Step: 616  | total loss: \u001b[1m\u001b[32m0.11103\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 616 | loss: 0.11103 - acc: 0.9819 -- iter: 8/8\n",
      "--\n",
      "Training Step: 617  | total loss: \u001b[1m\u001b[32m0.10276\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 617 | loss: 0.10276 - acc: 0.9837 -- iter: 8/8\n",
      "--\n",
      "Training Step: 618  | total loss: \u001b[1m\u001b[32m0.09530\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 618 | loss: 0.09530 - acc: 0.9853 -- iter: 8/8\n",
      "--\n",
      "Training Step: 619  | total loss: \u001b[1m\u001b[32m0.08859\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 619 | loss: 0.08859 - acc: 0.9868 -- iter: 8/8\n",
      "--\n",
      "Training Step: 620  | total loss: \u001b[1m\u001b[32m0.08254\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 620 | loss: 0.08254 - acc: 0.9881 -- iter: 8/8\n",
      "--\n",
      "Training Step: 621  | total loss: \u001b[1m\u001b[32m0.07708\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 621 | loss: 0.07708 - acc: 0.9893 -- iter: 8/8\n",
      "--\n",
      "Training Step: 622  | total loss: \u001b[1m\u001b[32m0.07216\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 622 | loss: 0.07216 - acc: 0.9904 -- iter: 8/8\n",
      "--\n",
      "Training Step: 623  | total loss: \u001b[1m\u001b[32m0.06372\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 623 | loss: 0.06372 - acc: 0.9913 -- iter: 8/8\n",
      "--\n",
      "Training Step: 624  | total loss: \u001b[1m\u001b[32m0.06372\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 624 | loss: 0.06372 - acc: 0.9922 -- iter: 8/8\n",
      "--\n",
      "Training Step: 625  | total loss: \u001b[1m\u001b[32m0.06011\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 625 | loss: 0.06011 - acc: 0.9930 -- iter: 8/8\n",
      "--\n",
      "Training Step: 626  | total loss: \u001b[1m\u001b[32m0.05684\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 626 | loss: 0.05684 - acc: 0.9937 -- iter: 8/8\n",
      "--\n",
      "Training Step: 627  | total loss: \u001b[1m\u001b[32m0.05389\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 627 | loss: 0.05389 - acc: 0.9943 -- iter: 8/8\n",
      "--\n",
      "Training Step: 628  | total loss: \u001b[1m\u001b[32m0.05122\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 628 | loss: 0.05122 - acc: 0.9949 -- iter: 8/8\n",
      "--\n",
      "Training Step: 629  | total loss: \u001b[1m\u001b[32m0.04881\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 629 | loss: 0.04881 - acc: 0.9954 -- iter: 8/8\n",
      "--\n",
      "Training Step: 630  | total loss: \u001b[1m\u001b[32m0.04662\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 630 | loss: 0.04662 - acc: 0.9959 -- iter: 8/8\n",
      "--\n",
      "Training Step: 631  | total loss: \u001b[1m\u001b[32m0.04464\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 631 | loss: 0.04464 - acc: 0.9963 -- iter: 8/8\n",
      "--\n",
      "Training Step: 632  | total loss: \u001b[1m\u001b[32m0.04285\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 632 | loss: 0.04285 - acc: 0.9966 -- iter: 8/8\n",
      "--\n",
      "Training Step: 633  | total loss: \u001b[1m\u001b[32m0.04122\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 633 | loss: 0.04122 - acc: 0.9970 -- iter: 8/8\n",
      "--\n",
      "Training Step: 634  | total loss: \u001b[1m\u001b[32m0.03974\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 634 | loss: 0.03974 - acc: 0.9973 -- iter: 8/8\n",
      "--\n",
      "Training Step: 635  | total loss: \u001b[1m\u001b[32m0.03839\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 635 | loss: 0.03839 - acc: 0.9976 -- iter: 8/8\n",
      "--\n",
      "Training Step: 636  | total loss: \u001b[1m\u001b[32m0.03717\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 636 | loss: 0.03717 - acc: 0.9978 -- iter: 8/8\n",
      "--\n",
      "Training Step: 637  | total loss: \u001b[1m\u001b[32m0.03606\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 637 | loss: 0.03606 - acc: 0.9980 -- iter: 8/8\n",
      "--\n",
      "Training Step: 638  | total loss: \u001b[1m\u001b[32m0.03504\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 638 | loss: 0.03504 - acc: 0.9982 -- iter: 8/8\n",
      "--\n",
      "Training Step: 639  | total loss: \u001b[1m\u001b[32m0.03411\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 639 | loss: 0.03411 - acc: 0.9984 -- iter: 8/8\n",
      "--\n",
      "Training Step: 640  | total loss: \u001b[1m\u001b[32m0.03326\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 640 | loss: 0.03326 - acc: 0.9986 -- iter: 8/8\n",
      "--\n",
      "Training Step: 641  | total loss: \u001b[1m\u001b[32m0.03248\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 641 | loss: 0.03248 - acc: 0.9987 -- iter: 8/8\n",
      "--\n",
      "Training Step: 642  | total loss: \u001b[1m\u001b[32m0.03177\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 642 | loss: 0.03177 - acc: 0.9988 -- iter: 8/8\n",
      "--\n",
      "Training Step: 643  | total loss: \u001b[1m\u001b[32m0.03111\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 643 | loss: 0.03111 - acc: 0.9989 -- iter: 8/8\n",
      "--\n",
      "Training Step: 644  | total loss: \u001b[1m\u001b[32m0.03050\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 644 | loss: 0.03050 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 645  | total loss: \u001b[1m\u001b[32m0.02995\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 645 | loss: 0.02995 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 646  | total loss: \u001b[1m\u001b[32m0.02943\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 646 | loss: 0.02943 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 647  | total loss: \u001b[1m\u001b[32m0.02896\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 647 | loss: 0.02896 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 648  | total loss: \u001b[1m\u001b[32m0.02851\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 648 | loss: 0.02851 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 649  | total loss: \u001b[1m\u001b[32m0.02810\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 649 | loss: 0.02810 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 650  | total loss: \u001b[1m\u001b[32m0.02772\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 650 | loss: 0.02772 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 651  | total loss: \u001b[1m\u001b[32m0.02736\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 651 | loss: 0.02736 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 652  | total loss: \u001b[1m\u001b[32m0.02702\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 652 | loss: 0.02702 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 653  | total loss: \u001b[1m\u001b[32m0.02671\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 653 | loss: 0.02671 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 654  | total loss: \u001b[1m\u001b[32m0.02641\u001b[0m\u001b[0m | time: 0.015s\n",
      "| Adam | epoch: 654 | loss: 0.02641 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 655  | total loss: \u001b[1m\u001b[32m0.02613\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 655 | loss: 0.02613 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 656  | total loss: \u001b[1m\u001b[32m0.02587\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 656 | loss: 0.02587 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 657  | total loss: \u001b[1m\u001b[32m0.02562\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 657 | loss: 0.02562 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 658  | total loss: \u001b[1m\u001b[32m0.02538\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 658 | loss: 0.02538 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 659  | total loss: \u001b[1m\u001b[32m0.02516\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 659 | loss: 0.02516 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 660  | total loss: \u001b[1m\u001b[32m0.02494\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 660 | loss: 0.02494 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 661  | total loss: \u001b[1m\u001b[32m0.02473\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 661 | loss: 0.02473 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 662  | total loss: \u001b[1m\u001b[32m0.02453\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 662 | loss: 0.02453 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 663  | total loss: \u001b[1m\u001b[32m0.02434\u001b[0m\u001b[0m | time: 0.015s\n",
      "| Adam | epoch: 663 | loss: 0.02434 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 664  | total loss: \u001b[1m\u001b[32m0.31786\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 664 | loss: 0.31786 - acc: 0.9374 -- iter: 8/8\n",
      "--\n",
      "Training Step: 665  | total loss: \u001b[1m\u001b[32m0.28834\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 665 | loss: 0.28834 - acc: 0.9436 -- iter: 8/8\n",
      "--\n",
      "Training Step: 666  | total loss: \u001b[1m\u001b[32m0.26180\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 666 | loss: 0.26180 - acc: 0.9493 -- iter: 8/8\n",
      "--\n",
      "Training Step: 667  | total loss: \u001b[1m\u001b[32m0.21644\u001b[0m\u001b[0m | time: 0.017s\n",
      "| Adam | epoch: 667 | loss: 0.21644 - acc: 0.9544 -- iter: 8/8\n",
      "--\n",
      "Training Step: 668  | total loss: \u001b[1m\u001b[32m0.21644\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 668 | loss: 0.21644 - acc: 0.9589 -- iter: 8/8\n",
      "--\n",
      "Training Step: 669  | total loss: \u001b[1m\u001b[32m0.19712\u001b[0m\u001b[0m | time: 0.020s\n",
      "| Adam | epoch: 669 | loss: 0.19712 - acc: 0.9630 -- iter: 8/8\n",
      "--\n",
      "Training Step: 670  | total loss: \u001b[1m\u001b[32m0.17975\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 670 | loss: 0.17975 - acc: 0.9667 -- iter: 8/8\n",
      "--\n",
      "Training Step: 671  | total loss: \u001b[1m\u001b[32m0.16411\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 671 | loss: 0.16411 - acc: 0.9701 -- iter: 8/8\n",
      "--\n",
      "Training Step: 672  | total loss: \u001b[1m\u001b[32m0.15004\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 672 | loss: 0.15004 - acc: 0.9730 -- iter: 8/8\n",
      "--\n",
      "Training Step: 673  | total loss: \u001b[1m\u001b[32m0.13739\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 673 | loss: 0.13739 - acc: 0.9757 -- iter: 8/8\n",
      "--\n",
      "Training Step: 674  | total loss: \u001b[1m\u001b[32m0.12599\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 674 | loss: 0.12599 - acc: 0.9782 -- iter: 8/8\n",
      "--\n",
      "Training Step: 675  | total loss: \u001b[1m\u001b[32m0.11574\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 675 | loss: 0.11574 - acc: 0.9804 -- iter: 8/8\n",
      "--\n",
      "Training Step: 676  | total loss: \u001b[1m\u001b[32m0.10652\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 676 | loss: 0.10652 - acc: 0.9823 -- iter: 8/8\n",
      "--\n",
      "Training Step: 677  | total loss: \u001b[1m\u001b[32m0.09821\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 677 | loss: 0.09821 - acc: 0.9841 -- iter: 8/8\n",
      "--\n",
      "Training Step: 678  | total loss: \u001b[1m\u001b[32m0.09073\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 678 | loss: 0.09073 - acc: 0.9857 -- iter: 8/8\n",
      "--\n",
      "Training Step: 679  | total loss: \u001b[1m\u001b[32m0.08399\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 679 | loss: 0.08399 - acc: 0.9871 -- iter: 8/8\n",
      "--\n",
      "Training Step: 680  | total loss: \u001b[1m\u001b[32m0.07792\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 680 | loss: 0.07792 - acc: 0.9884 -- iter: 8/8\n",
      "--\n",
      "Training Step: 681  | total loss: \u001b[1m\u001b[32m0.07246\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 681 | loss: 0.07246 - acc: 0.9896 -- iter: 8/8\n",
      "--\n",
      "Training Step: 682  | total loss: \u001b[1m\u001b[32m0.06753\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 682 | loss: 0.06753 - acc: 0.9906 -- iter: 8/8\n",
      "--\n",
      "Training Step: 683  | total loss: \u001b[1m\u001b[32m0.06309\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 683 | loss: 0.06309 - acc: 0.9915 -- iter: 8/8\n",
      "--\n",
      "Training Step: 684  | total loss: \u001b[1m\u001b[32m0.05909\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 684 | loss: 0.05909 - acc: 0.9924 -- iter: 8/8\n",
      "--\n",
      "Training Step: 685  | total loss: \u001b[1m\u001b[32m0.05548\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 685 | loss: 0.05548 - acc: 0.9931 -- iter: 8/8\n",
      "--\n",
      "Training Step: 686  | total loss: \u001b[1m\u001b[32m0.05222\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 686 | loss: 0.05222 - acc: 0.9938 -- iter: 8/8\n",
      "--\n",
      "Training Step: 687  | total loss: \u001b[1m\u001b[32m0.04928\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 687 | loss: 0.04928 - acc: 0.9945 -- iter: 8/8\n",
      "--\n",
      "Training Step: 688  | total loss: \u001b[1m\u001b[32m0.04662\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 688 | loss: 0.04662 - acc: 0.9950 -- iter: 8/8\n",
      "--\n",
      "Training Step: 689  | total loss: \u001b[1m\u001b[32m0.04422\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 689 | loss: 0.04422 - acc: 0.9955 -- iter: 8/8\n",
      "--\n",
      "Training Step: 690  | total loss: \u001b[1m\u001b[32m0.04205\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 690 | loss: 0.04205 - acc: 0.9960 -- iter: 8/8\n",
      "--\n",
      "Training Step: 691  | total loss: \u001b[1m\u001b[32m0.04009\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 691 | loss: 0.04009 - acc: 0.9964 -- iter: 8/8\n",
      "--\n",
      "Training Step: 692  | total loss: \u001b[1m\u001b[32m0.03832\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 692 | loss: 0.03832 - acc: 0.9967 -- iter: 8/8\n",
      "--\n",
      "Training Step: 693  | total loss: \u001b[1m\u001b[32m0.03671\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 693 | loss: 0.03671 - acc: 0.9971 -- iter: 8/8\n",
      "--\n",
      "Training Step: 694  | total loss: \u001b[1m\u001b[32m0.03525\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 694 | loss: 0.03525 - acc: 0.9973 -- iter: 8/8\n",
      "--\n",
      "Training Step: 695  | total loss: \u001b[1m\u001b[32m0.03393\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 695 | loss: 0.03393 - acc: 0.9976 -- iter: 8/8\n",
      "--\n",
      "Training Step: 696  | total loss: \u001b[1m\u001b[32m0.03273\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 696 | loss: 0.03273 - acc: 0.9979 -- iter: 8/8\n",
      "--\n",
      "Training Step: 697  | total loss: \u001b[1m\u001b[32m0.03164\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 697 | loss: 0.03164 - acc: 0.9981 -- iter: 8/8\n",
      "--\n",
      "Training Step: 698  | total loss: \u001b[1m\u001b[32m0.03065\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 698 | loss: 0.03065 - acc: 0.9983 -- iter: 8/8\n",
      "--\n",
      "Training Step: 699  | total loss: \u001b[1m\u001b[32m0.02975\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 699 | loss: 0.02975 - acc: 0.9984 -- iter: 8/8\n",
      "--\n",
      "Training Step: 700  | total loss: \u001b[1m\u001b[32m0.02893\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 700 | loss: 0.02893 - acc: 0.9986 -- iter: 8/8\n",
      "--\n",
      "Training Step: 701  | total loss: \u001b[1m\u001b[32m0.02749\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 701 | loss: 0.02749 - acc: 0.9987 -- iter: 8/8\n",
      "--\n",
      "Training Step: 702  | total loss: \u001b[1m\u001b[32m0.02749\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 702 | loss: 0.02749 - acc: 0.9989 -- iter: 8/8\n",
      "--\n",
      "Training Step: 703  | total loss: \u001b[1m\u001b[32m0.02686\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 703 | loss: 0.02686 - acc: 0.9990 -- iter: 8/8\n",
      "--\n",
      "Training Step: 704  | total loss: \u001b[1m\u001b[32m0.02629\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 704 | loss: 0.02629 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 705  | total loss: \u001b[1m\u001b[32m0.02576\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 705 | loss: 0.02576 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 706  | total loss: \u001b[1m\u001b[32m0.02528\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 706 | loss: 0.02528 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 707  | total loss: \u001b[1m\u001b[32m0.02442\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 707 | loss: 0.02442 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 708  | total loss: \u001b[1m\u001b[32m0.02442\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 708 | loss: 0.02442 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 709  | total loss: \u001b[1m\u001b[32m0.02404\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 709 | loss: 0.02404 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 710  | total loss: \u001b[1m\u001b[32m0.02368\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 710 | loss: 0.02368 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 711  | total loss: \u001b[1m\u001b[32m0.02335\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 711 | loss: 0.02335 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 712  | total loss: \u001b[1m\u001b[32m0.02305\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 712 | loss: 0.02305 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 713  | total loss: \u001b[1m\u001b[32m0.02277\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 713 | loss: 0.02277 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 714  | total loss: \u001b[1m\u001b[32m0.02250\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 714 | loss: 0.02250 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 715  | total loss: \u001b[1m\u001b[32m0.02225\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 715 | loss: 0.02225 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 716  | total loss: \u001b[1m\u001b[32m0.02202\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 716 | loss: 0.02202 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 717  | total loss: \u001b[1m\u001b[32m0.02180\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 717 | loss: 0.02180 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 718  | total loss: \u001b[1m\u001b[32m0.02159\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 718 | loss: 0.02159 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 719  | total loss: \u001b[1m\u001b[32m0.02139\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 719 | loss: 0.02139 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 720  | total loss: \u001b[1m\u001b[32m0.02120\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 720 | loss: 0.02120 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 721  | total loss: \u001b[1m\u001b[32m0.02103\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 721 | loss: 0.02103 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 722  | total loss: \u001b[1m\u001b[32m0.31695\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 722 | loss: 0.31695 - acc: 0.9374 -- iter: 8/8\n",
      "--\n",
      "Training Step: 723  | total loss: \u001b[1m\u001b[32m0.28721\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 723 | loss: 0.28721 - acc: 0.9436 -- iter: 8/8\n",
      "--\n",
      "Training Step: 724  | total loss: \u001b[1m\u001b[32m0.26046\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 724 | loss: 0.26046 - acc: 0.9493 -- iter: 8/8\n",
      "--\n",
      "Training Step: 725  | total loss: \u001b[1m\u001b[32m0.23640\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 725 | loss: 0.23640 - acc: 0.9543 -- iter: 8/8\n",
      "--\n",
      "Training Step: 726  | total loss: \u001b[1m\u001b[32m0.21476\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 726 | loss: 0.21476 - acc: 0.9589 -- iter: 8/8\n",
      "--\n",
      "Training Step: 727  | total loss: \u001b[1m\u001b[32m0.19529\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 727 | loss: 0.19529 - acc: 0.9630 -- iter: 8/8\n",
      "--\n",
      "Training Step: 728  | total loss: \u001b[1m\u001b[32m0.17779\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 728 | loss: 0.17779 - acc: 0.9667 -- iter: 8/8\n",
      "--\n",
      "Training Step: 729  | total loss: \u001b[1m\u001b[32m0.16203\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 729 | loss: 0.16203 - acc: 0.9700 -- iter: 8/8\n",
      "--\n",
      "Training Step: 730  | total loss: \u001b[1m\u001b[32m0.14786\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 730 | loss: 0.14786 - acc: 0.9730 -- iter: 8/8\n",
      "--\n",
      "Training Step: 731  | total loss: \u001b[1m\u001b[32m0.13511\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 731 | loss: 0.13511 - acc: 0.9757 -- iter: 8/8\n",
      "--\n",
      "Training Step: 732  | total loss: \u001b[1m\u001b[32m0.12364\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 732 | loss: 0.12364 - acc: 0.9782 -- iter: 8/8\n",
      "--\n",
      "Training Step: 733  | total loss: \u001b[1m\u001b[32m0.11332\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 733 | loss: 0.11332 - acc: 0.9803 -- iter: 8/8\n",
      "--\n",
      "Training Step: 734  | total loss: \u001b[1m\u001b[32m0.10403\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 734 | loss: 0.10403 - acc: 0.9823 -- iter: 8/8\n",
      "--\n",
      "Training Step: 735  | total loss: \u001b[1m\u001b[32m0.09567\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 735 | loss: 0.09567 - acc: 0.9841 -- iter: 8/8\n",
      "--\n",
      "Training Step: 736  | total loss: \u001b[1m\u001b[32m0.08814\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 736 | loss: 0.08814 - acc: 0.9857 -- iter: 8/8\n",
      "--\n",
      "Training Step: 737  | total loss: \u001b[1m\u001b[32m0.08137\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 737 | loss: 0.08137 - acc: 0.9871 -- iter: 8/8\n",
      "--\n",
      "Training Step: 738  | total loss: \u001b[1m\u001b[32m0.07526\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 738 | loss: 0.07526 - acc: 0.9884 -- iter: 8/8\n",
      "--\n",
      "Training Step: 739  | total loss: \u001b[1m\u001b[32m0.06977\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 739 | loss: 0.06977 - acc: 0.9896 -- iter: 8/8\n",
      "--\n",
      "Training Step: 740  | total loss: \u001b[1m\u001b[32m0.06482\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 740 | loss: 0.06482 - acc: 0.9906 -- iter: 8/8\n",
      "--\n",
      "Training Step: 741  | total loss: \u001b[1m\u001b[32m0.06036\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 741 | loss: 0.06036 - acc: 0.9915 -- iter: 8/8\n",
      "--\n",
      "Training Step: 742  | total loss: \u001b[1m\u001b[32m0.05634\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 742 | loss: 0.05634 - acc: 0.9924 -- iter: 8/8\n",
      "--\n",
      "Training Step: 743  | total loss: \u001b[1m\u001b[32m0.05271\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 743 | loss: 0.05271 - acc: 0.9931 -- iter: 8/8\n",
      "--\n",
      "Training Step: 744  | total loss: \u001b[1m\u001b[32m0.04944\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 744 | loss: 0.04944 - acc: 0.9938 -- iter: 8/8\n",
      "--\n",
      "Training Step: 745  | total loss: \u001b[1m\u001b[32m0.04650\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 745 | loss: 0.04650 - acc: 0.9944 -- iter: 8/8\n",
      "--\n",
      "Training Step: 746  | total loss: \u001b[1m\u001b[32m0.04384\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 746 | loss: 0.04384 - acc: 0.9950 -- iter: 8/8\n",
      "--\n",
      "Training Step: 747  | total loss: \u001b[1m\u001b[32m0.03927\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 747 | loss: 0.03927 - acc: 0.9955 -- iter: 8/8\n",
      "--\n",
      "Training Step: 748  | total loss: \u001b[1m\u001b[32m0.03927\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 748 | loss: 0.03927 - acc: 0.9960 -- iter: 8/8\n",
      "--\n",
      "Training Step: 749  | total loss: \u001b[1m\u001b[32m0.03731\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 749 | loss: 0.03731 - acc: 0.9964 -- iter: 8/8\n",
      "--\n",
      "Training Step: 750  | total loss: \u001b[1m\u001b[32m0.03554\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 750 | loss: 0.03554 - acc: 0.9967 -- iter: 8/8\n",
      "--\n",
      "Training Step: 751  | total loss: \u001b[1m\u001b[32m0.03249\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 751 | loss: 0.03249 - acc: 0.9970 -- iter: 8/8\n",
      "--\n",
      "Training Step: 752  | total loss: \u001b[1m\u001b[32m0.03249\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 752 | loss: 0.03249 - acc: 0.9973 -- iter: 8/8\n",
      "--\n",
      "Training Step: 753  | total loss: \u001b[1m\u001b[32m0.03117\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 753 | loss: 0.03117 - acc: 0.9976 -- iter: 8/8\n",
      "--\n",
      "Training Step: 754  | total loss: \u001b[1m\u001b[32m0.02998\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 754 | loss: 0.02998 - acc: 0.9978 -- iter: 8/8\n",
      "--\n",
      "Training Step: 755  | total loss: \u001b[1m\u001b[32m0.02890\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 755 | loss: 0.02890 - acc: 0.9981 -- iter: 8/8\n",
      "--\n",
      "Training Step: 756  | total loss: \u001b[1m\u001b[32m0.02704\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 756 | loss: 0.02704 - acc: 0.9983 -- iter: 8/8\n",
      "--\n",
      "Training Step: 757  | total loss: \u001b[1m\u001b[32m0.02623\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 757 | loss: 0.02623 - acc: 0.9984 -- iter: 8/8\n",
      "--\n",
      "Training Step: 758  | total loss: \u001b[1m\u001b[32m0.02623\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 758 | loss: 0.02623 - acc: 0.9986 -- iter: 8/8\n",
      "--\n",
      "Training Step: 759  | total loss: \u001b[1m\u001b[32m0.02549\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 759 | loss: 0.02549 - acc: 0.9987 -- iter: 8/8\n",
      "--\n",
      "Training Step: 760  | total loss: \u001b[1m\u001b[32m0.02482\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 760 | loss: 0.02482 - acc: 0.9989 -- iter: 8/8\n",
      "--\n",
      "Training Step: 761  | total loss: \u001b[1m\u001b[32m0.02420\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 761 | loss: 0.02420 - acc: 0.9990 -- iter: 8/8\n",
      "--\n",
      "Training Step: 762  | total loss: \u001b[1m\u001b[32m0.02364\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 762 | loss: 0.02364 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 763  | total loss: \u001b[1m\u001b[32m0.02313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 763 | loss: 0.02313 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 764  | total loss: \u001b[1m\u001b[32m0.42584\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 764 | loss: 0.42584 - acc: 0.9243 -- iter: 8/8\n",
      "--\n",
      "Training Step: 765  | total loss: \u001b[1m\u001b[32m0.38513\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 765 | loss: 0.38513 - acc: 0.9318 -- iter: 8/8\n",
      "--\n",
      "Training Step: 766  | total loss: \u001b[1m\u001b[32m0.34851\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 766 | loss: 0.34851 - acc: 0.9386 -- iter: 8/8\n",
      "--\n",
      "Training Step: 767  | total loss: \u001b[1m\u001b[32m0.31557\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 767 | loss: 0.31557 - acc: 0.9448 -- iter: 8/8\n",
      "--\n",
      "Training Step: 768  | total loss: \u001b[1m\u001b[32m0.28594\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 768 | loss: 0.28594 - acc: 0.9503 -- iter: 8/8\n",
      "--\n",
      "Training Step: 769  | total loss: \u001b[1m\u001b[32m0.25930\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 769 | loss: 0.25930 - acc: 0.9553 -- iter: 8/8\n",
      "--\n",
      "Training Step: 770  | total loss: \u001b[1m\u001b[32m0.23532\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 770 | loss: 0.23532 - acc: 0.9597 -- iter: 8/8\n",
      "--\n",
      "Training Step: 771  | total loss: \u001b[1m\u001b[32m0.21376\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 771 | loss: 0.21376 - acc: 0.9638 -- iter: 8/8\n",
      "--\n",
      "Training Step: 772  | total loss: \u001b[1m\u001b[32m0.19436\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 772 | loss: 0.19436 - acc: 0.9674 -- iter: 8/8\n",
      "--\n",
      "Training Step: 773  | total loss: \u001b[1m\u001b[32m0.17691\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 773 | loss: 0.17691 - acc: 0.9707 -- iter: 8/8\n",
      "--\n",
      "Training Step: 774  | total loss: \u001b[1m\u001b[32m0.16121\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 774 | loss: 0.16121 - acc: 0.9736 -- iter: 8/8\n",
      "--\n",
      "Training Step: 775  | total loss: \u001b[1m\u001b[32m0.14709\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 775 | loss: 0.14709 - acc: 0.9762 -- iter: 8/8\n",
      "--\n",
      "Training Step: 776  | total loss: \u001b[1m\u001b[32m0.13438\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 776 | loss: 0.13438 - acc: 0.9786 -- iter: 8/8\n",
      "--\n",
      "Training Step: 777  | total loss: \u001b[1m\u001b[32m0.12294\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 777 | loss: 0.12294 - acc: 0.9807 -- iter: 8/8\n",
      "--\n",
      "Training Step: 778  | total loss: \u001b[1m\u001b[32m0.11264\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 778 | loss: 0.11264 - acc: 0.9827 -- iter: 8/8\n",
      "--\n",
      "Training Step: 779  | total loss: \u001b[1m\u001b[32m0.10338\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 779 | loss: 0.10338 - acc: 0.9844 -- iter: 8/8\n",
      "--\n",
      "Training Step: 780  | total loss: \u001b[1m\u001b[32m0.09504\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 780 | loss: 0.09504 - acc: 0.9860 -- iter: 8/8\n",
      "--\n",
      "Training Step: 781  | total loss: \u001b[1m\u001b[32m0.08753\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 781 | loss: 0.08753 - acc: 0.9874 -- iter: 8/8\n",
      "--\n",
      "Training Step: 782  | total loss: \u001b[1m\u001b[32m0.08077\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 782 | loss: 0.08077 - acc: 0.9886 -- iter: 8/8\n",
      "--\n",
      "Training Step: 783  | total loss: \u001b[1m\u001b[32m0.07468\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 783 | loss: 0.07468 - acc: 0.9898 -- iter: 8/8\n",
      "--\n",
      "Training Step: 784  | total loss: \u001b[1m\u001b[32m0.06919\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 784 | loss: 0.06919 - acc: 0.9908 -- iter: 8/8\n",
      "--\n",
      "Training Step: 785  | total loss: \u001b[1m\u001b[32m0.06425\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 785 | loss: 0.06425 - acc: 0.9917 -- iter: 8/8\n",
      "--\n",
      "Training Step: 786  | total loss: \u001b[1m\u001b[32m0.05980\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 786 | loss: 0.05980 - acc: 0.9925 -- iter: 8/8\n",
      "--\n",
      "Training Step: 787  | total loss: \u001b[1m\u001b[32m0.05579\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 787 | loss: 0.05579 - acc: 0.9933 -- iter: 8/8\n",
      "--\n",
      "Training Step: 788  | total loss: \u001b[1m\u001b[32m0.05217\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 788 | loss: 0.05217 - acc: 0.9940 -- iter: 8/8\n",
      "--\n",
      "Training Step: 789  | total loss: \u001b[1m\u001b[32m0.04891\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 789 | loss: 0.04891 - acc: 0.9946 -- iter: 8/8\n",
      "--\n",
      "Training Step: 790  | total loss: \u001b[1m\u001b[32m0.04331\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 790 | loss: 0.04331 - acc: 0.9951 -- iter: 8/8\n",
      "--\n",
      "Training Step: 791  | total loss: \u001b[1m\u001b[32m0.04331\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 791 | loss: 0.04331 - acc: 0.9956 -- iter: 8/8\n",
      "--\n",
      "Training Step: 792  | total loss: \u001b[1m\u001b[32m0.04091\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 792 | loss: 0.04091 - acc: 0.9960 -- iter: 8/8\n",
      "--\n",
      "Training Step: 793  | total loss: \u001b[1m\u001b[32m0.03875\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 793 | loss: 0.03875 - acc: 0.9964 -- iter: 8/8\n",
      "--\n",
      "Training Step: 794  | total loss: \u001b[1m\u001b[32m0.03679\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 794 | loss: 0.03679 - acc: 0.9968 -- iter: 8/8\n",
      "--\n",
      "Training Step: 795  | total loss: \u001b[1m\u001b[32m0.03502\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 795 | loss: 0.03502 - acc: 0.9971 -- iter: 8/8\n",
      "--\n",
      "Training Step: 796  | total loss: \u001b[1m\u001b[32m0.03342\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 796 | loss: 0.03342 - acc: 0.9974 -- iter: 8/8\n",
      "--\n",
      "Training Step: 797  | total loss: \u001b[1m\u001b[32m0.03198\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 797 | loss: 0.03198 - acc: 0.9977 -- iter: 8/8\n",
      "--\n",
      "Training Step: 798  | total loss: \u001b[1m\u001b[32m0.02948\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 798 | loss: 0.02948 - acc: 0.9979 -- iter: 8/8\n",
      "--\n",
      "Training Step: 799  | total loss: \u001b[1m\u001b[32m0.02948\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 799 | loss: 0.02948 - acc: 0.9981 -- iter: 8/8\n",
      "--\n",
      "Training Step: 800  | total loss: \u001b[1m\u001b[32m0.23739\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 800 | loss: 0.23739 - acc: 0.9608 -- iter: 8/8\n",
      "--\n",
      "Training Step: 801  | total loss: \u001b[1m\u001b[32m0.21553\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 801 | loss: 0.21553 - acc: 0.9647 -- iter: 8/8\n",
      "--\n",
      "Training Step: 802  | total loss: \u001b[1m\u001b[32m0.19586\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 802 | loss: 0.19586 - acc: 0.9682 -- iter: 8/8\n",
      "--\n",
      "Training Step: 803  | total loss: \u001b[1m\u001b[32m0.17816\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 803 | loss: 0.17816 - acc: 0.9714 -- iter: 8/8\n",
      "--\n",
      "Training Step: 804  | total loss: \u001b[1m\u001b[32m0.16224\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 804 | loss: 0.16224 - acc: 0.9743 -- iter: 8/8\n",
      "--\n",
      "Training Step: 805  | total loss: \u001b[1m\u001b[32m0.14791\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 805 | loss: 0.14791 - acc: 0.9768 -- iter: 8/8\n",
      "--\n",
      "Training Step: 806  | total loss: \u001b[1m\u001b[32m0.13502\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 806 | loss: 0.13502 - acc: 0.9792 -- iter: 8/8\n",
      "--\n",
      "Training Step: 807  | total loss: \u001b[1m\u001b[32m0.12341\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 807 | loss: 0.12341 - acc: 0.9812 -- iter: 8/8\n",
      "--\n",
      "Training Step: 808  | total loss: \u001b[1m\u001b[32m0.11297\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 808 | loss: 0.11297 - acc: 0.9831 -- iter: 8/8\n",
      "--\n",
      "Training Step: 809  | total loss: \u001b[1m\u001b[32m0.10357\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 809 | loss: 0.10357 - acc: 0.9848 -- iter: 8/8\n",
      "--\n",
      "Training Step: 810  | total loss: \u001b[1m\u001b[32m0.09511\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 810 | loss: 0.09511 - acc: 0.9863 -- iter: 8/8\n",
      "--\n",
      "Training Step: 811  | total loss: \u001b[1m\u001b[32m0.08749\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 811 | loss: 0.08749 - acc: 0.9877 -- iter: 8/8\n",
      "--\n",
      "Training Step: 812  | total loss: \u001b[1m\u001b[32m0.08063\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 812 | loss: 0.08063 - acc: 0.9889 -- iter: 8/8\n",
      "--\n",
      "Training Step: 813  | total loss: \u001b[1m\u001b[32m0.07446\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 813 | loss: 0.07446 - acc: 0.9900 -- iter: 8/8\n",
      "--\n",
      "Training Step: 814  | total loss: \u001b[1m\u001b[32m0.06889\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 814 | loss: 0.06889 - acc: 0.9910 -- iter: 8/8\n",
      "--\n",
      "Training Step: 815  | total loss: \u001b[1m\u001b[32m0.06388\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 815 | loss: 0.06388 - acc: 0.9919 -- iter: 8/8\n",
      "--\n",
      "Training Step: 816  | total loss: \u001b[1m\u001b[32m0.05937\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 816 | loss: 0.05937 - acc: 0.9927 -- iter: 8/8\n",
      "--\n",
      "Training Step: 817  | total loss: \u001b[1m\u001b[32m0.05530\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 817 | loss: 0.05530 - acc: 0.9935 -- iter: 8/8\n",
      "--\n",
      "Training Step: 818  | total loss: \u001b[1m\u001b[32m0.05163\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 818 | loss: 0.05163 - acc: 0.9941 -- iter: 8/8\n",
      "--\n",
      "Training Step: 819  | total loss: \u001b[1m\u001b[32m0.04832\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 819 | loss: 0.04832 - acc: 0.9947 -- iter: 8/8\n",
      "--\n",
      "Training Step: 820  | total loss: \u001b[1m\u001b[32m0.04534\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 820 | loss: 0.04534 - acc: 0.9952 -- iter: 8/8\n",
      "--\n",
      "Training Step: 821  | total loss: \u001b[1m\u001b[32m0.04265\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 821 | loss: 0.04265 - acc: 0.9957 -- iter: 8/8\n",
      "--\n",
      "Training Step: 822  | total loss: \u001b[1m\u001b[32m0.04022\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 822 | loss: 0.04022 - acc: 0.9961 -- iter: 8/8\n",
      "--\n",
      "Training Step: 823  | total loss: \u001b[1m\u001b[32m0.03803\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 823 | loss: 0.03803 - acc: 0.9965 -- iter: 8/8\n",
      "--\n",
      "Training Step: 824  | total loss: \u001b[1m\u001b[32m0.03605\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 824 | loss: 0.03605 - acc: 0.9969 -- iter: 8/8\n",
      "--\n",
      "Training Step: 825  | total loss: \u001b[1m\u001b[32m0.03426\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 825 | loss: 0.03426 - acc: 0.9972 -- iter: 8/8\n",
      "--\n",
      "Training Step: 826  | total loss: \u001b[1m\u001b[32m0.03265\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 826 | loss: 0.03265 - acc: 0.9975 -- iter: 8/8\n",
      "--\n",
      "Training Step: 827  | total loss: \u001b[1m\u001b[32m0.03118\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 827 | loss: 0.03118 - acc: 0.9977 -- iter: 8/8\n",
      "--\n",
      "Training Step: 828  | total loss: \u001b[1m\u001b[32m0.23762\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 828 | loss: 0.23762 - acc: 0.9604 -- iter: 8/8\n",
      "--\n",
      "Training Step: 829  | total loss: \u001b[1m\u001b[32m0.21566\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 829 | loss: 0.21566 - acc: 0.9644 -- iter: 8/8\n",
      "--\n",
      "Training Step: 830  | total loss: \u001b[1m\u001b[32m0.19590\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 830 | loss: 0.19590 - acc: 0.9680 -- iter: 8/8\n",
      "--\n",
      "Training Step: 831  | total loss: \u001b[1m\u001b[32m0.17813\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 831 | loss: 0.17813 - acc: 0.9712 -- iter: 8/8\n",
      "--\n",
      "Training Step: 832  | total loss: \u001b[1m\u001b[32m0.16214\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 832 | loss: 0.16214 - acc: 0.9741 -- iter: 8/8\n",
      "--\n",
      "Training Step: 833  | total loss: \u001b[1m\u001b[32m0.14775\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 833 | loss: 0.14775 - acc: 0.9766 -- iter: 8/8\n",
      "--\n",
      "Training Step: 834  | total loss: \u001b[1m\u001b[32m0.13480\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 834 | loss: 0.13480 - acc: 0.9790 -- iter: 8/8\n",
      "--\n",
      "Training Step: 835  | total loss: \u001b[1m\u001b[32m0.12315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 835 | loss: 0.12315 - acc: 0.9811 -- iter: 8/8\n",
      "--\n",
      "Training Step: 836  | total loss: \u001b[1m\u001b[32m0.11266\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 836 | loss: 0.11266 - acc: 0.9830 -- iter: 8/8\n",
      "--\n",
      "Training Step: 837  | total loss: \u001b[1m\u001b[32m0.10322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 837 | loss: 0.10322 - acc: 0.9847 -- iter: 8/8\n",
      "--\n",
      "Training Step: 838  | total loss: \u001b[1m\u001b[32m0.48635\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 838 | loss: 0.48635 - acc: 0.9112 -- iter: 8/8\n",
      "--\n",
      "Training Step: 839  | total loss: \u001b[1m\u001b[32m0.43957\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 839 | loss: 0.43957 - acc: 0.9201 -- iter: 8/8\n",
      "--\n",
      "Training Step: 840  | total loss: \u001b[1m\u001b[32m0.39749\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 840 | loss: 0.39749 - acc: 0.9281 -- iter: 8/8\n",
      "--\n",
      "Training Step: 841  | total loss: \u001b[1m\u001b[32m0.35965\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 841 | loss: 0.35965 - acc: 0.9353 -- iter: 8/8\n",
      "--\n",
      "Training Step: 842  | total loss: \u001b[1m\u001b[32m0.32561\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 842 | loss: 0.32561 - acc: 0.9417 -- iter: 8/8\n",
      "--\n",
      "Training Step: 843  | total loss: \u001b[1m\u001b[32m0.29499\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 843 | loss: 0.29499 - acc: 0.9476 -- iter: 8/8\n",
      "--\n",
      "Training Step: 844  | total loss: \u001b[1m\u001b[32m0.26745\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 844 | loss: 0.26745 - acc: 0.9528 -- iter: 8/8\n",
      "--\n",
      "Training Step: 845  | total loss: \u001b[1m\u001b[32m0.24268\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 845 | loss: 0.24268 - acc: 0.9575 -- iter: 8/8\n",
      "--\n",
      "Training Step: 846  | total loss: \u001b[1m\u001b[32m0.22039\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 846 | loss: 0.22039 - acc: 0.9618 -- iter: 8/8\n",
      "--\n",
      "Training Step: 847  | total loss: \u001b[1m\u001b[32m0.20034\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 847 | loss: 0.20034 - acc: 0.9656 -- iter: 8/8\n",
      "--\n",
      "Training Step: 848  | total loss: \u001b[1m\u001b[32m0.18230\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 848 | loss: 0.18230 - acc: 0.9690 -- iter: 8/8\n",
      "--\n",
      "Training Step: 849  | total loss: \u001b[1m\u001b[32m0.16608\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 849 | loss: 0.16608 - acc: 0.9721 -- iter: 8/8\n",
      "--\n",
      "Training Step: 850  | total loss: \u001b[1m\u001b[32m0.15147\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 850 | loss: 0.15147 - acc: 0.9749 -- iter: 8/8\n",
      "--\n",
      "Training Step: 851  | total loss: \u001b[1m\u001b[32m0.13834\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 851 | loss: 0.13834 - acc: 0.9774 -- iter: 8/8\n",
      "--\n",
      "Training Step: 852  | total loss: \u001b[1m\u001b[32m0.12651\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 852 | loss: 0.12651 - acc: 0.9797 -- iter: 8/8\n",
      "--\n",
      "Training Step: 853  | total loss: \u001b[1m\u001b[32m0.11587\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 853 | loss: 0.11587 - acc: 0.9817 -- iter: 8/8\n",
      "--\n",
      "Training Step: 854  | total loss: \u001b[1m\u001b[32m0.10629\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 854 | loss: 0.10629 - acc: 0.9835 -- iter: 8/8\n",
      "--\n",
      "Training Step: 855  | total loss: \u001b[1m\u001b[32m0.09767\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 855 | loss: 0.09767 - acc: 0.9852 -- iter: 8/8\n",
      "--\n",
      "Training Step: 856  | total loss: \u001b[1m\u001b[32m0.08991\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 856 | loss: 0.08991 - acc: 0.9867 -- iter: 8/8\n",
      "--\n",
      "Training Step: 857  | total loss: \u001b[1m\u001b[32m0.08292\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 857 | loss: 0.08292 - acc: 0.9880 -- iter: 8/8\n",
      "--\n",
      "Training Step: 858  | total loss: \u001b[1m\u001b[32m0.34606\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 858 | loss: 0.34606 - acc: 0.9392 -- iter: 8/8\n",
      "--\n",
      "Training Step: 859  | total loss: \u001b[1m\u001b[32m0.31347\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 859 | loss: 0.31347 - acc: 0.9453 -- iter: 8/8\n",
      "--\n",
      "Training Step: 860  | total loss: \u001b[1m\u001b[32m0.28416\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 860 | loss: 0.28416 - acc: 0.9508 -- iter: 8/8\n",
      "--\n",
      "Training Step: 861  | total loss: \u001b[1m\u001b[32m0.25779\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 861 | loss: 0.25779 - acc: 0.9557 -- iter: 8/8\n",
      "--\n",
      "Training Step: 862  | total loss: \u001b[1m\u001b[32m0.23407\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 862 | loss: 0.23407 - acc: 0.9601 -- iter: 8/8\n",
      "--\n",
      "Training Step: 863  | total loss: \u001b[1m\u001b[32m0.21272\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 863 | loss: 0.21272 - acc: 0.9641 -- iter: 8/8\n",
      "--\n",
      "Training Step: 864  | total loss: \u001b[1m\u001b[32m0.19352\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 864 | loss: 0.19352 - acc: 0.9677 -- iter: 8/8\n",
      "--\n",
      "Training Step: 865  | total loss: \u001b[1m\u001b[32m0.17625\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 865 | loss: 0.17625 - acc: 0.9709 -- iter: 8/8\n",
      "--\n",
      "Training Step: 866  | total loss: \u001b[1m\u001b[32m0.16071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 866 | loss: 0.16071 - acc: 0.9738 -- iter: 8/8\n",
      "--\n",
      "Training Step: 867  | total loss: \u001b[1m\u001b[32m0.13413\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 867 | loss: 0.13413 - acc: 0.9764 -- iter: 8/8\n",
      "--\n",
      "Training Step: 868  | total loss: \u001b[1m\u001b[32m0.13413\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 868 | loss: 0.13413 - acc: 0.9788 -- iter: 8/8\n",
      "--\n",
      "Training Step: 869  | total loss: \u001b[1m\u001b[32m0.12281\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 869 | loss: 0.12281 - acc: 0.9809 -- iter: 8/8\n",
      "--\n",
      "Training Step: 870  | total loss: \u001b[1m\u001b[32m0.11261\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 870 | loss: 0.11261 - acc: 0.9828 -- iter: 8/8\n",
      "--\n",
      "Training Step: 871  | total loss: \u001b[1m\u001b[32m0.10343\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 871 | loss: 0.10343 - acc: 0.9845 -- iter: 8/8\n",
      "--\n",
      "Training Step: 872  | total loss: \u001b[1m\u001b[32m0.09517\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 872 | loss: 0.09517 - acc: 0.9861 -- iter: 8/8\n",
      "--\n",
      "Training Step: 873  | total loss: \u001b[1m\u001b[32m0.08773\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 873 | loss: 0.08773 - acc: 0.9875 -- iter: 8/8\n",
      "--\n",
      "Training Step: 874  | total loss: \u001b[1m\u001b[32m0.08103\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 874 | loss: 0.08103 - acc: 0.9887 -- iter: 8/8\n",
      "--\n",
      "Training Step: 875  | total loss: \u001b[1m\u001b[32m0.07499\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 875 | loss: 0.07499 - acc: 0.9899 -- iter: 8/8\n",
      "--\n",
      "Training Step: 876  | total loss: \u001b[1m\u001b[32m0.06955\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 876 | loss: 0.06955 - acc: 0.9909 -- iter: 8/8\n",
      "--\n",
      "Training Step: 877  | total loss: \u001b[1m\u001b[32m0.06465\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 877 | loss: 0.06465 - acc: 0.9918 -- iter: 8/8\n",
      "--\n",
      "Training Step: 878  | total loss: \u001b[1m\u001b[32m0.06024\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 878 | loss: 0.06024 - acc: 0.9926 -- iter: 8/8\n",
      "--\n",
      "Training Step: 879  | total loss: \u001b[1m\u001b[32m0.05626\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 879 | loss: 0.05626 - acc: 0.9933 -- iter: 8/8\n",
      "--\n",
      "Training Step: 880  | total loss: \u001b[1m\u001b[32m0.05267\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 880 | loss: 0.05267 - acc: 0.9940 -- iter: 8/8\n",
      "--\n",
      "Training Step: 881  | total loss: \u001b[1m\u001b[32m0.04943\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 881 | loss: 0.04943 - acc: 0.9946 -- iter: 8/8\n",
      "--\n",
      "Training Step: 882  | total loss: \u001b[1m\u001b[32m0.04651\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 882 | loss: 0.04651 - acc: 0.9952 -- iter: 8/8\n",
      "--\n",
      "Training Step: 883  | total loss: \u001b[1m\u001b[32m0.04387\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 883 | loss: 0.04387 - acc: 0.9956 -- iter: 8/8\n",
      "--\n",
      "Training Step: 884  | total loss: \u001b[1m\u001b[32m0.04149\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 884 | loss: 0.04149 - acc: 0.9961 -- iter: 8/8\n",
      "--\n",
      "Training Step: 885  | total loss: \u001b[1m\u001b[32m0.03934\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 885 | loss: 0.03934 - acc: 0.9965 -- iter: 8/8\n",
      "--\n",
      "Training Step: 886  | total loss: \u001b[1m\u001b[32m0.03739\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 886 | loss: 0.03739 - acc: 0.9968 -- iter: 8/8\n",
      "--\n",
      "Training Step: 887  | total loss: \u001b[1m\u001b[32m0.03563\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 887 | loss: 0.03563 - acc: 0.9971 -- iter: 8/8\n",
      "--\n",
      "Training Step: 888  | total loss: \u001b[1m\u001b[32m0.03404\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 888 | loss: 0.03404 - acc: 0.9974 -- iter: 8/8\n",
      "--\n",
      "Training Step: 889  | total loss: \u001b[1m\u001b[32m0.03260\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 889 | loss: 0.03260 - acc: 0.9977 -- iter: 8/8\n",
      "--\n",
      "Training Step: 890  | total loss: \u001b[1m\u001b[32m0.29897\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 890 | loss: 0.29897 - acc: 0.9479 -- iter: 8/8\n",
      "--\n",
      "Training Step: 891  | total loss: \u001b[1m\u001b[32m0.27104\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 891 | loss: 0.27104 - acc: 0.9531 -- iter: 8/8\n",
      "--\n",
      "Training Step: 892  | total loss: \u001b[1m\u001b[32m0.24592\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 892 | loss: 0.24592 - acc: 0.9578 -- iter: 8/8\n",
      "--\n",
      "Training Step: 893  | total loss: \u001b[1m\u001b[32m0.22331\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 893 | loss: 0.22331 - acc: 0.9620 -- iter: 8/8\n",
      "--\n",
      "Training Step: 894  | total loss: \u001b[1m\u001b[32m0.20298\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 894 | loss: 0.20298 - acc: 0.9658 -- iter: 8/8\n",
      "--\n",
      "Training Step: 895  | total loss: \u001b[1m\u001b[32m0.18469\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 895 | loss: 0.18469 - acc: 0.9692 -- iter: 8/8\n",
      "--\n",
      "Training Step: 896  | total loss: \u001b[1m\u001b[32m0.15342\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 896 | loss: 0.15342 - acc: 0.9723 -- iter: 8/8\n",
      "--\n",
      "Training Step: 897  | total loss: \u001b[1m\u001b[32m0.15342\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 897 | loss: 0.15342 - acc: 0.9751 -- iter: 8/8\n",
      "--\n",
      "Training Step: 898  | total loss: \u001b[1m\u001b[32m0.14009\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 898 | loss: 0.14009 - acc: 0.9776 -- iter: 8/8\n",
      "--\n",
      "Training Step: 899  | total loss: \u001b[1m\u001b[32m0.12809\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 899 | loss: 0.12809 - acc: 0.9798 -- iter: 8/8\n",
      "--\n",
      "Training Step: 900  | total loss: \u001b[1m\u001b[32m0.11730\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 900 | loss: 0.11730 - acc: 0.9818 -- iter: 8/8\n",
      "--\n",
      "Training Step: 901  | total loss: \u001b[1m\u001b[32m0.10758\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 901 | loss: 0.10758 - acc: 0.9837 -- iter: 8/8\n",
      "--\n",
      "Training Step: 902  | total loss: \u001b[1m\u001b[32m0.09883\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 902 | loss: 0.09883 - acc: 0.9853 -- iter: 8/8\n",
      "--\n",
      "Training Step: 903  | total loss: \u001b[1m\u001b[32m0.09096\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 903 | loss: 0.09096 - acc: 0.9868 -- iter: 8/8\n",
      "--\n",
      "Training Step: 904  | total loss: \u001b[1m\u001b[32m0.08387\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 904 | loss: 0.08387 - acc: 0.9881 -- iter: 8/8\n",
      "--\n",
      "Training Step: 905  | total loss: \u001b[1m\u001b[32m0.07748\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 905 | loss: 0.07748 - acc: 0.9893 -- iter: 8/8\n",
      "--\n",
      "Training Step: 906  | total loss: \u001b[1m\u001b[32m0.07173\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 906 | loss: 0.07173 - acc: 0.9903 -- iter: 8/8\n",
      "--\n",
      "Training Step: 907  | total loss: \u001b[1m\u001b[32m0.06654\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 907 | loss: 0.06654 - acc: 0.9913 -- iter: 8/8\n",
      "--\n",
      "Training Step: 908  | total loss: \u001b[1m\u001b[32m0.06187\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 908 | loss: 0.06187 - acc: 0.9922 -- iter: 8/8\n",
      "--\n",
      "Training Step: 909  | total loss: \u001b[1m\u001b[32m0.05766\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 909 | loss: 0.05766 - acc: 0.9930 -- iter: 8/8\n",
      "--\n",
      "Training Step: 910  | total loss: \u001b[1m\u001b[32m0.05387\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 910 | loss: 0.05387 - acc: 0.9937 -- iter: 8/8\n",
      "--\n",
      "Training Step: 911  | total loss: \u001b[1m\u001b[32m0.05045\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 911 | loss: 0.05045 - acc: 0.9943 -- iter: 8/8\n",
      "--\n",
      "Training Step: 912  | total loss: \u001b[1m\u001b[32m0.04736\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 912 | loss: 0.04736 - acc: 0.9949 -- iter: 8/8\n",
      "--\n",
      "Training Step: 913  | total loss: \u001b[1m\u001b[32m0.04457\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 913 | loss: 0.04457 - acc: 0.9954 -- iter: 8/8\n",
      "--\n",
      "Training Step: 914  | total loss: \u001b[1m\u001b[32m0.04206\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 914 | loss: 0.04206 - acc: 0.9958 -- iter: 8/8\n",
      "--\n",
      "Training Step: 915  | total loss: \u001b[1m\u001b[32m0.03979\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 915 | loss: 0.03979 - acc: 0.9963 -- iter: 8/8\n",
      "--\n",
      "Training Step: 916  | total loss: \u001b[1m\u001b[32m0.03774\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 916 | loss: 0.03774 - acc: 0.9966 -- iter: 8/8\n",
      "--\n",
      "Training Step: 917  | total loss: \u001b[1m\u001b[32m0.03589\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 917 | loss: 0.03589 - acc: 0.9970 -- iter: 8/8\n",
      "--\n",
      "Training Step: 918  | total loss: \u001b[1m\u001b[32m0.03421\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 918 | loss: 0.03421 - acc: 0.9973 -- iter: 8/8\n",
      "--\n",
      "Training Step: 919  | total loss: \u001b[1m\u001b[32m0.03269\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 919 | loss: 0.03269 - acc: 0.9975 -- iter: 8/8\n",
      "--\n",
      "Training Step: 920  | total loss: \u001b[1m\u001b[32m0.03132\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 920 | loss: 0.03132 - acc: 0.9978 -- iter: 8/8\n",
      "--\n",
      "Training Step: 921  | total loss: \u001b[1m\u001b[32m0.03008\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 921 | loss: 0.03008 - acc: 0.9980 -- iter: 8/8\n",
      "--\n",
      "Training Step: 922  | total loss: \u001b[1m\u001b[32m0.02895\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 922 | loss: 0.02895 - acc: 0.9982 -- iter: 8/8\n",
      "--\n",
      "Training Step: 923  | total loss: \u001b[1m\u001b[32m0.02793\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 923 | loss: 0.02793 - acc: 0.9984 -- iter: 8/8\n",
      "--\n",
      "Training Step: 924  | total loss: \u001b[1m\u001b[32m0.02700\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 924 | loss: 0.02700 - acc: 0.9986 -- iter: 8/8\n",
      "--\n",
      "Training Step: 925  | total loss: \u001b[1m\u001b[32m0.02615\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 925 | loss: 0.02615 - acc: 0.9987 -- iter: 8/8\n",
      "--\n",
      "Training Step: 926  | total loss: \u001b[1m\u001b[32m0.02539\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 926 | loss: 0.02539 - acc: 0.9988 -- iter: 8/8\n",
      "--\n",
      "Training Step: 927  | total loss: \u001b[1m\u001b[32m0.02469\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 927 | loss: 0.02469 - acc: 0.9989 -- iter: 8/8\n",
      "--\n",
      "Training Step: 928  | total loss: \u001b[1m\u001b[32m0.02405\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 928 | loss: 0.02405 - acc: 0.9990 -- iter: 8/8\n",
      "--\n",
      "Training Step: 929  | total loss: \u001b[1m\u001b[32m0.02347\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 929 | loss: 0.02347 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 930  | total loss: \u001b[1m\u001b[32m0.02294\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 930 | loss: 0.02294 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 931  | total loss: \u001b[1m\u001b[32m0.02245\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 931 | loss: 0.02245 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 932  | total loss: \u001b[1m\u001b[32m0.02200\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 932 | loss: 0.02200 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 933  | total loss: \u001b[1m\u001b[32m0.02122\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 933 | loss: 0.02122 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 934  | total loss: \u001b[1m\u001b[32m0.02122\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 934 | loss: 0.02122 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 935  | total loss: \u001b[1m\u001b[32m0.02087\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 935 | loss: 0.02087 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 936  | total loss: \u001b[1m\u001b[32m0.02055\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 936 | loss: 0.02055 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 937  | total loss: \u001b[1m\u001b[32m0.02025\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 937 | loss: 0.02025 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 938  | total loss: \u001b[1m\u001b[32m0.01998\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 938 | loss: 0.01998 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 939  | total loss: \u001b[1m\u001b[32m0.01972\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 939 | loss: 0.01972 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 940  | total loss: \u001b[1m\u001b[32m0.28514\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 940 | loss: 0.28514 - acc: 0.9497 -- iter: 8/8\n",
      "--\n",
      "Training Step: 941  | total loss: \u001b[1m\u001b[32m0.25837\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 941 | loss: 0.25837 - acc: 0.9548 -- iter: 8/8\n",
      "--\n",
      "Training Step: 942  | total loss: \u001b[1m\u001b[32m0.23429\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 942 | loss: 0.23429 - acc: 0.9593 -- iter: 8/8\n",
      "--\n",
      "Training Step: 943  | total loss: \u001b[1m\u001b[32m0.21263\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 943 | loss: 0.21263 - acc: 0.9634 -- iter: 8/8\n",
      "--\n",
      "Training Step: 944  | total loss: \u001b[1m\u001b[32m0.19314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 944 | loss: 0.19314 - acc: 0.9670 -- iter: 8/8\n",
      "--\n",
      "Training Step: 945  | total loss: \u001b[1m\u001b[32m0.17560\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 945 | loss: 0.17560 - acc: 0.9703 -- iter: 8/8\n",
      "--\n",
      "Training Step: 946  | total loss: \u001b[1m\u001b[32m0.15982\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 946 | loss: 0.15982 - acc: 0.9733 -- iter: 8/8\n",
      "--\n",
      "Training Step: 947  | total loss: \u001b[1m\u001b[32m0.14562\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 947 | loss: 0.14562 - acc: 0.9760 -- iter: 8/8\n",
      "--\n",
      "Training Step: 948  | total loss: \u001b[1m\u001b[32m0.13285\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 948 | loss: 0.13285 - acc: 0.9784 -- iter: 8/8\n",
      "--\n",
      "Training Step: 949  | total loss: \u001b[1m\u001b[32m0.12135\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 949 | loss: 0.12135 - acc: 0.9805 -- iter: 8/8\n",
      "--\n",
      "Training Step: 950  | total loss: \u001b[1m\u001b[32m0.11100\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 950 | loss: 0.11100 - acc: 0.9825 -- iter: 8/8\n",
      "--\n",
      "Training Step: 951  | total loss: \u001b[1m\u001b[32m0.10169\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 951 | loss: 0.10169 - acc: 0.9842 -- iter: 8/8\n",
      "--\n",
      "Training Step: 952  | total loss: \u001b[1m\u001b[32m0.09330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 952 | loss: 0.09330 - acc: 0.9858 -- iter: 8/8\n",
      "--\n",
      "Training Step: 953  | total loss: \u001b[1m\u001b[32m0.08576\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 953 | loss: 0.08576 - acc: 0.9872 -- iter: 8/8\n",
      "--\n",
      "Training Step: 954  | total loss: \u001b[1m\u001b[32m0.07896\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 954 | loss: 0.07896 - acc: 0.9885 -- iter: 8/8\n",
      "--\n",
      "Training Step: 955  | total loss: \u001b[1m\u001b[32m0.07284\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 955 | loss: 0.07284 - acc: 0.9897 -- iter: 8/8\n",
      "--\n",
      "Training Step: 956  | total loss: \u001b[1m\u001b[32m0.27936\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 956 | loss: 0.27936 - acc: 0.9407 -- iter: 8/8\n",
      "--\n",
      "Training Step: 957  | total loss: \u001b[1m\u001b[32m0.25321\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 957 | loss: 0.25321 - acc: 0.9466 -- iter: 8/8\n",
      "--\n",
      "Training Step: 958  | total loss: \u001b[1m\u001b[32m0.22970\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 958 | loss: 0.22970 - acc: 0.9520 -- iter: 8/8\n",
      "--\n",
      "Training Step: 959  | total loss: \u001b[1m\u001b[32m0.20854\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 959 | loss: 0.20854 - acc: 0.9568 -- iter: 8/8\n",
      "--\n",
      "Training Step: 960  | total loss: \u001b[1m\u001b[32m0.47771\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 960 | loss: 0.47771 - acc: 0.8986 -- iter: 8/8\n",
      "--\n",
      "Training Step: 961  | total loss: \u001b[1m\u001b[32m0.43180\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 961 | loss: 0.43180 - acc: 0.9087 -- iter: 8/8\n",
      "--\n",
      "Training Step: 962  | total loss: \u001b[1m\u001b[32m0.39051\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 962 | loss: 0.39051 - acc: 0.9179 -- iter: 8/8\n",
      "--\n",
      "Training Step: 963  | total loss: \u001b[1m\u001b[32m0.35338\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 963 | loss: 0.35338 - acc: 0.9261 -- iter: 8/8\n",
      "--\n",
      "Training Step: 964  | total loss: \u001b[1m\u001b[32m0.53548\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 964 | loss: 0.53548 - acc: 0.8835 -- iter: 8/8\n",
      "--\n",
      "Training Step: 965  | total loss: \u001b[1m\u001b[32m0.48392\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 965 | loss: 0.48392 - acc: 0.8951 -- iter: 8/8\n",
      "--\n",
      "Training Step: 966  | total loss: \u001b[1m\u001b[32m0.43755\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 966 | loss: 0.43755 - acc: 0.9056 -- iter: 8/8\n",
      "--\n",
      "Training Step: 967  | total loss: \u001b[1m\u001b[32m0.35836\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 967 | loss: 0.35836 - acc: 0.9150 -- iter: 8/8\n",
      "--\n",
      "Training Step: 968  | total loss: \u001b[1m\u001b[32m0.32464\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 968 | loss: 0.32464 - acc: 0.9235 -- iter: 8/8\n",
      "--\n",
      "Training Step: 969  | total loss: \u001b[1m\u001b[32m0.32464\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 969 | loss: 0.32464 - acc: 0.9312 -- iter: 8/8\n",
      "--\n",
      "Training Step: 970  | total loss: \u001b[1m\u001b[32m0.29432\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 970 | loss: 0.29432 - acc: 0.9381 -- iter: 8/8\n",
      "--\n",
      "Training Step: 971  | total loss: \u001b[1m\u001b[32m0.26705\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 971 | loss: 0.26705 - acc: 0.9443 -- iter: 8/8\n",
      "--\n",
      "Training Step: 972  | total loss: \u001b[1m\u001b[32m0.24253\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 972 | loss: 0.24253 - acc: 0.9498 -- iter: 8/8\n",
      "--\n",
      "Training Step: 973  | total loss: \u001b[1m\u001b[32m0.22047\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 973 | loss: 0.22047 - acc: 0.9549 -- iter: 8/8\n",
      "--\n",
      "Training Step: 974  | total loss: \u001b[1m\u001b[32m0.20064\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 974 | loss: 0.20064 - acc: 0.9594 -- iter: 8/8\n",
      "--\n",
      "Training Step: 975  | total loss: \u001b[1m\u001b[32m0.18279\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 975 | loss: 0.18279 - acc: 0.9634 -- iter: 8/8\n",
      "--\n",
      "Training Step: 976  | total loss: \u001b[1m\u001b[32m0.16674\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 976 | loss: 0.16674 - acc: 0.9671 -- iter: 8/8\n",
      "--\n",
      "Training Step: 977  | total loss: \u001b[1m\u001b[32m0.13931\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 977 | loss: 0.13931 - acc: 0.9704 -- iter: 8/8\n",
      "--\n",
      "Training Step: 978  | total loss: \u001b[1m\u001b[32m0.13931\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 978 | loss: 0.13931 - acc: 0.9733 -- iter: 8/8\n",
      "--\n",
      "Training Step: 979  | total loss: \u001b[1m\u001b[32m0.12762\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 979 | loss: 0.12762 - acc: 0.9760 -- iter: 8/8\n",
      "--\n",
      "Training Step: 980  | total loss: \u001b[1m\u001b[32m0.11710\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 980 | loss: 0.11710 - acc: 0.9784 -- iter: 8/8\n",
      "--\n",
      "Training Step: 981  | total loss: \u001b[1m\u001b[32m0.10764\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 981 | loss: 0.10764 - acc: 0.9806 -- iter: 8/8\n",
      "--\n",
      "Training Step: 982  | total loss: \u001b[1m\u001b[32m0.09912\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 982 | loss: 0.09912 - acc: 0.9825 -- iter: 8/8\n",
      "--\n",
      "Training Step: 983  | total loss: \u001b[1m\u001b[32m0.09145\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 983 | loss: 0.09145 - acc: 0.9843 -- iter: 8/8\n",
      "--\n",
      "Training Step: 984  | total loss: \u001b[1m\u001b[32m0.08455\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 984 | loss: 0.08455 - acc: 0.9858 -- iter: 8/8\n",
      "--\n",
      "Training Step: 985  | total loss: \u001b[1m\u001b[32m0.07833\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 985 | loss: 0.07833 - acc: 0.9872 -- iter: 8/8\n",
      "--\n",
      "Training Step: 986  | total loss: \u001b[1m\u001b[32m0.07273\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 986 | loss: 0.07273 - acc: 0.9885 -- iter: 8/8\n",
      "--\n",
      "Training Step: 987  | total loss: \u001b[1m\u001b[32m0.06768\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 987 | loss: 0.06768 - acc: 0.9897 -- iter: 8/8\n",
      "--\n",
      "Training Step: 988  | total loss: \u001b[1m\u001b[32m0.34015\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 988 | loss: 0.34015 - acc: 0.9282 -- iter: 8/8\n",
      "--\n",
      "Training Step: 989  | total loss: \u001b[1m\u001b[32m0.30839\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 989 | loss: 0.30839 - acc: 0.9354 -- iter: 8/8\n",
      "--\n",
      "Training Step: 990  | total loss: \u001b[1m\u001b[32m0.27982\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 990 | loss: 0.27982 - acc: 0.9418 -- iter: 8/8\n",
      "--\n",
      "Training Step: 991  | total loss: \u001b[1m\u001b[32m0.25412\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 991 | loss: 0.25412 - acc: 0.9477 -- iter: 8/8\n",
      "--\n",
      "Training Step: 992  | total loss: \u001b[1m\u001b[32m0.23101\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 992 | loss: 0.23101 - acc: 0.9529 -- iter: 8/8\n",
      "--\n",
      "Training Step: 993  | total loss: \u001b[1m\u001b[32m0.21022\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 993 | loss: 0.21022 - acc: 0.9576 -- iter: 8/8\n",
      "--\n",
      "Training Step: 994  | total loss: \u001b[1m\u001b[32m0.19152\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 994 | loss: 0.19152 - acc: 0.9618 -- iter: 8/8\n",
      "--\n",
      "Training Step: 995  | total loss: \u001b[1m\u001b[32m0.17470\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 995 | loss: 0.17470 - acc: 0.9657 -- iter: 8/8\n",
      "--\n",
      "Training Step: 996  | total loss: \u001b[1m\u001b[32m0.15957\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 996 | loss: 0.15957 - acc: 0.9691 -- iter: 8/8\n",
      "--\n",
      "Training Step: 997  | total loss: \u001b[1m\u001b[32m0.14596\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 997 | loss: 0.14596 - acc: 0.9722 -- iter: 8/8\n",
      "--\n",
      "Training Step: 998  | total loss: \u001b[1m\u001b[32m0.13371\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 998 | loss: 0.13371 - acc: 0.9750 -- iter: 8/8\n",
      "--\n",
      "Training Step: 999  | total loss: \u001b[1m\u001b[32m0.12269\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 999 | loss: 0.12269 - acc: 0.9775 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1000  | total loss: \u001b[1m\u001b[32m0.11277\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1000 | loss: 0.11277 - acc: 0.9797 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1001  | total loss: \u001b[1m\u001b[32m0.10384\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1001 | loss: 0.10384 - acc: 0.9818 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1002  | total loss: \u001b[1m\u001b[32m0.09580\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 1002 | loss: 0.09580 - acc: 0.9836 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1003  | total loss: \u001b[1m\u001b[32m0.08856\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1003 | loss: 0.08856 - acc: 0.9852 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1004  | total loss: \u001b[1m\u001b[32m0.08204\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1004 | loss: 0.08204 - acc: 0.9867 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1005  | total loss: \u001b[1m\u001b[32m0.07088\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1005 | loss: 0.07088 - acc: 0.9880 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1006  | total loss: \u001b[1m\u001b[32m0.07088\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1006 | loss: 0.07088 - acc: 0.9892 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1007  | total loss: \u001b[1m\u001b[32m0.06612\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1007 | loss: 0.06612 - acc: 0.9903 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1008  | total loss: \u001b[1m\u001b[32m0.06182\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1008 | loss: 0.06182 - acc: 0.9913 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1009  | total loss: \u001b[1m\u001b[32m0.05795\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1009 | loss: 0.05795 - acc: 0.9921 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1010  | total loss: \u001b[1m\u001b[32m0.05445\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1010 | loss: 0.05445 - acc: 0.9929 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1011  | total loss: \u001b[1m\u001b[32m0.05130\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1011 | loss: 0.05130 - acc: 0.9936 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1012  | total loss: \u001b[1m\u001b[32m0.04846\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1012 | loss: 0.04846 - acc: 0.9943 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1013  | total loss: \u001b[1m\u001b[32m0.04589\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1013 | loss: 0.04589 - acc: 0.9948 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1014  | total loss: \u001b[1m\u001b[32m0.04357\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1014 | loss: 0.04357 - acc: 0.9954 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1015  | total loss: \u001b[1m\u001b[32m0.04147\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1015 | loss: 0.04147 - acc: 0.9958 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1016  | total loss: \u001b[1m\u001b[32m0.03957\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1016 | loss: 0.03957 - acc: 0.9962 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1017  | total loss: \u001b[1m\u001b[32m0.03785\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1017 | loss: 0.03785 - acc: 0.9966 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1018  | total loss: \u001b[1m\u001b[32m0.03630\u001b[0m\u001b[0m | time: 0.017s\n",
      "| Adam | epoch: 1018 | loss: 0.03630 - acc: 0.9970 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1019  | total loss: \u001b[1m\u001b[32m0.03489\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1019 | loss: 0.03489 - acc: 0.9973 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1020  | total loss: \u001b[1m\u001b[32m0.03362\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1020 | loss: 0.03362 - acc: 0.9975 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1021  | total loss: \u001b[1m\u001b[32m0.03246\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1021 | loss: 0.03246 - acc: 0.9978 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1022  | total loss: \u001b[1m\u001b[32m0.03140\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1022 | loss: 0.03140 - acc: 0.9980 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1023  | total loss: \u001b[1m\u001b[32m0.03045\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1023 | loss: 0.03045 - acc: 0.9982 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1024  | total loss: \u001b[1m\u001b[32m0.02957\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1024 | loss: 0.02957 - acc: 0.9984 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1025  | total loss: \u001b[1m\u001b[32m0.02878\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1025 | loss: 0.02878 - acc: 0.9985 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1026  | total loss: \u001b[1m\u001b[32m0.02806\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1026 | loss: 0.02806 - acc: 0.9987 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1027  | total loss: \u001b[1m\u001b[32m0.02739\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1027 | loss: 0.02739 - acc: 0.9988 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1028  | total loss: \u001b[1m\u001b[32m0.02679\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1028 | loss: 0.02679 - acc: 0.9989 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1029  | total loss: \u001b[1m\u001b[32m0.02623\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1029 | loss: 0.02623 - acc: 0.9990 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1030  | total loss: \u001b[1m\u001b[32m0.02572\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1030 | loss: 0.02572 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1031  | total loss: \u001b[1m\u001b[32m0.02526\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1031 | loss: 0.02526 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1032  | total loss: \u001b[1m\u001b[32m0.02482\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1032 | loss: 0.02482 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1033  | total loss: \u001b[1m\u001b[32m0.02443\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1033 | loss: 0.02443 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1034  | total loss: \u001b[1m\u001b[32m0.02406\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1034 | loss: 0.02406 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1035  | total loss: \u001b[1m\u001b[32m0.02372\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1035 | loss: 0.02372 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1036  | total loss: \u001b[1m\u001b[32m0.02340\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1036 | loss: 0.02340 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1037  | total loss: \u001b[1m\u001b[32m0.02311\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1037 | loss: 0.02311 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1038  | total loss: \u001b[1m\u001b[32m0.02283\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1038 | loss: 0.02283 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1039  | total loss: \u001b[1m\u001b[32m0.02258\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1039 | loss: 0.02258 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1040  | total loss: \u001b[1m\u001b[32m0.02234\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1040 | loss: 0.02234 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1041  | total loss: \u001b[1m\u001b[32m0.02211\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1041 | loss: 0.02211 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1042  | total loss: \u001b[1m\u001b[32m0.02190\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1042 | loss: 0.02190 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1043  | total loss: \u001b[1m\u001b[32m0.31215\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1043 | loss: 0.31215 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1044  | total loss: \u001b[1m\u001b[32m0.28294\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 1044 | loss: 0.28294 - acc: 0.9373 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1045  | total loss: \u001b[1m\u001b[32m0.25666\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1045 | loss: 0.25666 - acc: 0.9436 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1046  | total loss: \u001b[1m\u001b[32m0.23302\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 1046 | loss: 0.23302 - acc: 0.9492 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1047  | total loss: \u001b[1m\u001b[32m0.21176\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1047 | loss: 0.21176 - acc: 0.9543 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1048  | total loss: \u001b[1m\u001b[32m0.19264\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1048 | loss: 0.19264 - acc: 0.9589 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1049  | total loss: \u001b[1m\u001b[32m0.17544\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 1049 | loss: 0.17544 - acc: 0.9630 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1050  | total loss: \u001b[1m\u001b[32m0.15996\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1050 | loss: 0.15996 - acc: 0.9667 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1051  | total loss: \u001b[1m\u001b[32m0.14604\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1051 | loss: 0.14604 - acc: 0.9700 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1052  | total loss: \u001b[1m\u001b[32m0.14604\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1052 | loss: 0.14604 - acc: 0.9730 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1053  | total loss: \u001b[1m\u001b[32m0.13351\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1053 | loss: 0.13351 - acc: 0.9757 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1054  | total loss: \u001b[1m\u001b[32m0.12223\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1054 | loss: 0.12223 - acc: 0.9781 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1055  | total loss: \u001b[1m\u001b[32m0.11209\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1055 | loss: 0.11209 - acc: 0.9803 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1056  | total loss: \u001b[1m\u001b[32m0.10296\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1056 | loss: 0.10296 - acc: 0.9823 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1057  | total loss: \u001b[1m\u001b[32m0.09474\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 1057 | loss: 0.09474 - acc: 0.9841 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1058  | total loss: \u001b[1m\u001b[32m0.08734\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1058 | loss: 0.08734 - acc: 0.9857 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1059  | total loss: \u001b[1m\u001b[32m0.08068\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1059 | loss: 0.08068 - acc: 0.9871 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1060  | total loss: \u001b[1m\u001b[32m0.07468\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1060 | loss: 0.07468 - acc: 0.9884 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1061  | total loss: \u001b[1m\u001b[32m0.06928\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1061 | loss: 0.06928 - acc: 0.9895 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1062  | total loss: \u001b[1m\u001b[32m0.06442\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1062 | loss: 0.06442 - acc: 0.9906 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1063  | total loss: \u001b[1m\u001b[32m0.06003\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1063 | loss: 0.06003 - acc: 0.9915 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1064  | total loss: \u001b[1m\u001b[32m0.05608\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1064 | loss: 0.05608 - acc: 0.9924 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1065  | total loss: \u001b[1m\u001b[32m0.05252\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1065 | loss: 0.05252 - acc: 0.9931 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1066  | total loss: \u001b[1m\u001b[32m0.04930\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1066 | loss: 0.04930 - acc: 0.9938 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1067  | total loss: \u001b[1m\u001b[32m0.04641\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1067 | loss: 0.04641 - acc: 0.9944 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1068  | total loss: \u001b[1m\u001b[32m0.33140\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1068 | loss: 0.33140 - acc: 0.9325 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1069  | total loss: \u001b[1m\u001b[32m0.30031\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1069 | loss: 0.30031 - acc: 0.9392 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1070  | total loss: \u001b[1m\u001b[32m0.27234\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1070 | loss: 0.27234 - acc: 0.9453 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1071  | total loss: \u001b[1m\u001b[32m0.24718\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1071 | loss: 0.24718 - acc: 0.9508 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1072  | total loss: \u001b[1m\u001b[32m0.22455\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1072 | loss: 0.22455 - acc: 0.9557 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1073  | total loss: \u001b[1m\u001b[32m0.20419\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1073 | loss: 0.20419 - acc: 0.9601 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1074  | total loss: \u001b[1m\u001b[32m0.18588\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1074 | loss: 0.18588 - acc: 0.9641 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1075  | total loss: \u001b[1m\u001b[32m0.16940\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1075 | loss: 0.16940 - acc: 0.9677 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1076  | total loss: \u001b[1m\u001b[32m0.15458\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1076 | loss: 0.15458 - acc: 0.9709 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1077  | total loss: \u001b[1m\u001b[32m0.14124\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1077 | loss: 0.14124 - acc: 0.9738 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1078  | total loss: \u001b[1m\u001b[32m0.12924\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1078 | loss: 0.12924 - acc: 0.9765 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1079  | total loss: \u001b[1m\u001b[32m0.11843\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1079 | loss: 0.11843 - acc: 0.9788 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1080  | total loss: \u001b[1m\u001b[32m0.10871\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1080 | loss: 0.10871 - acc: 0.9809 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1081  | total loss: \u001b[1m\u001b[32m0.09996\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1081 | loss: 0.09996 - acc: 0.9828 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1082  | total loss: \u001b[1m\u001b[32m0.09208\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1082 | loss: 0.09208 - acc: 0.9846 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1083  | total loss: \u001b[1m\u001b[32m0.08499\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1083 | loss: 0.08499 - acc: 0.9861 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1084  | total loss: \u001b[1m\u001b[32m0.07861\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1084 | loss: 0.07861 - acc: 0.9875 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1085  | total loss: \u001b[1m\u001b[32m0.07285\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1085 | loss: 0.07285 - acc: 0.9887 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1086  | total loss: \u001b[1m\u001b[32m0.06767\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1086 | loss: 0.06767 - acc: 0.9899 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1087  | total loss: \u001b[1m\u001b[32m0.06300\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1087 | loss: 0.06300 - acc: 0.9909 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1088  | total loss: \u001b[1m\u001b[32m0.05880\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1088 | loss: 0.05880 - acc: 0.9918 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1089  | total loss: \u001b[1m\u001b[32m0.05500\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1089 | loss: 0.05500 - acc: 0.9926 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1090  | total loss: \u001b[1m\u001b[32m0.05158\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1090 | loss: 0.05158 - acc: 0.9934 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1091  | total loss: \u001b[1m\u001b[32m0.04850\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1091 | loss: 0.04850 - acc: 0.9940 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1092  | total loss: \u001b[1m\u001b[32m0.04572\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1092 | loss: 0.04572 - acc: 0.9946 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1093  | total loss: \u001b[1m\u001b[32m0.04320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1093 | loss: 0.04320 - acc: 0.9952 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1094  | total loss: \u001b[1m\u001b[32m0.04094\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1094 | loss: 0.04094 - acc: 0.9956 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1095  | total loss: \u001b[1m\u001b[32m0.03889\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1095 | loss: 0.03889 - acc: 0.9961 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1096  | total loss: \u001b[1m\u001b[32m0.03704\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1096 | loss: 0.03704 - acc: 0.9965 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1097  | total loss: \u001b[1m\u001b[32m0.03536\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1097 | loss: 0.03536 - acc: 0.9968 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1098  | total loss: \u001b[1m\u001b[32m0.03385\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1098 | loss: 0.03385 - acc: 0.9971 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1099  | total loss: \u001b[1m\u001b[32m0.03247\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1099 | loss: 0.03247 - acc: 0.9974 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1100  | total loss: \u001b[1m\u001b[32m0.03123\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1100 | loss: 0.03123 - acc: 0.9977 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1101  | total loss: \u001b[1m\u001b[32m0.03011\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1101 | loss: 0.03011 - acc: 0.9979 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1102  | total loss: \u001b[1m\u001b[32m0.02908\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 1102 | loss: 0.02908 - acc: 0.9981 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1103  | total loss: \u001b[1m\u001b[32m0.02815\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1103 | loss: 0.02815 - acc: 0.9983 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1104  | total loss: \u001b[1m\u001b[32m0.02731\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1104 | loss: 0.02731 - acc: 0.9985 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1105  | total loss: \u001b[1m\u001b[32m0.02654\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 1105 | loss: 0.02654 - acc: 0.9986 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1106  | total loss: \u001b[1m\u001b[32m0.02584\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1106 | loss: 0.02584 - acc: 0.9988 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1107  | total loss: \u001b[1m\u001b[32m0.02521\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1107 | loss: 0.02521 - acc: 0.9989 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1108  | total loss: \u001b[1m\u001b[32m0.02462\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1108 | loss: 0.02462 - acc: 0.9990 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1109  | total loss: \u001b[1m\u001b[32m0.02409\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1109 | loss: 0.02409 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1110  | total loss: \u001b[1m\u001b[32m0.02360\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1110 | loss: 0.02360 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1111  | total loss: \u001b[1m\u001b[32m0.02315\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1111 | loss: 0.02315 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1112  | total loss: \u001b[1m\u001b[32m0.02274\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1112 | loss: 0.02274 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1113  | total loss: \u001b[1m\u001b[32m0.02236\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1113 | loss: 0.02236 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1114  | total loss: \u001b[1m\u001b[32m0.02202\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1114 | loss: 0.02202 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1115  | total loss: \u001b[1m\u001b[32m0.02169\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1115 | loss: 0.02169 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1116  | total loss: \u001b[1m\u001b[32m0.02139\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1116 | loss: 0.02139 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1117  | total loss: \u001b[1m\u001b[32m0.02112\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1117 | loss: 0.02112 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1118  | total loss: \u001b[1m\u001b[32m0.02086\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1118 | loss: 0.02086 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1119  | total loss: \u001b[1m\u001b[32m0.02062\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1119 | loss: 0.02062 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1120  | total loss: \u001b[1m\u001b[32m0.02040\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1120 | loss: 0.02040 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1121  | total loss: \u001b[1m\u001b[32m0.02019\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1121 | loss: 0.02019 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1122  | total loss: \u001b[1m\u001b[32m0.01999\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1122 | loss: 0.01999 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1123  | total loss: \u001b[1m\u001b[32m0.01980\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1123 | loss: 0.01980 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1124  | total loss: \u001b[1m\u001b[32m0.01963\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1124 | loss: 0.01963 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1125  | total loss: \u001b[1m\u001b[32m0.01947\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1125 | loss: 0.01947 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1126  | total loss: \u001b[1m\u001b[32m0.01931\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1126 | loss: 0.01931 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1127  | total loss: \u001b[1m\u001b[32m0.01916\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1127 | loss: 0.01916 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1128  | total loss: \u001b[1m\u001b[32m0.01902\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1128 | loss: 0.01902 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1129  | total loss: \u001b[1m\u001b[32m0.01875\u001b[0m\u001b[0m | time: 0.015s\n",
      "| Adam | epoch: 1129 | loss: 0.01875 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1130  | total loss: \u001b[1m\u001b[32m0.01875\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1130 | loss: 0.01875 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1131  | total loss: \u001b[1m\u001b[32m0.01863\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1131 | loss: 0.01863 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1132  | total loss: \u001b[1m\u001b[32m0.01851\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1132 | loss: 0.01851 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1133  | total loss: \u001b[1m\u001b[32m0.01840\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1133 | loss: 0.01840 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1134  | total loss: \u001b[1m\u001b[32m0.01828\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1134 | loss: 0.01828 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1135  | total loss: \u001b[1m\u001b[32m0.01818\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1135 | loss: 0.01818 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1136  | total loss: \u001b[1m\u001b[32m0.01807\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1136 | loss: 0.01807 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1137  | total loss: \u001b[1m\u001b[32m0.01797\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1137 | loss: 0.01797 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1138  | total loss: \u001b[1m\u001b[32m0.01787\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 1138 | loss: 0.01787 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1139  | total loss: \u001b[1m\u001b[32m0.01778\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1139 | loss: 0.01778 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1140  | total loss: \u001b[1m\u001b[32m0.01768\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1140 | loss: 0.01768 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1141  | total loss: \u001b[1m\u001b[32m0.01759\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1141 | loss: 0.01759 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1142  | total loss: \u001b[1m\u001b[32m0.01750\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1142 | loss: 0.01750 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1143  | total loss: \u001b[1m\u001b[32m0.01742\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1143 | loss: 0.01742 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1144  | total loss: \u001b[1m\u001b[32m0.01733\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1144 | loss: 0.01733 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1145  | total loss: \u001b[1m\u001b[32m0.01725\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1145 | loss: 0.01725 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1146  | total loss: \u001b[1m\u001b[32m0.01716\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1146 | loss: 0.01716 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1147  | total loss: \u001b[1m\u001b[32m0.01708\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1147 | loss: 0.01708 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1148  | total loss: \u001b[1m\u001b[32m0.01700\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 1148 | loss: 0.01700 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1149  | total loss: \u001b[1m\u001b[32m0.01692\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1149 | loss: 0.01692 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1150  | total loss: \u001b[1m\u001b[32m0.01685\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1150 | loss: 0.01685 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1151  | total loss: \u001b[1m\u001b[32m0.01677\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1151 | loss: 0.01677 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1152  | total loss: \u001b[1m\u001b[32m0.01669\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1152 | loss: 0.01669 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1153  | total loss: \u001b[1m\u001b[32m0.01662\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1153 | loss: 0.01662 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1154  | total loss: \u001b[1m\u001b[32m0.23563\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1154 | loss: 0.23563 - acc: 0.9500 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1155  | total loss: \u001b[1m\u001b[32m0.21367\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1155 | loss: 0.21367 - acc: 0.9550 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1156  | total loss: \u001b[1m\u001b[32m0.19391\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1156 | loss: 0.19391 - acc: 0.9595 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1157  | total loss: \u001b[1m\u001b[32m0.17614\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1157 | loss: 0.17614 - acc: 0.9635 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1158  | total loss: \u001b[1m\u001b[32m0.16016\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1158 | loss: 0.16016 - acc: 0.9672 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1159  | total loss: \u001b[1m\u001b[32m0.14578\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1159 | loss: 0.14578 - acc: 0.9705 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1160  | total loss: \u001b[1m\u001b[32m0.13284\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1160 | loss: 0.13284 - acc: 0.9734 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1161  | total loss: \u001b[1m\u001b[32m0.12120\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1161 | loss: 0.12120 - acc: 0.9761 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1162  | total loss: \u001b[1m\u001b[32m0.11072\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1162 | loss: 0.11072 - acc: 0.9785 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1163  | total loss: \u001b[1m\u001b[32m0.10130\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1163 | loss: 0.10130 - acc: 0.9806 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1164  | total loss: \u001b[1m\u001b[32m0.09282\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1164 | loss: 0.09282 - acc: 0.9826 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1165  | total loss: \u001b[1m\u001b[32m0.08519\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1165 | loss: 0.08519 - acc: 0.9843 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1166  | total loss: \u001b[1m\u001b[32m0.07832\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1166 | loss: 0.07832 - acc: 0.9859 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1167  | total loss: \u001b[1m\u001b[32m0.07214\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1167 | loss: 0.07214 - acc: 0.9873 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1168  | total loss: \u001b[1m\u001b[32m0.06657\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1168 | loss: 0.06657 - acc: 0.9886 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1169  | total loss: \u001b[1m\u001b[32m0.06156\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1169 | loss: 0.06156 - acc: 0.9897 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1170  | total loss: \u001b[1m\u001b[32m0.05705\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1170 | loss: 0.05705 - acc: 0.9907 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1171  | total loss: \u001b[1m\u001b[32m0.05298\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1171 | loss: 0.05298 - acc: 0.9917 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1172  | total loss: \u001b[1m\u001b[32m0.04932\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1172 | loss: 0.04932 - acc: 0.9925 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1173  | total loss: \u001b[1m\u001b[32m0.04602\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1173 | loss: 0.04602 - acc: 0.9932 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1174  | total loss: \u001b[1m\u001b[32m0.04305\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1174 | loss: 0.04305 - acc: 0.9939 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1175  | total loss: \u001b[1m\u001b[32m0.04037\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1175 | loss: 0.04037 - acc: 0.9945 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1176  | total loss: \u001b[1m\u001b[32m0.03795\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1176 | loss: 0.03795 - acc: 0.9951 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1177  | total loss: \u001b[1m\u001b[32m0.03577\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1177 | loss: 0.03577 - acc: 0.9956 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1178  | total loss: \u001b[1m\u001b[32m0.03381\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1178 | loss: 0.03381 - acc: 0.9960 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1179  | total loss: \u001b[1m\u001b[32m0.03203\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1179 | loss: 0.03203 - acc: 0.9964 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1180  | total loss: \u001b[1m\u001b[32m0.03043\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1180 | loss: 0.03043 - acc: 0.9968 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1181  | total loss: \u001b[1m\u001b[32m0.02898\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1181 | loss: 0.02898 - acc: 0.9971 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1182  | total loss: \u001b[1m\u001b[32m0.29094\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1182 | loss: 0.29094 - acc: 0.9474 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1183  | total loss: \u001b[1m\u001b[32m0.26345\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1183 | loss: 0.26345 - acc: 0.9526 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1184  | total loss: \u001b[1m\u001b[32m0.23872\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1184 | loss: 0.23872 - acc: 0.9574 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1185  | total loss: \u001b[1m\u001b[32m0.21647\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1185 | loss: 0.21647 - acc: 0.9616 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1186  | total loss: \u001b[1m\u001b[32m0.19646\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1186 | loss: 0.19646 - acc: 0.9655 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1187  | total loss: \u001b[1m\u001b[32m0.17845\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1187 | loss: 0.17845 - acc: 0.9689 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1188  | total loss: \u001b[1m\u001b[32m0.16225\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1188 | loss: 0.16225 - acc: 0.9720 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1189  | total loss: \u001b[1m\u001b[32m0.14768\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1189 | loss: 0.14768 - acc: 0.9748 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1190  | total loss: \u001b[1m\u001b[32m0.13456\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1190 | loss: 0.13456 - acc: 0.9774 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1191  | total loss: \u001b[1m\u001b[32m0.12276\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1191 | loss: 0.12276 - acc: 0.9796 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1192  | total loss: \u001b[1m\u001b[32m0.11214\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 1192 | loss: 0.11214 - acc: 0.9817 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1193  | total loss: \u001b[1m\u001b[32m0.10258\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1193 | loss: 0.10258 - acc: 0.9835 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1194  | total loss: \u001b[1m\u001b[32m0.09398\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1194 | loss: 0.09398 - acc: 0.9851 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1195  | total loss: \u001b[1m\u001b[32m0.08624\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1195 | loss: 0.08624 - acc: 0.9866 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1196  | total loss: \u001b[1m\u001b[32m0.07927\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1196 | loss: 0.07927 - acc: 0.9880 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1197  | total loss: \u001b[1m\u001b[32m0.07299\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1197 | loss: 0.07299 - acc: 0.9892 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1198  | total loss: \u001b[1m\u001b[32m0.06734\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1198 | loss: 0.06734 - acc: 0.9902 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1199  | total loss: \u001b[1m\u001b[32m0.06226\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1199 | loss: 0.06226 - acc: 0.9912 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1200  | total loss: \u001b[1m\u001b[32m0.05767\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1200 | loss: 0.05767 - acc: 0.9921 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1201  | total loss: \u001b[1m\u001b[32m0.04983\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1201 | loss: 0.04983 - acc: 0.9929 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1202  | total loss: \u001b[1m\u001b[32m0.04983\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1202 | loss: 0.04983 - acc: 0.9936 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1203  | total loss: \u001b[1m\u001b[32m0.04648\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1203 | loss: 0.04648 - acc: 0.9942 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1204  | total loss: \u001b[1m\u001b[32m0.04346\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1204 | loss: 0.04346 - acc: 0.9948 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1205  | total loss: \u001b[1m\u001b[32m0.04073\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1205 | loss: 0.04073 - acc: 0.9953 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1206  | total loss: \u001b[1m\u001b[32m0.03828\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1206 | loss: 0.03828 - acc: 0.9958 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1207  | total loss: \u001b[1m\u001b[32m0.03606\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1207 | loss: 0.03606 - acc: 0.9962 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1208  | total loss: \u001b[1m\u001b[32m0.03407\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1208 | loss: 0.03407 - acc: 0.9966 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1209  | total loss: \u001b[1m\u001b[32m0.03226\u001b[0m\u001b[0m | time: 0.015s\n",
      "| Adam | epoch: 1209 | loss: 0.03226 - acc: 0.9969 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1210  | total loss: \u001b[1m\u001b[32m0.03063\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1210 | loss: 0.03063 - acc: 0.9972 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1211  | total loss: \u001b[1m\u001b[32m0.02916\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1211 | loss: 0.02916 - acc: 0.9975 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1212  | total loss: \u001b[1m\u001b[32m0.02783\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1212 | loss: 0.02783 - acc: 0.9978 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1213  | total loss: \u001b[1m\u001b[32m0.02663\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1213 | loss: 0.02663 - acc: 0.9980 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1214  | total loss: \u001b[1m\u001b[32m0.02554\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1214 | loss: 0.02554 - acc: 0.9982 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1215  | total loss: \u001b[1m\u001b[32m0.02455\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1215 | loss: 0.02455 - acc: 0.9984 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1216  | total loss: \u001b[1m\u001b[32m0.02366\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1216 | loss: 0.02366 - acc: 0.9985 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1217  | total loss: \u001b[1m\u001b[32m0.02285\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1217 | loss: 0.02285 - acc: 0.9987 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1218  | total loss: \u001b[1m\u001b[32m0.02212\u001b[0m\u001b[0m | time: 0.015s\n",
      "| Adam | epoch: 1218 | loss: 0.02212 - acc: 0.9988 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1219  | total loss: \u001b[1m\u001b[32m0.02145\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1219 | loss: 0.02145 - acc: 0.9989 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1220  | total loss: \u001b[1m\u001b[32m0.02085\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1220 | loss: 0.02085 - acc: 0.9990 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1221  | total loss: \u001b[1m\u001b[32m0.02030\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1221 | loss: 0.02030 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1222  | total loss: \u001b[1m\u001b[32m0.01980\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1222 | loss: 0.01980 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1223  | total loss: \u001b[1m\u001b[32m0.01934\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1223 | loss: 0.01934 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1224  | total loss: \u001b[1m\u001b[32m0.01892\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1224 | loss: 0.01892 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1225  | total loss: \u001b[1m\u001b[32m0.01854\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1225 | loss: 0.01854 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1226  | total loss: \u001b[1m\u001b[32m0.01819\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1226 | loss: 0.01819 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1227  | total loss: \u001b[1m\u001b[32m0.01787\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1227 | loss: 0.01787 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1228  | total loss: \u001b[1m\u001b[32m0.01757\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1228 | loss: 0.01757 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1229  | total loss: \u001b[1m\u001b[32m0.01730\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1229 | loss: 0.01730 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1230  | total loss: \u001b[1m\u001b[32m0.01705\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1230 | loss: 0.01705 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1231  | total loss: \u001b[1m\u001b[32m0.01682\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1231 | loss: 0.01682 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1232  | total loss: \u001b[1m\u001b[32m0.01661\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1232 | loss: 0.01661 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1233  | total loss: \u001b[1m\u001b[32m0.01641\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1233 | loss: 0.01641 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1234  | total loss: \u001b[1m\u001b[32m0.01623\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1234 | loss: 0.01623 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1235  | total loss: \u001b[1m\u001b[32m0.01606\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1235 | loss: 0.01606 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1236  | total loss: \u001b[1m\u001b[32m0.24399\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1236 | loss: 0.24399 - acc: 0.9498 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1237  | total loss: \u001b[1m\u001b[32m0.22105\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1237 | loss: 0.22105 - acc: 0.9548 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1238  | total loss: \u001b[1m\u001b[32m0.20042\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1238 | loss: 0.20042 - acc: 0.9594 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1239  | total loss: \u001b[1m\u001b[32m0.18186\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1239 | loss: 0.18186 - acc: 0.9634 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1240  | total loss: \u001b[1m\u001b[32m0.16516\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1240 | loss: 0.16516 - acc: 0.9671 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1241  | total loss: \u001b[1m\u001b[32m0.15014\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1241 | loss: 0.15014 - acc: 0.9704 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1242  | total loss: \u001b[1m\u001b[32m0.13663\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1242 | loss: 0.13663 - acc: 0.9733 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1243  | total loss: \u001b[1m\u001b[32m0.12448\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1243 | loss: 0.12448 - acc: 0.9760 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1244  | total loss: \u001b[1m\u001b[32m0.11354\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1244 | loss: 0.11354 - acc: 0.9784 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1245  | total loss: \u001b[1m\u001b[32m0.10370\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1245 | loss: 0.10370 - acc: 0.9806 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1246  | total loss: \u001b[1m\u001b[32m0.09485\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1246 | loss: 0.09485 - acc: 0.9825 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1247  | total loss: \u001b[1m\u001b[32m0.08688\u001b[0m\u001b[0m | time: 0.014s\n",
      "| Adam | epoch: 1247 | loss: 0.08688 - acc: 0.9843 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1248  | total loss: \u001b[1m\u001b[32m0.07971\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1248 | loss: 0.07971 - acc: 0.9858 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1249  | total loss: \u001b[1m\u001b[32m0.07326\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1249 | loss: 0.07326 - acc: 0.9872 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1250  | total loss: \u001b[1m\u001b[32m0.06745\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1250 | loss: 0.06745 - acc: 0.9885 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1251  | total loss: \u001b[1m\u001b[32m0.06222\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1251 | loss: 0.06222 - acc: 0.9897 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1252  | total loss: \u001b[1m\u001b[32m0.05751\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1252 | loss: 0.05751 - acc: 0.9907 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1253  | total loss: \u001b[1m\u001b[32m0.05327\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1253 | loss: 0.05327 - acc: 0.9916 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1254  | total loss: \u001b[1m\u001b[32m0.04945\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1254 | loss: 0.04945 - acc: 0.9925 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1255  | total loss: \u001b[1m\u001b[32m0.04602\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1255 | loss: 0.04602 - acc: 0.9932 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1256  | total loss: \u001b[1m\u001b[32m0.04292\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1256 | loss: 0.04292 - acc: 0.9939 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1257  | total loss: \u001b[1m\u001b[32m0.04013\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1257 | loss: 0.04013 - acc: 0.9945 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1258  | total loss: \u001b[1m\u001b[32m0.03761\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1258 | loss: 0.03761 - acc: 0.9951 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1259  | total loss: \u001b[1m\u001b[32m0.03534\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1259 | loss: 0.03534 - acc: 0.9956 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1260  | total loss: \u001b[1m\u001b[32m0.03330\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1260 | loss: 0.03330 - acc: 0.9960 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1261  | total loss: \u001b[1m\u001b[32m0.03145\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1261 | loss: 0.03145 - acc: 0.9964 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1262  | total loss: \u001b[1m\u001b[32m0.02979\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1262 | loss: 0.02979 - acc: 0.9968 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1263  | total loss: \u001b[1m\u001b[32m0.02828\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1263 | loss: 0.02828 - acc: 0.9971 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1264  | total loss: \u001b[1m\u001b[32m0.02692\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1264 | loss: 0.02692 - acc: 0.9974 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1265  | total loss: \u001b[1m\u001b[32m0.02570\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1265 | loss: 0.02570 - acc: 0.9976 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1266  | total loss: \u001b[1m\u001b[32m0.02459\u001b[0m\u001b[0m | time: 0.014s\n",
      "| Adam | epoch: 1266 | loss: 0.02459 - acc: 0.9979 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1267  | total loss: \u001b[1m\u001b[32m0.02359\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1267 | loss: 0.02359 - acc: 0.9981 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1268  | total loss: \u001b[1m\u001b[32m0.02268\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1268 | loss: 0.02268 - acc: 0.9983 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1269  | total loss: \u001b[1m\u001b[32m0.02186\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1269 | loss: 0.02186 - acc: 0.9984 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1270  | total loss: \u001b[1m\u001b[32m0.02044\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1270 | loss: 0.02044 - acc: 0.9986 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1271  | total loss: \u001b[1m\u001b[32m0.02044\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1271 | loss: 0.02044 - acc: 0.9987 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1272  | total loss: \u001b[1m\u001b[32m0.01983\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1272 | loss: 0.01983 - acc: 0.9989 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1273  | total loss: \u001b[1m\u001b[32m0.01927\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1273 | loss: 0.01927 - acc: 0.9990 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1274  | total loss: \u001b[1m\u001b[32m0.01877\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1274 | loss: 0.01877 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1275  | total loss: \u001b[1m\u001b[32m0.01831\u001b[0m\u001b[0m | time: 0.014s\n",
      "| Adam | epoch: 1275 | loss: 0.01831 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1276  | total loss: \u001b[1m\u001b[32m0.01789\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1276 | loss: 0.01789 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1277  | total loss: \u001b[1m\u001b[32m0.01750\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1277 | loss: 0.01750 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1278  | total loss: \u001b[1m\u001b[32m0.01715\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1278 | loss: 0.01715 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1279  | total loss: \u001b[1m\u001b[32m0.01683\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1279 | loss: 0.01683 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1280  | total loss: \u001b[1m\u001b[32m0.01654\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1280 | loss: 0.01654 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1281  | total loss: \u001b[1m\u001b[32m0.01627\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1281 | loss: 0.01627 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1282  | total loss: \u001b[1m\u001b[32m0.01603\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1282 | loss: 0.01603 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1283  | total loss: \u001b[1m\u001b[32m0.01580\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1283 | loss: 0.01580 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1284  | total loss: \u001b[1m\u001b[32m0.01559\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1284 | loss: 0.01559 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1285  | total loss: \u001b[1m\u001b[32m0.01540\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1285 | loss: 0.01540 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1286  | total loss: \u001b[1m\u001b[32m0.01522\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1286 | loss: 0.01522 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1287  | total loss: \u001b[1m\u001b[32m0.01505\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1287 | loss: 0.01505 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1288  | total loss: \u001b[1m\u001b[32m0.01489\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1288 | loss: 0.01489 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1289  | total loss: \u001b[1m\u001b[32m0.01475\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1289 | loss: 0.01475 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1290  | total loss: \u001b[1m\u001b[32m0.01461\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1290 | loss: 0.01461 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1291  | total loss: \u001b[1m\u001b[32m0.01449\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1291 | loss: 0.01449 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1292  | total loss: \u001b[1m\u001b[32m0.01437\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1292 | loss: 0.01437 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1293  | total loss: \u001b[1m\u001b[32m0.01426\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1293 | loss: 0.01426 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1294  | total loss: \u001b[1m\u001b[32m0.01415\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 1294 | loss: 0.01415 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1295  | total loss: \u001b[1m\u001b[32m0.01405\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1295 | loss: 0.01405 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1296  | total loss: \u001b[1m\u001b[32m0.01396\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1296 | loss: 0.01396 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1297  | total loss: \u001b[1m\u001b[32m0.01387\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1297 | loss: 0.01387 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1298  | total loss: \u001b[1m\u001b[32m0.01378\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1298 | loss: 0.01378 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1299  | total loss: \u001b[1m\u001b[32m0.01370\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1299 | loss: 0.01370 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1300  | total loss: \u001b[1m\u001b[32m0.01362\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1300 | loss: 0.01362 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1301  | total loss: \u001b[1m\u001b[32m0.01354\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1301 | loss: 0.01354 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1302  | total loss: \u001b[1m\u001b[32m0.01347\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1302 | loss: 0.01347 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1303  | total loss: \u001b[1m\u001b[32m0.01340\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1303 | loss: 0.01340 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1304  | total loss: \u001b[1m\u001b[32m0.01333\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 1304 | loss: 0.01333 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1305  | total loss: \u001b[1m\u001b[32m0.01327\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1305 | loss: 0.01327 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1306  | total loss: \u001b[1m\u001b[32m0.01320\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1306 | loss: 0.01320 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1307  | total loss: \u001b[1m\u001b[32m0.01314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1307 | loss: 0.01314 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1308  | total loss: \u001b[1m\u001b[32m0.01308\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1308 | loss: 0.01308 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1309  | total loss: \u001b[1m\u001b[32m0.01302\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1309 | loss: 0.01302 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1310  | total loss: \u001b[1m\u001b[32m0.01297\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1310 | loss: 0.01297 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1311  | total loss: \u001b[1m\u001b[32m0.01291\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1311 | loss: 0.01291 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1312  | total loss: \u001b[1m\u001b[32m0.01286\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1312 | loss: 0.01286 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1313  | total loss: \u001b[1m\u001b[32m0.01280\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 1313 | loss: 0.01280 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1314  | total loss: \u001b[1m\u001b[32m0.01275\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1314 | loss: 0.01275 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1315  | total loss: \u001b[1m\u001b[32m0.01270\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1315 | loss: 0.01270 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1316  | total loss: \u001b[1m\u001b[32m0.01264\u001b[0m\u001b[0m | time: 0.000s\n",
      "| Adam | epoch: 1316 | loss: 0.01264 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1317  | total loss: \u001b[1m\u001b[32m0.01259\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1317 | loss: 0.01259 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1318  | total loss: \u001b[1m\u001b[32m0.01254\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1318 | loss: 0.01254 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1319  | total loss: \u001b[1m\u001b[32m0.01249\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1319 | loss: 0.01249 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1320  | total loss: \u001b[1m\u001b[32m0.40958\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1320 | loss: 0.40958 - acc: 0.9250 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1321  | total loss: \u001b[1m\u001b[32m0.36984\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1321 | loss: 0.36984 - acc: 0.9325 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1322  | total loss: \u001b[1m\u001b[32m0.33410\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 1322 | loss: 0.33410 - acc: 0.9392 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1323  | total loss: \u001b[1m\u001b[32m0.30194\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1323 | loss: 0.30194 - acc: 0.9453 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1324  | total loss: \u001b[1m\u001b[32m0.27302\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1324 | loss: 0.27302 - acc: 0.9508 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1325  | total loss: \u001b[1m\u001b[32m0.24699\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1325 | loss: 0.24699 - acc: 0.9557 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1326  | total loss: \u001b[1m\u001b[32m0.22359\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1326 | loss: 0.22359 - acc: 0.9601 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1327  | total loss: \u001b[1m\u001b[32m0.20253\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1327 | loss: 0.20253 - acc: 0.9641 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1328  | total loss: \u001b[1m\u001b[32m0.18359\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1328 | loss: 0.18359 - acc: 0.9677 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1329  | total loss: \u001b[1m\u001b[32m0.16654\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1329 | loss: 0.16654 - acc: 0.9709 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1330  | total loss: \u001b[1m\u001b[32m0.15121\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 1330 | loss: 0.15121 - acc: 0.9738 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1331  | total loss: \u001b[1m\u001b[32m0.12500\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1331 | loss: 0.12500 - acc: 0.9765 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1332  | total loss: \u001b[1m\u001b[32m0.11384\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1332 | loss: 0.11384 - acc: 0.9788 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1333  | total loss: \u001b[1m\u001b[32m0.10379\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1333 | loss: 0.10379 - acc: 0.9809 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1334  | total loss: \u001b[1m\u001b[32m0.10379\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1334 | loss: 0.10379 - acc: 0.9828 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1335  | total loss: \u001b[1m\u001b[32m0.08661\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1335 | loss: 0.08661 - acc: 0.9846 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1336  | total loss: \u001b[1m\u001b[32m0.07929\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1336 | loss: 0.07929 - acc: 0.9861 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1337  | total loss: \u001b[1m\u001b[32m0.07270\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 1337 | loss: 0.07270 - acc: 0.9875 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1338  | total loss: \u001b[1m\u001b[32m0.07270\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1338 | loss: 0.07270 - acc: 0.9887 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1339  | total loss: \u001b[1m\u001b[32m0.41423\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 1339 | loss: 0.41423 - acc: 0.9899 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1340  | total loss: \u001b[1m\u001b[32m0.41423\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1340 | loss: 0.41423 - acc: 0.9159 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1341  | total loss: \u001b[1m\u001b[32m0.37416\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1341 | loss: 0.37416 - acc: 0.9243 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1342  | total loss: \u001b[1m\u001b[32m0.30572\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1342 | loss: 0.30572 - acc: 0.9319 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1343  | total loss: \u001b[1m\u001b[32m0.30572\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1343 | loss: 0.30572 - acc: 0.9387 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1344  | total loss: \u001b[1m\u001b[32m0.27657\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1344 | loss: 0.27657 - acc: 0.9448 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1345  | total loss: \u001b[1m\u001b[32m0.25035\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1345 | loss: 0.25035 - acc: 0.9503 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1346  | total loss: \u001b[1m\u001b[32m0.22677\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1346 | loss: 0.22677 - acc: 0.9553 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1347  | total loss: \u001b[1m\u001b[32m0.20555\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1347 | loss: 0.20555 - acc: 0.9598 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1348  | total loss: \u001b[1m\u001b[32m0.18647\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1348 | loss: 0.18647 - acc: 0.9638 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1349  | total loss: \u001b[1m\u001b[32m0.16930\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1349 | loss: 0.16930 - acc: 0.9674 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1350  | total loss: \u001b[1m\u001b[32m0.15386\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1350 | loss: 0.15386 - acc: 0.9707 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1351  | total loss: \u001b[1m\u001b[32m0.13997\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1351 | loss: 0.13997 - acc: 0.9736 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1352  | total loss: \u001b[1m\u001b[32m0.12748\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1352 | loss: 0.12748 - acc: 0.9762 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1353  | total loss: \u001b[1m\u001b[32m0.11623\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 1353 | loss: 0.11623 - acc: 0.9786 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1354  | total loss: \u001b[1m\u001b[32m0.10612\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1354 | loss: 0.10612 - acc: 0.9808 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1355  | total loss: \u001b[1m\u001b[32m0.09701\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1355 | loss: 0.09701 - acc: 0.9827 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1356  | total loss: \u001b[1m\u001b[32m0.08882\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1356 | loss: 0.08882 - acc: 0.9844 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1357  | total loss: \u001b[1m\u001b[32m0.08145\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1357 | loss: 0.08145 - acc: 0.9860 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1358  | total loss: \u001b[1m\u001b[32m0.07482\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1358 | loss: 0.07482 - acc: 0.9874 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1359  | total loss: \u001b[1m\u001b[32m0.06885\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1359 | loss: 0.06885 - acc: 0.9886 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1360  | total loss: \u001b[1m\u001b[32m0.06347\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1360 | loss: 0.06347 - acc: 0.9898 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1361  | total loss: \u001b[1m\u001b[32m0.05863\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1361 | loss: 0.05863 - acc: 0.9908 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1362  | total loss: \u001b[1m\u001b[32m0.05428\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 1362 | loss: 0.05428 - acc: 0.9917 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1363  | total loss: \u001b[1m\u001b[32m0.05035\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1363 | loss: 0.05035 - acc: 0.9925 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1364  | total loss: \u001b[1m\u001b[32m0.04682\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1364 | loss: 0.04682 - acc: 0.9933 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1365  | total loss: \u001b[1m\u001b[32m0.04364\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1365 | loss: 0.04364 - acc: 0.9940 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1366  | total loss: \u001b[1m\u001b[32m0.04077\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1366 | loss: 0.04077 - acc: 0.9946 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1367  | total loss: \u001b[1m\u001b[32m0.03818\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1367 | loss: 0.03818 - acc: 0.9951 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1368  | total loss: \u001b[1m\u001b[32m0.03585\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1368 | loss: 0.03585 - acc: 0.9956 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1369  | total loss: \u001b[1m\u001b[32m0.03375\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1369 | loss: 0.03375 - acc: 0.9960 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1370  | total loss: \u001b[1m\u001b[32m0.03185\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1370 | loss: 0.03185 - acc: 0.9964 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1371  | total loss: \u001b[1m\u001b[32m0.03015\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1371 | loss: 0.03015 - acc: 0.9968 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1372  | total loss: \u001b[1m\u001b[32m0.02860\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1372 | loss: 0.02860 - acc: 0.9971 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1373  | total loss: \u001b[1m\u001b[32m0.02721\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1373 | loss: 0.02721 - acc: 0.9974 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1374  | total loss: \u001b[1m\u001b[32m0.02595\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1374 | loss: 0.02595 - acc: 0.9977 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1375  | total loss: \u001b[1m\u001b[32m0.02481\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1375 | loss: 0.02481 - acc: 0.9979 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1376  | total loss: \u001b[1m\u001b[32m0.33552\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1376 | loss: 0.33552 - acc: 0.9356 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1377  | total loss: \u001b[1m\u001b[32m0.30344\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1377 | loss: 0.30344 - acc: 0.9420 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1378  | total loss: \u001b[1m\u001b[32m0.27458\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1378 | loss: 0.27458 - acc: 0.9478 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1379  | total loss: \u001b[1m\u001b[32m0.24862\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1379 | loss: 0.24862 - acc: 0.9531 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1380  | total loss: \u001b[1m\u001b[32m0.22527\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1380 | loss: 0.22527 - acc: 0.9578 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1381  | total loss: \u001b[1m\u001b[32m0.20427\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 1381 | loss: 0.20427 - acc: 0.9620 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1382  | total loss: \u001b[1m\u001b[32m0.18537\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1382 | loss: 0.18537 - acc: 0.9658 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1383  | total loss: \u001b[1m\u001b[32m0.16838\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1383 | loss: 0.16838 - acc: 0.9692 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1384  | total loss: \u001b[1m\u001b[32m0.15308\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1384 | loss: 0.15308 - acc: 0.9723 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1385  | total loss: \u001b[1m\u001b[32m0.13933\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1385 | loss: 0.13933 - acc: 0.9751 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1386  | total loss: \u001b[1m\u001b[32m0.38638\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1386 | loss: 0.38638 - acc: 0.9275 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1387  | total loss: \u001b[1m\u001b[32m0.34931\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1387 | loss: 0.34931 - acc: 0.9348 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1388  | total loss: \u001b[1m\u001b[32m0.31598\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1388 | loss: 0.31598 - acc: 0.9413 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1389  | total loss: \u001b[1m\u001b[32m0.28599\u001b[0m\u001b[0m | time: 0.011s\n",
      "| Adam | epoch: 1389 | loss: 0.28599 - acc: 0.9472 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1390  | total loss: \u001b[1m\u001b[32m0.25902\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1390 | loss: 0.25902 - acc: 0.9525 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1391  | total loss: \u001b[1m\u001b[32m0.23476\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1391 | loss: 0.23476 - acc: 0.9572 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1392  | total loss: \u001b[1m\u001b[32m0.21293\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1392 | loss: 0.21293 - acc: 0.9615 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1393  | total loss: \u001b[1m\u001b[32m0.19330\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1393 | loss: 0.19330 - acc: 0.9653 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1394  | total loss: \u001b[1m\u001b[32m0.17564\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1394 | loss: 0.17564 - acc: 0.9688 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1395  | total loss: \u001b[1m\u001b[32m0.15975\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1395 | loss: 0.15975 - acc: 0.9719 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1396  | total loss: \u001b[1m\u001b[32m0.14545\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1396 | loss: 0.14545 - acc: 0.9747 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1397  | total loss: \u001b[1m\u001b[32m0.13259\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1397 | loss: 0.13259 - acc: 0.9773 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1398  | total loss: \u001b[1m\u001b[32m0.11060\u001b[0m\u001b[0m | time: 0.011s\n",
      "| Adam | epoch: 1398 | loss: 0.11060 - acc: 0.9795 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1399  | total loss: \u001b[1m\u001b[32m0.11060\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1399 | loss: 0.11060 - acc: 0.9816 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1400  | total loss: \u001b[1m\u001b[32m0.10123\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1400 | loss: 0.10123 - acc: 0.9834 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1401  | total loss: \u001b[1m\u001b[32m0.09279\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1401 | loss: 0.09279 - acc: 0.9851 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1402  | total loss: \u001b[1m\u001b[32m0.08520\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1402 | loss: 0.08520 - acc: 0.9866 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1403  | total loss: \u001b[1m\u001b[32m0.07837\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1403 | loss: 0.07837 - acc: 0.9879 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1404  | total loss: \u001b[1m\u001b[32m0.07222\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1404 | loss: 0.07222 - acc: 0.9891 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1405  | total loss: \u001b[1m\u001b[32m0.06668\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1405 | loss: 0.06668 - acc: 0.9902 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1406  | total loss: \u001b[1m\u001b[32m0.06169\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1406 | loss: 0.06169 - acc: 0.9912 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1407  | total loss: \u001b[1m\u001b[32m0.05720\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1407 | loss: 0.05720 - acc: 0.9921 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1408  | total loss: \u001b[1m\u001b[32m0.05315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1408 | loss: 0.05315 - acc: 0.9929 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1409  | total loss: \u001b[1m\u001b[32m0.04950\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1409 | loss: 0.04950 - acc: 0.9936 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1410  | total loss: \u001b[1m\u001b[32m0.04622\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1410 | loss: 0.04622 - acc: 0.9942 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1411  | total loss: \u001b[1m\u001b[32m0.04326\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1411 | loss: 0.04326 - acc: 0.9948 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1412  | total loss: \u001b[1m\u001b[32m0.04059\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1412 | loss: 0.04059 - acc: 0.9953 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1413  | total loss: \u001b[1m\u001b[32m0.03818\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1413 | loss: 0.03818 - acc: 0.9958 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1414  | total loss: \u001b[1m\u001b[32m0.03601\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1414 | loss: 0.03601 - acc: 0.9962 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1415  | total loss: \u001b[1m\u001b[32m0.03405\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1415 | loss: 0.03405 - acc: 0.9966 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1416  | total loss: \u001b[1m\u001b[32m0.03228\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1416 | loss: 0.03228 - acc: 0.9969 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1417  | total loss: \u001b[1m\u001b[32m0.03068\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1417 | loss: 0.03068 - acc: 0.9972 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1418  | total loss: \u001b[1m\u001b[32m0.02924\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1418 | loss: 0.02924 - acc: 0.9975 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1419  | total loss: \u001b[1m\u001b[32m0.02794\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1419 | loss: 0.02794 - acc: 0.9978 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1420  | total loss: \u001b[1m\u001b[32m0.02676\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1420 | loss: 0.02676 - acc: 0.9980 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1421  | total loss: \u001b[1m\u001b[32m0.02569\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1421 | loss: 0.02569 - acc: 0.9982 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1422  | total loss: \u001b[1m\u001b[32m0.02472\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1422 | loss: 0.02472 - acc: 0.9984 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1423  | total loss: \u001b[1m\u001b[32m0.02385\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1423 | loss: 0.02385 - acc: 0.9985 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1424  | total loss: \u001b[1m\u001b[32m0.02305\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1424 | loss: 0.02305 - acc: 0.9987 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1425  | total loss: \u001b[1m\u001b[32m0.02233\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1425 | loss: 0.02233 - acc: 0.9988 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1426  | total loss: \u001b[1m\u001b[32m0.02168\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1426 | loss: 0.02168 - acc: 0.9989 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1427  | total loss: \u001b[1m\u001b[32m0.02108\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1427 | loss: 0.02108 - acc: 0.9990 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1428  | total loss: \u001b[1m\u001b[32m0.02054\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1428 | loss: 0.02054 - acc: 0.9991 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1429  | total loss: \u001b[1m\u001b[32m0.02005\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1429 | loss: 0.02005 - acc: 0.9992 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1430  | total loss: \u001b[1m\u001b[32m0.01960\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1430 | loss: 0.01960 - acc: 0.9993 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1431  | total loss: \u001b[1m\u001b[32m0.01919\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1431 | loss: 0.01919 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1432  | total loss: \u001b[1m\u001b[32m0.01881\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1432 | loss: 0.01881 - acc: 0.9994 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1433  | total loss: \u001b[1m\u001b[32m0.01847\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1433 | loss: 0.01847 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1434  | total loss: \u001b[1m\u001b[32m0.01815\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1434 | loss: 0.01815 - acc: 0.9995 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1435  | total loss: \u001b[1m\u001b[32m0.01786\u001b[0m\u001b[0m | time: 0.040s\n",
      "| Adam | epoch: 1435 | loss: 0.01786 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1436  | total loss: \u001b[1m\u001b[32m0.01759\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1436 | loss: 0.01759 - acc: 0.9996 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1437  | total loss: \u001b[1m\u001b[32m0.01735\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1437 | loss: 0.01735 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1438  | total loss: \u001b[1m\u001b[32m0.01712\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1438 | loss: 0.01712 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1439  | total loss: \u001b[1m\u001b[32m0.01691\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1439 | loss: 0.01691 - acc: 0.9997 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1440  | total loss: \u001b[1m\u001b[32m0.01671\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 1440 | loss: 0.01671 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1441  | total loss: \u001b[1m\u001b[32m0.01653\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1441 | loss: 0.01653 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1442  | total loss: \u001b[1m\u001b[32m0.01636\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1442 | loss: 0.01636 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1443  | total loss: \u001b[1m\u001b[32m0.01620\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1443 | loss: 0.01620 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1444  | total loss: \u001b[1m\u001b[32m0.01606\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1444 | loss: 0.01606 - acc: 0.9998 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1445  | total loss: \u001b[1m\u001b[32m0.01592\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1445 | loss: 0.01592 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1446  | total loss: \u001b[1m\u001b[32m0.01579\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1446 | loss: 0.01579 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1447  | total loss: \u001b[1m\u001b[32m0.01566\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1447 | loss: 0.01566 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1448  | total loss: \u001b[1m\u001b[32m0.01555\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1448 | loss: 0.01555 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1449  | total loss: \u001b[1m\u001b[32m0.01544\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1449 | loss: 0.01544 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1450  | total loss: \u001b[1m\u001b[32m0.01533\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1450 | loss: 0.01533 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1451  | total loss: \u001b[1m\u001b[32m0.01523\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1451 | loss: 0.01523 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1452  | total loss: \u001b[1m\u001b[32m0.01514\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1452 | loss: 0.01514 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1453  | total loss: \u001b[1m\u001b[32m0.01505\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1453 | loss: 0.01505 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1454  | total loss: \u001b[1m\u001b[32m0.01496\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1454 | loss: 0.01496 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1455  | total loss: \u001b[1m\u001b[32m0.01487\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1455 | loss: 0.01487 - acc: 0.9999 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1456  | total loss: \u001b[1m\u001b[32m0.01479\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1456 | loss: 0.01479 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1457  | total loss: \u001b[1m\u001b[32m0.01471\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1457 | loss: 0.01471 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1458  | total loss: \u001b[1m\u001b[32m0.01464\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1458 | loss: 0.01464 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1459  | total loss: \u001b[1m\u001b[32m0.01456\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1459 | loss: 0.01456 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1460  | total loss: \u001b[1m\u001b[32m0.01449\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1460 | loss: 0.01449 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1461  | total loss: \u001b[1m\u001b[32m0.01442\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1461 | loss: 0.01442 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1462  | total loss: \u001b[1m\u001b[32m0.01435\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1462 | loss: 0.01435 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1463  | total loss: \u001b[1m\u001b[32m0.01429\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1463 | loss: 0.01429 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1464  | total loss: \u001b[1m\u001b[32m0.01422\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1464 | loss: 0.01422 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1465  | total loss: \u001b[1m\u001b[32m0.01416\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1465 | loss: 0.01416 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1466  | total loss: \u001b[1m\u001b[32m0.01410\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1466 | loss: 0.01410 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1467  | total loss: \u001b[1m\u001b[32m0.01404\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1467 | loss: 0.01404 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1468  | total loss: \u001b[1m\u001b[32m0.01398\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1468 | loss: 0.01398 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1469  | total loss: \u001b[1m\u001b[32m0.01392\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1469 | loss: 0.01392 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1470  | total loss: \u001b[1m\u001b[32m0.01386\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1470 | loss: 0.01386 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1471  | total loss: \u001b[1m\u001b[32m0.01380\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1471 | loss: 0.01380 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1472  | total loss: \u001b[1m\u001b[32m0.01375\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1472 | loss: 0.01375 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1473  | total loss: \u001b[1m\u001b[32m0.01363\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1473 | loss: 0.01363 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1474  | total loss: \u001b[1m\u001b[32m0.01363\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1474 | loss: 0.01363 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1475  | total loss: \u001b[1m\u001b[32m0.01358\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1475 | loss: 0.01358 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1476  | total loss: \u001b[1m\u001b[32m0.01353\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1476 | loss: 0.01353 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1477  | total loss: \u001b[1m\u001b[32m0.01347\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1477 | loss: 0.01347 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1478  | total loss: \u001b[1m\u001b[32m0.01342\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1478 | loss: 0.01342 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1479  | total loss: \u001b[1m\u001b[32m0.01337\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1479 | loss: 0.01337 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1480  | total loss: \u001b[1m\u001b[32m0.01332\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1480 | loss: 0.01332 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1481  | total loss: \u001b[1m\u001b[32m0.01327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1481 | loss: 0.01327 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1482  | total loss: \u001b[1m\u001b[32m0.01322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1482 | loss: 0.01322 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1483  | total loss: \u001b[1m\u001b[32m0.01317\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1483 | loss: 0.01317 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1484  | total loss: \u001b[1m\u001b[32m0.01312\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1484 | loss: 0.01312 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1485  | total loss: \u001b[1m\u001b[32m0.01307\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1485 | loss: 0.01307 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1486  | total loss: \u001b[1m\u001b[32m0.01302\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1486 | loss: 0.01302 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1487  | total loss: \u001b[1m\u001b[32m0.01297\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1487 | loss: 0.01297 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1488  | total loss: \u001b[1m\u001b[32m0.01292\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1488 | loss: 0.01292 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1489  | total loss: \u001b[1m\u001b[32m0.01287\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1489 | loss: 0.01287 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1490  | total loss: \u001b[1m\u001b[32m0.01282\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1490 | loss: 0.01282 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1491  | total loss: \u001b[1m\u001b[32m0.01278\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1491 | loss: 0.01278 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1492  | total loss: \u001b[1m\u001b[32m0.01273\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 1492 | loss: 0.01273 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1493  | total loss: \u001b[1m\u001b[32m0.01268\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1493 | loss: 0.01268 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1494  | total loss: \u001b[1m\u001b[32m0.01264\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1494 | loss: 0.01264 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1495  | total loss: \u001b[1m\u001b[32m0.01259\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1495 | loss: 0.01259 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1496  | total loss: \u001b[1m\u001b[32m0.01255\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1496 | loss: 0.01255 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1497  | total loss: \u001b[1m\u001b[32m0.01250\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1497 | loss: 0.01250 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1498  | total loss: \u001b[1m\u001b[32m0.01246\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1498 | loss: 0.01246 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1499  | total loss: \u001b[1m\u001b[32m0.01241\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 1499 | loss: 0.01241 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "Training Step: 1500  | total loss: \u001b[1m\u001b[32m0.01237\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1500 | loss: 0.01237 - acc: 1.0000 -- iter: 8/8\n",
      "--\n",
      "INFO:tensorflow:c:\\Users\\user\\Desktop\\BotTrial\\model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.fit(training,output,n_epoch=1500,batch_size=8,show_metric=True)\n",
    "model.save(\"model.tflearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fd9120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(s, words):\n",
    "    bag = [0 for _ in range(len(words))]\n",
    "\n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "\n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i] = 1\n",
    "\n",
    "    return numpy.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25baedf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start talking with your bot (type quit to stop):\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def chat():\n",
    "    print(\"Start talking with your bot (type quit to stop):\")\n",
    "    while True:\n",
    "        inp=input(\"You:\")\n",
    "        if inp.lower()==\"quit\":\n",
    "            break\n",
    "        results=model.predict([bag_of_words(inp,words)])\n",
    "        results_index=numpy.argmax(results)\n",
    "        tag=labels[results_index]\n",
    "\n",
    "        for tg in data[\"intents\"]:\n",
    "            if tg[\"tag\"]==tag:\n",
    "                responses=tg[\"responses\"]\n",
    "        print(random.choice(responses))\n",
    "chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
