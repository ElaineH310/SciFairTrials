{"cells":[{"cell_type":"code","source":["# Importing google drive to colab\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","# to change the current working directory for the notebook environment\n","%cd '/content/gdrive/MyDrive/Colab Notebooks/SciFair/NLP'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WycF-ITa7X0W","executionInfo":{"status":"ok","timestamp":1730265964090,"user_tz":-480,"elapsed":3823,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}},"outputId":"3409c1bd-1c58-4a78-8029-8be52b480010"},"id":"WycF-ITa7X0W","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","/content/gdrive/MyDrive/Colab Notebooks/SciFair/NLP\n"]}]},{"cell_type":"code","execution_count":2,"id":"c259c2ed","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c259c2ed","executionInfo":{"status":"ok","timestamp":1730265987456,"user_tz":-480,"elapsed":20371,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}},"outputId":"f8b9ad00-1d1a-4c60-d138-7208a7626f9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.3)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.5)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n","Collecting git+https://github.com/MihaMarkic/tflearn.git@fix/is_sequence_missing\n","  Cloning https://github.com/MihaMarkic/tflearn.git (to revision fix/is_sequence_missing) to /tmp/pip-req-build-dg_24xk4\n","  Running command git clone --filter=blob:none --quiet https://github.com/MihaMarkic/tflearn.git /tmp/pip-req-build-dg_24xk4\n","  Running command git checkout -b fix/is_sequence_missing --track origin/fix/is_sequence_missing\n","  Switched to a new branch 'fix/is_sequence_missing'\n","  Branch 'fix/is_sequence_missing' set up to track remote branch 'fix/is_sequence_missing' from 'origin'.\n","  Resolved https://github.com/MihaMarkic/tflearn.git to commit 6472b8588e758ff4a33a2764d4ee638bbd0e42f0\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tflearn==0.5.0) (1.26.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tflearn==0.5.0) (1.16.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tflearn==0.5.0) (9.5.0)\n","Requirement already satisfied: Pillow==9.5.0 in /usr/local/lib/python3.10/dist-packages (9.5.0)\n"]}],"source":["!pip install numpy\n","!pip install nltk\n","!pip install tensorflow\n","\n","!pip install git+https://github.com/MihaMarkic/tflearn.git@fix/is_sequence_missing\n","!pip install Pillow==9.5.0"]},{"cell_type":"code","execution_count":3,"id":"bb9b4825","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bb9b4825","executionInfo":{"status":"ok","timestamp":1730265998494,"user_tz":-480,"elapsed":8215,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}},"outputId":"3dc01a05-813c-4a16-bbf7-28e60d01a423"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["import nltk\n","nltk.download('punkt')\n","from nltk.stem.lancaster import LancasterStemmer\n","stemmer=LancasterStemmer()\n","import numpy\n","# import tflearn #only works in local\n","import tensorflow\n","import random\n","import json\n","with open('intents_ZH-TW.json') as file:\n","    data=json.load(file)"]},{"cell_type":"code","execution_count":4,"id":"7155741b","metadata":{"id":"7155741b","executionInfo":{"status":"ok","timestamp":1730266025622,"user_tz":-480,"elapsed":1104,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}}},"outputs":[],"source":["'''\n","try:\n","    with open(\"data.pickle\", \"rb\") as f:\n","        words, labels, training, output = pickle.load(f)\n","except:\n","'''\n","words=[]\n","labels=[]\n","docs_x=[]\n","docs_y=[]\n","for intent in data[\"intents\"]:\n","    for pattern in intent[\"patterns\"]:\n","        wrds=nltk.word_tokenize(pattern)\n","        words.extend(wrds)\n","        docs_x.append(wrds)\n","        docs_y.append(intent[\"tag\"])\n","\n","    if intent['tag'] not in labels:\n","        labels.append (intent[\"tag\"])\n"]},{"cell_type":"code","execution_count":5,"id":"3309bd41","metadata":{"id":"3309bd41","executionInfo":{"status":"ok","timestamp":1730266029697,"user_tz":-480,"elapsed":1066,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}}},"outputs":[],"source":["words=[stemmer.stem(w.lower()) for w in words if w !=\"?\"]\n","words=sorted(list(set(words)))\n","labels=sorted(labels)"]},{"cell_type":"code","execution_count":6,"id":"b386c8c9","metadata":{"id":"b386c8c9","executionInfo":{"status":"ok","timestamp":1730266034012,"user_tz":-480,"elapsed":869,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}}},"outputs":[],"source":["training=[]\n","output=[]\n","out_empty=[0 for _ in range(len(labels))]\n","for x,doc in enumerate(docs_x):\n","    bag=[]\n","    wrds=[stemmer.stem(w.lower()) for w in doc]\n","    for w in words:\n","        if w in wrds:\n","            bag.append(1)\n","        else:\n","            bag.append(0)\n","    output_row=out_empty[:]\n","    output_row[labels.index(docs_y[x])]=1\n","\n","    training.append(bag)\n","    output.append(output_row)"]},{"cell_type":"code","execution_count":7,"id":"ace03c67","metadata":{"id":"ace03c67","executionInfo":{"status":"ok","timestamp":1730266035647,"user_tz":-480,"elapsed":1087,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}}},"outputs":[],"source":["training=numpy.array(training)\n","output=numpy.array(output)"]},{"cell_type":"code","source":["# !pip uninstall tflearn\n","# !pip install git+https://github.com/MihaMarkic/tflearn.git@fix/is_sequence_missing"],"metadata":{"id":"YrUGWafz2EsV"},"id":"YrUGWafz2EsV","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install Pillow==9.5.0"],"metadata":{"id":"cGHu0CsY2uek"},"id":"cGHu0CsY2uek","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":8,"id":"a0137a82","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a0137a82","executionInfo":{"status":"ok","timestamp":1730266041446,"user_tz":-480,"elapsed":2495,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}},"outputId":"8959fefc-1bee-48a8-ea4b-7ef8c900e20a"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tflearn/initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import backend as K\n","import tflearn\n","\n","K.clear_session()\n","\n","net = tflearn.input_data(shape=[None, len(training[0])])\n","net = tflearn.fully_connected(net, 8)\n","net = tflearn.fully_connected(net, 8)\n","net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\")\n","net = tflearn.regression(net)\n","\n","model = tflearn.DNN(net)"]},{"cell_type":"code","execution_count":9,"id":"fa21117f","metadata":{"id":"fa21117f","outputId":"c079795f-a3d6-4dbb-af8d-b917adc0a82e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730266754864,"user_tz":-480,"elapsed":709427,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Training Step: 17999  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.074s\n","| Adam | epoch: 1500 | loss: 0.00003 - acc: 1.0000 -- iter: 88/93\n","Training Step: 18000  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.078s\n","| Adam | epoch: 1500 | loss: 0.00003 - acc: 1.0000 -- iter: 93/93\n","--\n"]}],"source":["model.fit(training,output,n_epoch=1500,batch_size=8,show_metric=True)\n","model.save(\"model.tflearn\")"]},{"cell_type":"code","execution_count":10,"id":"8fd9120b","metadata":{"id":"8fd9120b","executionInfo":{"status":"ok","timestamp":1730266795088,"user_tz":-480,"elapsed":1109,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}}},"outputs":[],"source":["def bag_of_words(s, words):\n","    bag = [0 for _ in range(len(words))]\n","\n","    s_words = nltk.word_tokenize(s)\n","    s_words = [stemmer.stem(word.lower()) for word in s_words]\n","\n","    for se in s_words:\n","        for i, w in enumerate(words):\n","            if w == se:\n","                bag[i] = 1\n","\n","    return numpy.array(bag)"]},{"cell_type":"code","source":["!apt-get update && apt-get install -y libasound2-dev"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qQZtU20RBXXd","executionInfo":{"status":"ok","timestamp":1730266808728,"user_tz":-480,"elapsed":11569,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}},"outputId":"c0701e4a-8ef9-423b-a9ad-25ea93018523"},"id":"qQZtU20RBXXd","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,091 kB]\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Ign:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:11 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n","Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,377 kB]\n","Get:14 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [51.8 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,654 kB]\n","Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,431 kB]\n","Get:18 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.7 kB]\n","Get:19 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,208 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,286 kB]\n","Get:21 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,605 kB]\n","Fetched 24.1 MB in 6s (4,189 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","libasound2-dev is already the newest version (1.2.6.1-1ubuntu1).\n","0 upgraded, 0 newly installed, 0 to remove and 53 not upgraded.\n"]}]},{"cell_type":"code","source":["!pip install SpeechRecognition\n","!pip install gTTS"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B6atIVJXl0SQ","executionInfo":{"status":"ok","timestamp":1730266907706,"user_tz":-480,"elapsed":6805,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}},"outputId":"dfa92dde-ba2a-49d3-c4ae-a44a71a1e3b1"},"id":"B6atIVJXl0SQ","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting SpeechRecognition\n","  Downloading SpeechRecognition-3.11.0-py2.py3-none-any.whl.metadata (28 kB)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.32.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.8.30)\n","Downloading SpeechRecognition-3.11.0-py2.py3-none-any.whl (32.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: SpeechRecognition\n","Successfully installed SpeechRecognition-3.11.0\n","Collecting gTTS\n","  Downloading gTTS-2.5.3-py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.32.3)\n","Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2024.8.30)\n","Downloading gTTS-2.5.3-py3-none-any.whl (29 kB)\n","Installing collected packages: gTTS\n","Successfully installed gTTS-2.5.3\n"]}]},{"cell_type":"code","source":["!pip install ffmpeg-python"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QURZAB7o-Jey","executionInfo":{"status":"ok","timestamp":1730267362123,"user_tz":-480,"elapsed":3057,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}},"outputId":"42cef6be-80ac-4fcb-8c83-824c4888a535"},"id":"QURZAB7o-Jey","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ffmpeg-python\n","  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (1.0.0)\n","Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n","Installing collected packages: ffmpeg-python\n","Successfully installed ffmpeg-python-0.2.0\n"]}]},{"cell_type":"code","source":["from IPython.display import HTML, Audio\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","import numpy as np\n","from scipy.io.wavfile import read as wav_read\n","import io\n","import ffmpeg\n","\n","AUDIO_HTML = \"\"\"\n","<script>\n","var my_div = document.createElement(\"DIV\");\n","var my_p = document.createElement(\"P\");\n","var my_btn = document.createElement(\"BUTTON\");\n","var t = document.createTextNode(\"Press to start recording\");\n","\n","my_btn.appendChild(t);\n","//my_p.appendChild(my_btn);\n","my_div.appendChild(my_btn);\n","document.body.appendChild(my_div);\n","\n","var base64data = 0;\n","var reader;\n","var recorder, gumStream;\n","var recordButton = my_btn;\n","\n","var handleSuccess = function(stream) {\n","  gumStream = stream;\n","  var options = {\n","    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n","    mimeType : 'audio/webm;codecs=opus'\n","    //mimeType : 'audio/webm;codecs=pcm'\n","  };\n","  //recorder = new MediaRecorder(stream, options);\n","  recorder = new MediaRecorder(stream);\n","  recorder.ondataavailable = function(e) {\n","    var url = URL.createObjectURL(e.data);\n","    var preview = document.createElement('audio');\n","    preview.controls = true;\n","    preview.src = url;\n","    document.body.appendChild(preview);\n","\n","    reader = new FileReader();\n","    reader.readAsDataURL(e.data);\n","    reader.onloadend = function() {\n","      base64data = reader.result;\n","      //console.log(\"Inside FileReader:\" + base64data);\n","    }\n","  };\n","  recorder.start();\n","  };\n","\n","recordButton.innerText = \"Recording... press to stop\";\n","\n","navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n","\n","\n","function toggleRecording() {\n","  if (recorder && recorder.state == \"recording\") {\n","      recorder.stop();\n","      gumStream.getAudioTracks()[0].stop();\n","      recordButton.innerText = \"Saving the recording... pls wait!\"\n","  }\n","}\n","\n","// https://stackoverflow.com/a/951057\n","function sleep(ms) {\n","  return new Promise(resolve => setTimeout(resolve, ms));\n","}\n","\n","var data = new Promise(resolve=>{\n","//recordButton.addEventListener(\"click\", toggleRecording);\n","recordButton.onclick = ()=>{\n","toggleRecording()\n","\n","sleep(2000).then(() => {\n","  // wait 2000ms for the data to be available...\n","  // ideally this should use something like await...\n","  //console.log(\"Inside data:\" + base64data)\n","  resolve(base64data.toString())\n","\n","});\n","\n","}\n","});\n","\n","</script>\n","\"\"\"\n","\n","def get_audio():\n","  display(HTML(AUDIO_HTML))\n","  data = eval_js(\"data\")\n","\n","  # Check if data contains a comma before splitting\n","  if ',' in data:\n","    binary = b64decode(data.split(',')[1])\n","  else:\n","    # Handle the case where data doesn't contain a comma\n","    # For example, you might want to raise an exception or return an error value\n","    # Here, we're assuming the data is already base64 encoded and doesn't need splitting\n","    binary = b64decode(data)\n","\n","  process = (ffmpeg\n","    .input('pipe:0')\n","    .output('pipe:1', format='wav')\n","    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n","  )\n","  output, err = process.communicate(input=binary)\n","\n","  riff_chunk_size = len(output) - 8\n","  # Break up the chunk size into four bytes, held in b.\n","  q = riff_chunk_size\n","  b = []\n","  for i in range(4):\n","      q, r = divmod(q, 256)\n","      b.append(r)\n","\n","  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n","  riff = output[:4] + bytes(b) + output[8:]\n","\n","  sr, audio = wav_read(io.BytesIO(riff))\n","\n","  return audio, sr"],"metadata":{"id":"WWjXhVVh9tRB","executionInfo":{"status":"ok","timestamp":1730269261441,"user_tz":-480,"elapsed":536,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}}},"id":"WWjXhVVh9tRB","execution_count":40,"outputs":[]},{"cell_type":"code","source":["audio, sr = get_audio()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":96},"id":"AhdxwL-N-pux","executionInfo":{"status":"ok","timestamp":1730267504243,"user_tz":-480,"elapsed":14182,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}},"outputId":"f260aef5-d4ee-4308-da83-fc9f8c1d86c7"},"id":"AhdxwL-N-pux","execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<script>\n","var my_div = document.createElement(\"DIV\");\n","var my_p = document.createElement(\"P\");\n","var my_btn = document.createElement(\"BUTTON\");\n","var t = document.createTextNode(\"Press to start recording\");\n","\n","my_btn.appendChild(t);\n","//my_p.appendChild(my_btn);\n","my_div.appendChild(my_btn);\n","document.body.appendChild(my_div);\n","\n","var base64data = 0;\n","var reader;\n","var recorder, gumStream;\n","var recordButton = my_btn;\n","\n","var handleSuccess = function(stream) {\n","  gumStream = stream;\n","  var options = {\n","    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n","    mimeType : 'audio/webm;codecs=opus'\n","    //mimeType : 'audio/webm;codecs=pcm'\n","  };            \n","  //recorder = new MediaRecorder(stream, options);\n","  recorder = new MediaRecorder(stream);\n","  recorder.ondataavailable = function(e) {            \n","    var url = URL.createObjectURL(e.data);\n","    var preview = document.createElement('audio');\n","    preview.controls = true;\n","    preview.src = url;\n","    document.body.appendChild(preview);\n","\n","    reader = new FileReader();\n","    reader.readAsDataURL(e.data); \n","    reader.onloadend = function() {\n","      base64data = reader.result;\n","      //console.log(\"Inside FileReader:\" + base64data);\n","    }\n","  };\n","  recorder.start();\n","  };\n","\n","recordButton.innerText = \"Recording... press to stop\";\n","\n","navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n","\n","\n","function toggleRecording() {\n","  if (recorder && recorder.state == \"recording\") {\n","      recorder.stop();\n","      gumStream.getAudioTracks()[0].stop();\n","      recordButton.innerText = \"Saving the recording... pls wait!\"\n","  }\n","}\n","\n","// https://stackoverflow.com/a/951057\n","function sleep(ms) {\n","  return new Promise(resolve => setTimeout(resolve, ms));\n","}\n","\n","var data = new Promise(resolve=>{\n","//recordButton.addEventListener(\"click\", toggleRecording);\n","recordButton.onclick = ()=>{\n","toggleRecording()\n","\n","sleep(2000).then(() => {\n","  // wait 2000ms for the data to be available...\n","  // ideally this should use something like await...\n","  //console.log(\"Inside data:\" + base64data)\n","  resolve(base64data.toString())\n","\n","});\n","\n","}\n","});\n","      \n","</script>\n"]},"metadata":{}}]},{"cell_type":"code","source":["!pip install whisper\n","!pip install sounddevice wavio\n","!pip install git+https://github.com/openai/whisper.git\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ZmwHtO4AJX9","executionInfo":{"status":"ok","timestamp":1730267558566,"user_tz":-480,"elapsed":28992,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}},"outputId":"ae4be648-15fd-4e65-e1f5-5cbabe76a990"},"id":"-ZmwHtO4AJX9","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting whisper\n","  Downloading whisper-1.1.10.tar.gz (42 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from whisper) (1.16.0)\n","Building wheels for collected packages: whisper\n","  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41120 sha256=521cd882bbadd9a6dec1ebf066b33f804af7158a436150aa9f1214b2c79de33d\n","  Stored in directory: /root/.cache/pip/wheels/aa/7c/1d/015619716e2facae6631312503baf3c3220e6a9a3508cb14b6\n","Successfully built whisper\n","Installing collected packages: whisper\n","Successfully installed whisper-1.1.10\n","Collecting sounddevice\n","  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n","Collecting wavio\n","  Downloading wavio-0.0.9-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice) (1.17.1)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from wavio) (1.26.4)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice) (2.22)\n","Downloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n","Downloading wavio-0.0.9-py3-none-any.whl (9.5 kB)\n","Installing collected packages: wavio, sounddevice\n","Successfully installed sounddevice-0.5.1 wavio-0.0.9\n","Collecting git+https://github.com/openai/whisper.git\n","  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-5r_bw5e6\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-5r_bw5e6\n","  Resolved https://github.com/openai/whisper.git to commit 5979f03701209bb035a0a466f14131aeb1116cbb\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.60.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (1.26.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.5.0+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (4.66.5)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (10.5.0)\n","Collecting tiktoken (from openai-whisper==20240930)\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Collecting triton>=2.0.0 (from openai-whisper==20240930)\n","  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper==20240930) (3.16.1)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (2024.6.1)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n","Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: openai-whisper\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803560 sha256=723df8a951bf2307e6a89eba78ca6735fdfadb955e8e85ef0d1538c2c709d73d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-46w15c_0/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n","Successfully built openai-whisper\n","Installing collected packages: triton, tiktoken, openai-whisper\n","Successfully installed openai-whisper-20240930 tiktoken-0.8.0 triton-3.1.0\n"]}]},{"cell_type":"code","source":["!pip install gtts\n","from gtts import gTTS\n","import os\n","import time"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_VfZhIIEETpv","executionInfo":{"status":"ok","timestamp":1730269101923,"user_tz":-480,"elapsed":2338,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}},"outputId":"19639607-2984-4f72-86df-9ea047654dd7"},"id":"_VfZhIIEETpv","execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gtts in /usr/local/lib/python3.10/dist-packages (2.5.3)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.32.3)\n","Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.8.30)\n"]}]},{"cell_type":"code","source":["import random\n","import time\n","import numpy as np\n","import whisper\n","import sounddevice as sd\n","import wavio\n","import os\n","\n","\n","# Load Whisper model (you can choose 'base', 'small', 'medium', 'large')\n","whisper_model = whisper.load_model(\"base\")\n","\n","# Function to record audio from the microphone\n","def record_audio(duration=5):\n","    print(f\"Recording for {duration} seconds...\")\n","\n","    # Call get_audio to record audio\n","    audio, sr = get_audio()\n","\n","    # Save the recorded audio as a WAV file\n","    filename = \"recorded_audio.wav\"\n","    wavio.write(filename, audio, sr, sampwidth=3)  # Save as WAV file\n","\n","    return filename\n","\n","\n","# Function to transcribe the recorded audio using Whisper\n","def transcribe_audio(filename):\n","    result = whisper_model.transcribe(filename, language='zh')  # Specify Chinese language\n","    return result['text']\n","\n","def speak(text):\n","    tts = gTTS(text=text, lang='zh', slow=False)  # Adjust 'lang' as needed\n","    filename = \"temp_audio.mp3\"\n","    tts.save(filename)\n","    os.system(f\"start {filename}\")  # For Windows; use 'xdg-open' for Linux, 'afplay' for macOS\n","\n","# Main chat function\n","def chat():\n","    print(\"開始與您的機器人對話（輸入 結束 以停止）：\")\n","    speak(\"開始與您的機器人對話，輸入結束以停止\")\n","    time.sleep(2)\n","\n","    while True:\n","        try:\n","            choice = input(\"輸入 '1' 以進行文字輸入，或 '2' 以進行語音輸入：\")\n","            if choice == '1':  # Text input\n","                inp = input(\"請輸入您的問題：\")\n","            elif choice == '2':  # Speech input\n","                filename = record_audio(duration=5)\n","                inp = transcribe_audio(filename)  # Transcribe the recorded audio\n","                print(\"You (語音):\", inp)\n","            else:\n","                print(\"無效的選擇，請輸入 '1' 或 '2'。\")\n","                continue  # Skip to the next iteration\n","\n","            time.sleep(2)\n","            if inp == \"結束\":\n","                speak(\"再見！\")\n","                print(\"再見！\")\n","                break\n","\n","            # Process the input for the chatbot\n","            results = model.predict([bag_of_words(inp, words)])\n","            results_index = np.argmax(results)\n","            tag = labels[results_index]\n","\n","            for tg in data[\"intents\"]:\n","                if tg[\"tag\"] == tag:\n","                    responses = tg[\"responses\"]\n","\n","            rd = random.choice(responses)\n","            speak(rd)  # Speak the response\n","            print(rd)\n","            time.sleep(2)\n","\n","        except Exception as e:\n","            speak(\"抱歉，發生了錯誤\")\n","            print(\"發生錯誤:\", e)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GTEwt7lJAFHN","executionInfo":{"status":"ok","timestamp":1730269709889,"user_tz":-480,"elapsed":3012,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}},"outputId":"b7802bd6-e1aa-4e4a-b332-03d1cce03b2a"},"id":"GTEwt7lJAFHN","execution_count":48,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(fp, map_location=device)\n"]}]},{"cell_type":"code","source":["chat()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":630},"id":"9QmNyD3kFBVn","executionInfo":{"status":"ok","timestamp":1730269777332,"user_tz":-480,"elapsed":65178,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}},"outputId":"a0c96b4d-0a05-47ed-ed6b-d5ba7b5bfa73"},"id":"9QmNyD3kFBVn","execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["開始與您的機器人對話（輸入 結束 以停止）：\n","輸入 '1' 以進行文字輸入，或 '2' 以進行語音輸入：2\n","Recording for 5 seconds...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<script>\n","var my_div = document.createElement(\"DIV\");\n","var my_p = document.createElement(\"P\");\n","var my_btn = document.createElement(\"BUTTON\");\n","var t = document.createTextNode(\"Press to start recording\");\n","\n","my_btn.appendChild(t);\n","//my_p.appendChild(my_btn);\n","my_div.appendChild(my_btn);\n","document.body.appendChild(my_div);\n","\n","var base64data = 0;\n","var reader;\n","var recorder, gumStream;\n","var recordButton = my_btn;\n","\n","var handleSuccess = function(stream) {\n","  gumStream = stream;\n","  var options = {\n","    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n","    mimeType : 'audio/webm;codecs=opus'\n","    //mimeType : 'audio/webm;codecs=pcm'\n","  };            \n","  //recorder = new MediaRecorder(stream, options);\n","  recorder = new MediaRecorder(stream);\n","  recorder.ondataavailable = function(e) {            \n","    var url = URL.createObjectURL(e.data);\n","    var preview = document.createElement('audio');\n","    preview.controls = true;\n","    preview.src = url;\n","    document.body.appendChild(preview);\n","\n","    reader = new FileReader();\n","    reader.readAsDataURL(e.data); \n","    reader.onloadend = function() {\n","      base64data = reader.result;\n","      //console.log(\"Inside FileReader:\" + base64data);\n","    }\n","  };\n","  recorder.start();\n","  };\n","\n","recordButton.innerText = \"Recording... press to stop\";\n","\n","navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n","\n","\n","function toggleRecording() {\n","  if (recorder && recorder.state == \"recording\") {\n","      recorder.stop();\n","      gumStream.getAudioTracks()[0].stop();\n","      recordButton.innerText = \"Saving the recording... pls wait!\"\n","  }\n","}\n","\n","// https://stackoverflow.com/a/951057\n","function sleep(ms) {\n","  return new Promise(resolve => setTimeout(resolve, ms));\n","}\n","\n","var data = new Promise(resolve=>{\n","//recordButton.addEventListener(\"click\", toggleRecording);\n","recordButton.onclick = ()=>{\n","toggleRecording()\n","\n","sleep(2000).then(() => {\n","  // wait 2000ms for the data to be available...\n","  // ideally this should use something like await...\n","  //console.log(\"Inside data:\" + base64data)\n","  resolve(base64data.toString())\n","\n","});\n","\n","}\n","});\n","      \n","</script>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["You (語音): \n","親密關係中的問題可能對心理健康有重大影響。你是否願意分享更多關於這方面的情況？\n","輸入 '1' 以進行文字輸入，或 '2' 以進行語音輸入：2\n","Recording for 5 seconds...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<script>\n","var my_div = document.createElement(\"DIV\");\n","var my_p = document.createElement(\"P\");\n","var my_btn = document.createElement(\"BUTTON\");\n","var t = document.createTextNode(\"Press to start recording\");\n","\n","my_btn.appendChild(t);\n","//my_p.appendChild(my_btn);\n","my_div.appendChild(my_btn);\n","document.body.appendChild(my_div);\n","\n","var base64data = 0;\n","var reader;\n","var recorder, gumStream;\n","var recordButton = my_btn;\n","\n","var handleSuccess = function(stream) {\n","  gumStream = stream;\n","  var options = {\n","    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n","    mimeType : 'audio/webm;codecs=opus'\n","    //mimeType : 'audio/webm;codecs=pcm'\n","  };            \n","  //recorder = new MediaRecorder(stream, options);\n","  recorder = new MediaRecorder(stream);\n","  recorder.ondataavailable = function(e) {            \n","    var url = URL.createObjectURL(e.data);\n","    var preview = document.createElement('audio');\n","    preview.controls = true;\n","    preview.src = url;\n","    document.body.appendChild(preview);\n","\n","    reader = new FileReader();\n","    reader.readAsDataURL(e.data); \n","    reader.onloadend = function() {\n","      base64data = reader.result;\n","      //console.log(\"Inside FileReader:\" + base64data);\n","    }\n","  };\n","  recorder.start();\n","  };\n","\n","recordButton.innerText = \"Recording... press to stop\";\n","\n","navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n","\n","\n","function toggleRecording() {\n","  if (recorder && recorder.state == \"recording\") {\n","      recorder.stop();\n","      gumStream.getAudioTracks()[0].stop();\n","      recordButton.innerText = \"Saving the recording... pls wait!\"\n","  }\n","}\n","\n","// https://stackoverflow.com/a/951057\n","function sleep(ms) {\n","  return new Promise(resolve => setTimeout(resolve, ms));\n","}\n","\n","var data = new Promise(resolve=>{\n","//recordButton.addEventListener(\"click\", toggleRecording);\n","recordButton.onclick = ()=>{\n","toggleRecording()\n","\n","sleep(2000).then(() => {\n","  // wait 2000ms for the data to be available...\n","  // ideally this should use something like await...\n","  //console.log(\"Inside data:\" + base64data)\n","  resolve(base64data.toString())\n","\n","});\n","\n","}\n","});\n","      \n","</script>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["You (語音): 你好,請問你可以怎麼幫我\n","你好，有什麼需要我協助的嗎？\n","輸入 '1' 以進行文字輸入，或 '2' 以進行語音輸入：2\n","Recording for 5 seconds...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<script>\n","var my_div = document.createElement(\"DIV\");\n","var my_p = document.createElement(\"P\");\n","var my_btn = document.createElement(\"BUTTON\");\n","var t = document.createTextNode(\"Press to start recording\");\n","\n","my_btn.appendChild(t);\n","//my_p.appendChild(my_btn);\n","my_div.appendChild(my_btn);\n","document.body.appendChild(my_div);\n","\n","var base64data = 0;\n","var reader;\n","var recorder, gumStream;\n","var recordButton = my_btn;\n","\n","var handleSuccess = function(stream) {\n","  gumStream = stream;\n","  var options = {\n","    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n","    mimeType : 'audio/webm;codecs=opus'\n","    //mimeType : 'audio/webm;codecs=pcm'\n","  };            \n","  //recorder = new MediaRecorder(stream, options);\n","  recorder = new MediaRecorder(stream);\n","  recorder.ondataavailable = function(e) {            \n","    var url = URL.createObjectURL(e.data);\n","    var preview = document.createElement('audio');\n","    preview.controls = true;\n","    preview.src = url;\n","    document.body.appendChild(preview);\n","\n","    reader = new FileReader();\n","    reader.readAsDataURL(e.data); \n","    reader.onloadend = function() {\n","      base64data = reader.result;\n","      //console.log(\"Inside FileReader:\" + base64data);\n","    }\n","  };\n","  recorder.start();\n","  };\n","\n","recordButton.innerText = \"Recording... press to stop\";\n","\n","navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n","\n","\n","function toggleRecording() {\n","  if (recorder && recorder.state == \"recording\") {\n","      recorder.stop();\n","      gumStream.getAudioTracks()[0].stop();\n","      recordButton.innerText = \"Saving the recording... pls wait!\"\n","  }\n","}\n","\n","// https://stackoverflow.com/a/951057\n","function sleep(ms) {\n","  return new Promise(resolve => setTimeout(resolve, ms));\n","}\n","\n","var data = new Promise(resolve=>{\n","//recordButton.addEventListener(\"click\", toggleRecording);\n","recordButton.onclick = ()=>{\n","toggleRecording()\n","\n","sleep(2000).then(() => {\n","  // wait 2000ms for the data to be available...\n","  // ideally this should use something like await...\n","  //console.log(\"Inside data:\" + base64data)\n","  resolve(base64data.toString())\n","\n","});\n","\n","}\n","});\n","      \n","</script>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["You (語音): 祟祝祚\n","家人和朋友之間的關係可能是引起情緒困擾的一個因素。我願意聽取更多你的故事。\n","輸入 '1' 以進行文字輸入，或 '2' 以進行語音輸入：2\n","Recording for 5 seconds...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<script>\n","var my_div = document.createElement(\"DIV\");\n","var my_p = document.createElement(\"P\");\n","var my_btn = document.createElement(\"BUTTON\");\n","var t = document.createTextNode(\"Press to start recording\");\n","\n","my_btn.appendChild(t);\n","//my_p.appendChild(my_btn);\n","my_div.appendChild(my_btn);\n","document.body.appendChild(my_div);\n","\n","var base64data = 0;\n","var reader;\n","var recorder, gumStream;\n","var recordButton = my_btn;\n","\n","var handleSuccess = function(stream) {\n","  gumStream = stream;\n","  var options = {\n","    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n","    mimeType : 'audio/webm;codecs=opus'\n","    //mimeType : 'audio/webm;codecs=pcm'\n","  };            \n","  //recorder = new MediaRecorder(stream, options);\n","  recorder = new MediaRecorder(stream);\n","  recorder.ondataavailable = function(e) {            \n","    var url = URL.createObjectURL(e.data);\n","    var preview = document.createElement('audio');\n","    preview.controls = true;\n","    preview.src = url;\n","    document.body.appendChild(preview);\n","\n","    reader = new FileReader();\n","    reader.readAsDataURL(e.data); \n","    reader.onloadend = function() {\n","      base64data = reader.result;\n","      //console.log(\"Inside FileReader:\" + base64data);\n","    }\n","  };\n","  recorder.start();\n","  };\n","\n","recordButton.innerText = \"Recording... press to stop\";\n","\n","navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n","\n","\n","function toggleRecording() {\n","  if (recorder && recorder.state == \"recording\") {\n","      recorder.stop();\n","      gumStream.getAudioTracks()[0].stop();\n","      recordButton.innerText = \"Saving the recording... pls wait!\"\n","  }\n","}\n","\n","// https://stackoverflow.com/a/951057\n","function sleep(ms) {\n","  return new Promise(resolve => setTimeout(resolve, ms));\n","}\n","\n","var data = new Promise(resolve=>{\n","//recordButton.addEventListener(\"click\", toggleRecording);\n","recordButton.onclick = ()=>{\n","toggleRecording()\n","\n","sleep(2000).then(() => {\n","  // wait 2000ms for the data to be available...\n","  // ideally this should use something like await...\n","  //console.log(\"Inside data:\" + base64data)\n","  resolve(base64data.toString())\n","\n","});\n","\n","}\n","});\n","      \n","</script>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["You (語音): 結束\n","再見！\n"]}]},{"cell_type":"code","source":["# def chat():\n","#     print(\"開始與您的機器人對話（輸入 結束 以停止）：\")\n","#     # speak(\"開始與您的機器人對話（輸入 結束 以停止）：\")\n","#     choice = input(\"輸入 '1' 以進行文字輸入，或 '2' 以進行語音輸入：\")\n","#     time.sleep(5)\n","#     while True:\n","#         try:\n","#             if choice == '1':  # Text input\n","#                 inp = input(\"請輸入您的問題：\")\n","#                 if inp==\"結束\":\n","#                   break\n","#             elif choice == '2':  # Speech input\n","#               inp=listenTo()\n","#               print(\"You:\",inp)\n","#               time.sleep(2)\n","#               if inp==\"結束\":\n","#                   break\n","#               print(\"You (語音):\", inp)\n","#             else:\n","#               print(\"無效的選擇，請輸入 '1' 或 '2'。\")\n","#               continue  # Skip to the next iteration\n","\n","\n","#             results=model.predict([bag_of_words(inp,words)])\n","#             results_index=numpy.argmax(results)\n","#             tag=labels[results_index]\n","\n","#             for tg in data[\"intents\"]:\n","#                 if tg[\"tag\"]==tag:\n","#                     responses=tg[\"responses\"]\n","#             rd=random.choice(responses)\n","#             #speak(rd)\n","#             print(rd)\n","#             time.sleep(5)\n","#         except sr.UnknownValueError:\n","#             print(\"我無法理解音訊\")\n","#         except sr.RequestError as e:\n","#             print(\"無法從 Google 語音識別服務請求結果; {0}\".format(e))\n","# chat()"],"metadata":{"id":"Ljl_xOeyCs01","executionInfo":{"status":"ok","timestamp":1730269684683,"user_tz":-480,"elapsed":1100,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}}},"id":"Ljl_xOeyCs01","execution_count":47,"outputs":[]},{"cell_type":"code","source":["# def chat():\n","#     print(\"開始與您的機器人對話（輸入 結束 以停止）：\")\n","#     speak(\"開始與您的機器人對話（輸入 結束 以停止）：\")\n","#     time.sleep(5)\n","#     while True:\n","#         try:\n","#             inp=listenTo()\n","#             print(\"You:\",inp)\n","#             time.sleep(2)\n","#             if inp==\"結束\":\n","#                 break\n","#             results=model.predict([bag_of_words(inp,words)])\n","#             results_index=numpy.argmax(results)\n","#             tag=labels[results_index]\n","\n","#             for tg in data[\"intents\"]:\n","#                 if tg[\"tag\"]==tag:\n","#                     responses=tg[\"responses\"]\n","#             rd=random.choice(responses)\n","#             speak(rd)\n","#             print(rd)\n","#             time.sleep(5)\n","#         except sr.UnknownValueError:\n","#             print(\"我無法理解音訊\")\n","#         except sr.RequestError as e:\n","#             print(\"無法從 Google 語音識別服務請求結果; {0}\".format(e))\n","# chat()"],"metadata":{"id":"RWNkTcAg-N_P","executionInfo":{"status":"ok","timestamp":1730269678904,"user_tz":-480,"elapsed":1092,"user":{"displayName":"11 黃苡菱 Elaine","userId":"09328617780337970743"}}},"id":"RWNkTcAg-N_P","execution_count":46,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}